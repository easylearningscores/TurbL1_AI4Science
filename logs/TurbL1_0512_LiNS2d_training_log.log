2025-05-12 12:20:38,472 Epoch 1/500
2025-05-12 12:20:52,181 Current Learning Rate: 0.0009999901
2025-05-12 12:20:52,308 Train Loss: 0.0366269, Val Loss: 0.0268818
2025-05-12 12:20:52,308 Epoch 2/500
2025-05-12 12:21:04,814 Current Learning Rate: 0.0009999605
2025-05-12 12:21:04,917 Train Loss: 0.0216158, Val Loss: 0.0172549
2025-05-12 12:21:04,917 Epoch 3/500
2025-05-12 12:21:17,289 Current Learning Rate: 0.0009999112
2025-05-12 12:21:17,377 Train Loss: 0.0129906, Val Loss: 0.0099386
2025-05-12 12:21:17,377 Epoch 4/500
2025-05-12 12:21:29,854 Current Learning Rate: 0.0009998421
2025-05-12 12:21:29,974 Train Loss: 0.0083267, Val Loss: 0.0069986
2025-05-12 12:21:29,974 Epoch 5/500
2025-05-12 12:21:42,552 Current Learning Rate: 0.0009997533
2025-05-12 12:21:42,641 Train Loss: 0.0060662, Val Loss: 0.0054679
2025-05-12 12:21:42,642 Epoch 6/500
2025-05-12 12:21:54,966 Current Learning Rate: 0.0009996447
2025-05-12 12:21:55,045 Train Loss: 0.0050072, Val Loss: 0.0053337
2025-05-12 12:21:55,045 Epoch 7/500
2025-05-12 12:22:07,247 Current Learning Rate: 0.0009995165
2025-05-12 12:22:07,349 Train Loss: 0.0042268, Val Loss: 0.0039783
2025-05-12 12:22:07,350 Epoch 8/500
2025-05-12 12:22:19,638 Current Learning Rate: 0.0009993685
2025-05-12 12:22:19,727 Train Loss: 0.0036096, Val Loss: 0.0035810
2025-05-12 12:22:19,728 Epoch 9/500
2025-05-12 12:22:32,346 Current Learning Rate: 0.0009992008
2025-05-12 12:22:32,441 Train Loss: 0.0032742, Val Loss: 0.0030473
2025-05-12 12:22:32,442 Epoch 10/500
2025-05-12 12:22:44,933 Current Learning Rate: 0.0009990134
2025-05-12 12:22:45,021 Train Loss: 0.0027844, Val Loss: 0.0029425
2025-05-12 12:22:45,021 Epoch 11/500
2025-05-12 12:22:57,476 Current Learning Rate: 0.0009988063
2025-05-12 12:22:57,593 Train Loss: 0.0026465, Val Loss: 0.0025781
2025-05-12 12:22:57,594 Epoch 12/500
2025-05-12 12:23:10,300 Current Learning Rate: 0.0009985795
2025-05-12 12:23:10,415 Train Loss: 0.0023473, Val Loss: 0.0023833
2025-05-12 12:23:10,416 Epoch 13/500
2025-05-12 12:23:23,146 Current Learning Rate: 0.0009983330
2025-05-12 12:23:23,147 Train Loss: 0.0021853, Val Loss: 0.0024092
2025-05-12 12:23:23,147 Epoch 14/500
2025-05-12 12:23:35,940 Current Learning Rate: 0.0009980668
2025-05-12 12:23:36,029 Train Loss: 0.0021277, Val Loss: 0.0022556
2025-05-12 12:23:36,030 Epoch 15/500
2025-05-12 12:23:48,532 Current Learning Rate: 0.0009977810
2025-05-12 12:23:48,614 Train Loss: 0.0019064, Val Loss: 0.0020060
2025-05-12 12:23:48,615 Epoch 16/500
2025-05-12 12:24:01,249 Current Learning Rate: 0.0009974755
2025-05-12 12:24:01,358 Train Loss: 0.0017137, Val Loss: 0.0019302
2025-05-12 12:24:01,358 Epoch 17/500
2025-05-12 12:24:13,732 Current Learning Rate: 0.0009971504
2025-05-12 12:24:13,821 Train Loss: 0.0017257, Val Loss: 0.0018127
2025-05-12 12:24:13,821 Epoch 18/500
2025-05-12 12:24:26,008 Current Learning Rate: 0.0009968057
2025-05-12 12:24:26,101 Train Loss: 0.0015665, Val Loss: 0.0017138
2025-05-12 12:24:26,101 Epoch 19/500
2025-05-12 12:24:38,729 Current Learning Rate: 0.0009964413
2025-05-12 12:24:38,729 Train Loss: 0.0015721, Val Loss: 0.0017456
2025-05-12 12:24:38,729 Epoch 20/500
2025-05-12 12:24:51,433 Current Learning Rate: 0.0009960574
2025-05-12 12:24:51,536 Train Loss: 0.0014397, Val Loss: 0.0016877
2025-05-12 12:24:51,537 Epoch 21/500
2025-05-12 12:25:04,078 Current Learning Rate: 0.0009956538
2025-05-12 12:25:04,160 Train Loss: 0.0013397, Val Loss: 0.0015178
2025-05-12 12:25:04,160 Epoch 22/500
2025-05-12 12:25:16,792 Current Learning Rate: 0.0009952307
2025-05-12 12:25:16,792 Train Loss: 0.0013182, Val Loss: 0.0015785
2025-05-12 12:25:16,793 Epoch 23/500
2025-05-12 12:25:29,252 Current Learning Rate: 0.0009947881
2025-05-12 12:25:29,253 Train Loss: 0.0012886, Val Loss: 0.0015313
2025-05-12 12:25:29,253 Epoch 24/500
2025-05-12 12:25:41,813 Current Learning Rate: 0.0009943259
2025-05-12 12:25:41,898 Train Loss: 0.0012068, Val Loss: 0.0014304
2025-05-12 12:25:41,898 Epoch 25/500
2025-05-12 12:25:54,295 Current Learning Rate: 0.0009938442
2025-05-12 12:25:54,518 Train Loss: 0.0011612, Val Loss: 0.0013660
2025-05-12 12:25:54,518 Epoch 26/500
2025-05-12 12:26:06,860 Current Learning Rate: 0.0009933430
2025-05-12 12:26:06,957 Train Loss: 0.0011317, Val Loss: 0.0013421
2025-05-12 12:26:06,957 Epoch 27/500
2025-05-12 12:26:19,407 Current Learning Rate: 0.0009928223
2025-05-12 12:26:19,500 Train Loss: 0.0011078, Val Loss: 0.0013229
2025-05-12 12:26:19,500 Epoch 28/500
2025-05-12 12:26:32,108 Current Learning Rate: 0.0009922822
2025-05-12 12:26:32,108 Train Loss: 0.0010746, Val Loss: 0.0013451
2025-05-12 12:26:32,108 Epoch 29/500
2025-05-12 12:26:44,674 Current Learning Rate: 0.0009917226
2025-05-12 12:26:44,674 Train Loss: 0.0010151, Val Loss: 0.0015941
2025-05-12 12:26:44,674 Epoch 30/500
2025-05-12 12:26:57,248 Current Learning Rate: 0.0009911436
2025-05-12 12:26:57,336 Train Loss: 0.0010172, Val Loss: 0.0011655
2025-05-12 12:26:57,337 Epoch 31/500
2025-05-12 12:27:09,670 Current Learning Rate: 0.0009905453
2025-05-12 12:27:09,671 Train Loss: 0.0009529, Val Loss: 0.0011894
2025-05-12 12:27:09,671 Epoch 32/500
2025-05-12 12:27:22,192 Current Learning Rate: 0.0009899275
2025-05-12 12:27:22,277 Train Loss: 0.0009495, Val Loss: 0.0011471
2025-05-12 12:27:22,277 Epoch 33/500
2025-05-12 12:27:34,593 Current Learning Rate: 0.0009892905
2025-05-12 12:27:34,686 Train Loss: 0.0009292, Val Loss: 0.0011318
2025-05-12 12:27:34,686 Epoch 34/500
2025-05-12 12:27:46,987 Current Learning Rate: 0.0009886341
2025-05-12 12:27:46,988 Train Loss: 0.0008912, Val Loss: 0.0011942
2025-05-12 12:27:46,988 Epoch 35/500
2025-05-12 12:27:59,512 Current Learning Rate: 0.0009879584
2025-05-12 12:27:59,606 Train Loss: 0.0008575, Val Loss: 0.0010984
2025-05-12 12:27:59,606 Epoch 36/500
2025-05-12 12:28:11,925 Current Learning Rate: 0.0009872634
2025-05-12 12:28:11,926 Train Loss: 0.0009036, Val Loss: 0.0011725
2025-05-12 12:28:11,926 Epoch 37/500
2025-05-12 12:28:24,702 Current Learning Rate: 0.0009865493
2025-05-12 12:28:24,786 Train Loss: 0.0008317, Val Loss: 0.0010787
2025-05-12 12:28:24,786 Epoch 38/500
2025-05-12 12:28:37,119 Current Learning Rate: 0.0009858159
2025-05-12 12:28:37,194 Train Loss: 0.0008035, Val Loss: 0.0010393
2025-05-12 12:28:37,195 Epoch 39/500
2025-05-12 12:28:49,539 Current Learning Rate: 0.0009850633
2025-05-12 12:28:49,632 Train Loss: 0.0007927, Val Loss: 0.0010016
2025-05-12 12:28:49,632 Epoch 40/500
2025-05-12 12:29:02,105 Current Learning Rate: 0.0009842916
2025-05-12 12:29:02,106 Train Loss: 0.0007677, Val Loss: 0.0010718
2025-05-12 12:29:02,106 Epoch 41/500
2025-05-12 12:29:14,698 Current Learning Rate: 0.0009835007
2025-05-12 12:29:14,698 Train Loss: 0.0007895, Val Loss: 0.0010229
2025-05-12 12:29:14,698 Epoch 42/500
2025-05-12 12:29:27,154 Current Learning Rate: 0.0009826908
2025-05-12 12:29:27,155 Train Loss: 0.0007463, Val Loss: 0.0010708
2025-05-12 12:29:27,155 Epoch 43/500
2025-05-12 12:29:39,894 Current Learning Rate: 0.0009818618
2025-05-12 12:29:39,977 Train Loss: 0.0007210, Val Loss: 0.0009577
2025-05-12 12:29:39,977 Epoch 44/500
2025-05-12 12:29:52,506 Current Learning Rate: 0.0009810138
2025-05-12 12:29:52,590 Train Loss: 0.0007816, Val Loss: 0.0009497
2025-05-12 12:29:52,590 Epoch 45/500
2025-05-12 12:30:05,035 Current Learning Rate: 0.0009801468
2025-05-12 12:30:05,036 Train Loss: 0.0007076, Val Loss: 0.0011157
2025-05-12 12:30:05,036 Epoch 46/500
2025-05-12 12:30:17,685 Current Learning Rate: 0.0009792609
2025-05-12 12:30:17,771 Train Loss: 0.0007261, Val Loss: 0.0009423
2025-05-12 12:30:17,771 Epoch 47/500
2025-05-12 12:30:30,346 Current Learning Rate: 0.0009783560
2025-05-12 12:30:30,346 Train Loss: 0.0006777, Val Loss: 0.0009805
2025-05-12 12:30:30,346 Epoch 48/500
2025-05-12 12:30:42,875 Current Learning Rate: 0.0009774323
2025-05-12 12:30:42,966 Train Loss: 0.0006622, Val Loss: 0.0009029
2025-05-12 12:30:42,966 Epoch 49/500
2025-05-12 12:30:55,331 Current Learning Rate: 0.0009764897
2025-05-12 12:30:55,332 Train Loss: 0.0006709, Val Loss: 0.0009954
2025-05-12 12:30:55,332 Epoch 50/500
2025-05-12 12:31:07,885 Current Learning Rate: 0.0009755283
2025-05-12 12:31:08,051 Saved periodic model at epoch 50 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/TurbL1_0512_LiNS2d_epoch_50.pth
2025-05-12 12:31:08,051 Train Loss: 0.0006615, Val Loss: 0.0008901
2025-05-12 12:31:08,051 Epoch 51/500
2025-05-12 12:31:20,480 Current Learning Rate: 0.0009745481
2025-05-12 12:31:20,481 Train Loss: 0.0006297, Val Loss: 0.0009215
2025-05-12 12:31:20,481 Epoch 52/500
2025-05-12 12:31:33,080 Current Learning Rate: 0.0009735492
2025-05-12 12:31:33,194 Train Loss: 0.0006311, Val Loss: 0.0008776
2025-05-12 12:31:33,195 Epoch 53/500
2025-05-12 12:31:45,644 Current Learning Rate: 0.0009725315
2025-05-12 12:31:45,644 Train Loss: 0.0006092, Val Loss: 0.0008937
2025-05-12 12:31:45,645 Epoch 54/500
2025-05-12 12:31:58,109 Current Learning Rate: 0.0009714953
2025-05-12 12:31:58,109 Train Loss: 0.0006366, Val Loss: 0.0009626
2025-05-12 12:31:58,109 Epoch 55/500
2025-05-12 12:32:10,742 Current Learning Rate: 0.0009704404
2025-05-12 12:32:10,849 Train Loss: 0.0005741, Val Loss: 0.0008637
2025-05-12 12:32:10,850 Epoch 56/500
2025-05-12 12:32:23,405 Current Learning Rate: 0.0009693669
2025-05-12 12:32:23,500 Train Loss: 0.0006293, Val Loss: 0.0008630
2025-05-12 12:32:23,500 Epoch 57/500
2025-05-12 12:32:35,818 Current Learning Rate: 0.0009682749
2025-05-12 12:32:35,819 Train Loss: 0.0006011, Val Loss: 0.0009213
2025-05-12 12:32:35,819 Epoch 58/500
2025-05-12 12:32:48,573 Current Learning Rate: 0.0009671645
2025-05-12 12:32:48,574 Train Loss: 0.0005775, Val Loss: 0.0009024
2025-05-12 12:32:48,574 Epoch 59/500
2025-05-12 12:33:01,209 Current Learning Rate: 0.0009660356
2025-05-12 12:33:01,309 Train Loss: 0.0005359, Val Loss: 0.0008067
2025-05-12 12:33:01,309 Epoch 60/500
2025-05-12 12:33:13,881 Current Learning Rate: 0.0009648882
2025-05-12 12:33:13,882 Train Loss: 0.0005812, Val Loss: 0.0008426
2025-05-12 12:33:13,882 Epoch 61/500
2025-05-12 12:33:26,495 Current Learning Rate: 0.0009637226
2025-05-12 12:33:26,496 Train Loss: 0.0005356, Val Loss: 0.0008524
2025-05-12 12:33:26,496 Epoch 62/500
2025-05-12 12:33:39,211 Current Learning Rate: 0.0009625386
2025-05-12 12:33:39,212 Train Loss: 0.0005478, Val Loss: 0.0008933
2025-05-12 12:33:39,212 Epoch 63/500
2025-05-12 12:33:51,873 Current Learning Rate: 0.0009613364
2025-05-12 12:33:51,974 Train Loss: 0.0005442, Val Loss: 0.0008005
2025-05-12 12:33:51,975 Epoch 64/500
2025-05-12 12:34:04,523 Current Learning Rate: 0.0009601159
2025-05-12 12:34:04,524 Train Loss: 0.0005370, Val Loss: 0.0008142
2025-05-12 12:34:04,524 Epoch 65/500
2025-05-12 12:34:16,776 Current Learning Rate: 0.0009588773
2025-05-12 12:34:16,867 Train Loss: 0.0004949, Val Loss: 0.0007938
2025-05-12 12:34:16,868 Epoch 66/500
2025-05-12 12:34:29,181 Current Learning Rate: 0.0009576206
2025-05-12 12:34:29,182 Train Loss: 0.0005153, Val Loss: 0.0008069
2025-05-12 12:34:29,182 Epoch 67/500
2025-05-12 12:34:41,667 Current Learning Rate: 0.0009563458
2025-05-12 12:34:41,765 Train Loss: 0.0005130, Val Loss: 0.0007771
2025-05-12 12:34:41,765 Epoch 68/500
2025-05-12 12:34:54,349 Current Learning Rate: 0.0009550530
2025-05-12 12:34:54,454 Train Loss: 0.0005121, Val Loss: 0.0007679
2025-05-12 12:34:54,454 Epoch 69/500
2025-05-12 12:35:06,968 Current Learning Rate: 0.0009537422
2025-05-12 12:35:06,969 Train Loss: 0.0005000, Val Loss: 0.0008226
2025-05-12 12:35:06,969 Epoch 70/500
2025-05-12 12:35:19,239 Current Learning Rate: 0.0009524135
2025-05-12 12:35:19,327 Train Loss: 0.0005401, Val Loss: 0.0007365
2025-05-12 12:35:19,327 Epoch 71/500
2025-05-12 12:35:31,525 Current Learning Rate: 0.0009510670
2025-05-12 12:35:31,608 Train Loss: 0.0004449, Val Loss: 0.0007126
2025-05-12 12:35:31,609 Epoch 72/500
2025-05-12 12:35:44,213 Current Learning Rate: 0.0009497026
2025-05-12 12:35:44,214 Train Loss: 0.0004578, Val Loss: 0.0007653
2025-05-12 12:35:44,214 Epoch 73/500
2025-05-12 12:35:56,910 Current Learning Rate: 0.0009483205
2025-05-12 12:35:56,910 Train Loss: 0.0004498, Val Loss: 0.0007562
2025-05-12 12:35:56,910 Epoch 74/500
2025-05-12 12:36:09,325 Current Learning Rate: 0.0009469207
2025-05-12 12:36:09,325 Train Loss: 0.0005041, Val Loss: 0.0007891
2025-05-12 12:36:09,326 Epoch 75/500
2025-05-12 12:36:21,633 Current Learning Rate: 0.0009455033
2025-05-12 12:36:21,723 Train Loss: 0.0004449, Val Loss: 0.0006968
2025-05-12 12:36:21,724 Epoch 76/500
2025-05-12 12:36:34,306 Current Learning Rate: 0.0009440682
2025-05-12 12:36:34,307 Train Loss: 0.0004561, Val Loss: 0.0007114
2025-05-12 12:36:34,307 Epoch 77/500
2025-05-12 12:36:46,889 Current Learning Rate: 0.0009426157
2025-05-12 12:36:46,889 Train Loss: 0.0004498, Val Loss: 0.0007426
2025-05-12 12:36:46,889 Epoch 78/500
2025-05-12 12:36:59,183 Current Learning Rate: 0.0009411456
2025-05-12 12:36:59,184 Train Loss: 0.0004501, Val Loss: 0.0007634
2025-05-12 12:36:59,184 Epoch 79/500
2025-05-12 12:37:11,556 Current Learning Rate: 0.0009396582
2025-05-12 12:37:11,557 Train Loss: 0.0004767, Val Loss: 0.0007475
2025-05-12 12:37:11,557 Epoch 80/500
2025-05-12 12:37:23,956 Current Learning Rate: 0.0009381533
2025-05-12 12:37:23,956 Train Loss: 0.0004559, Val Loss: 0.0007090
2025-05-12 12:37:23,956 Epoch 81/500
2025-05-12 12:37:36,548 Current Learning Rate: 0.0009366312
2025-05-12 12:37:36,549 Train Loss: 0.0004272, Val Loss: 0.0007519
2025-05-12 12:37:36,549 Epoch 82/500
2025-05-12 12:37:49,090 Current Learning Rate: 0.0009350919
2025-05-12 12:37:49,172 Train Loss: 0.0004160, Val Loss: 0.0006880
2025-05-12 12:37:49,172 Epoch 83/500
2025-05-12 12:38:01,637 Current Learning Rate: 0.0009335354
2025-05-12 12:38:01,637 Train Loss: 0.0004252, Val Loss: 0.0007133
2025-05-12 12:38:01,637 Epoch 84/500
2025-05-12 12:38:13,990 Current Learning Rate: 0.0009319617
2025-05-12 12:38:14,080 Train Loss: 0.0004185, Val Loss: 0.0006659
2025-05-12 12:38:14,080 Epoch 85/500
2025-05-12 12:38:26,540 Current Learning Rate: 0.0009303710
2025-05-12 12:38:26,618 Train Loss: 0.0003984, Val Loss: 0.0006649
2025-05-12 12:38:26,619 Epoch 86/500
2025-05-12 12:38:38,955 Current Learning Rate: 0.0009287633
2025-05-12 12:38:38,956 Train Loss: 0.0003995, Val Loss: 0.0007465
2025-05-12 12:38:38,956 Epoch 87/500
2025-05-12 12:38:51,444 Current Learning Rate: 0.0009271387
2025-05-12 12:38:51,445 Train Loss: 0.0004392, Val Loss: 0.0006836
2025-05-12 12:38:51,445 Epoch 88/500
2025-05-12 12:39:03,937 Current Learning Rate: 0.0009254972
2025-05-12 12:39:03,937 Train Loss: 0.0004008, Val Loss: 0.0007321
2025-05-12 12:39:03,937 Epoch 89/500
2025-05-12 12:39:16,562 Current Learning Rate: 0.0009238390
2025-05-12 12:39:16,562 Train Loss: 0.0003943, Val Loss: 0.0007182
2025-05-12 12:39:16,562 Epoch 90/500
2025-05-12 12:39:28,826 Current Learning Rate: 0.0009221640
2025-05-12 12:39:28,902 Train Loss: 0.0003660, Val Loss: 0.0006524
2025-05-12 12:39:28,902 Epoch 91/500
2025-05-12 12:39:41,300 Current Learning Rate: 0.0009204723
2025-05-12 12:39:41,300 Train Loss: 0.0003962, Val Loss: 0.0006755
2025-05-12 12:39:41,300 Epoch 92/500
2025-05-12 12:39:53,917 Current Learning Rate: 0.0009187640
2025-05-12 12:39:53,918 Train Loss: 0.0003916, Val Loss: 0.0007235
2025-05-12 12:39:53,918 Epoch 93/500
2025-05-12 12:40:06,375 Current Learning Rate: 0.0009170392
2025-05-12 12:40:06,375 Train Loss: 0.0003896, Val Loss: 0.0006884
2025-05-12 12:40:06,375 Epoch 94/500
2025-05-12 12:40:18,663 Current Learning Rate: 0.0009152979
2025-05-12 12:40:18,663 Train Loss: 0.0004182, Val Loss: 0.0006620
2025-05-12 12:40:18,663 Epoch 95/500
2025-05-12 12:40:31,243 Current Learning Rate: 0.0009135403
2025-05-12 12:40:31,328 Train Loss: 0.0003528, Val Loss: 0.0006217
2025-05-12 12:40:31,328 Epoch 96/500
2025-05-12 12:40:43,846 Current Learning Rate: 0.0009117663
2025-05-12 12:40:43,846 Train Loss: 0.0003511, Val Loss: 0.0006609
2025-05-12 12:40:43,846 Epoch 97/500
2025-05-12 12:40:56,293 Current Learning Rate: 0.0009099761
2025-05-12 12:40:56,293 Train Loss: 0.0003631, Val Loss: 0.0006324
2025-05-12 12:40:56,294 Epoch 98/500
2025-05-12 12:41:08,714 Current Learning Rate: 0.0009081696
2025-05-12 12:41:08,715 Train Loss: 0.0003400, Val Loss: 0.0006465
2025-05-12 12:41:08,715 Epoch 99/500
2025-05-12 12:41:21,149 Current Learning Rate: 0.0009063471
2025-05-12 12:41:21,224 Train Loss: 0.0003817, Val Loss: 0.0006195
2025-05-12 12:41:21,224 Epoch 100/500
2025-05-12 12:41:33,652 Current Learning Rate: 0.0009045085
2025-05-12 12:41:33,758 Saved periodic model at epoch 100 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/TurbL1_0512_LiNS2d_epoch_100.pth
2025-05-12 12:41:33,759 Train Loss: 0.0003493, Val Loss: 0.0006594
2025-05-12 12:41:33,759 Epoch 101/500
2025-05-12 12:41:46,136 Current Learning Rate: 0.0009026539
2025-05-12 12:41:46,138 Train Loss: 0.0003573, Val Loss: 0.0006325
2025-05-12 12:41:46,138 Epoch 102/500
2025-05-12 12:41:58,709 Current Learning Rate: 0.0009007835
2025-05-12 12:41:58,709 Train Loss: 0.0003535, Val Loss: 0.0006664
2025-05-12 12:41:58,709 Epoch 103/500
2025-05-12 12:42:11,290 Current Learning Rate: 0.0008988972
2025-05-12 12:42:11,290 Train Loss: 0.0003750, Val Loss: 0.0008330
2025-05-12 12:42:11,290 Epoch 104/500
2025-05-12 12:42:23,942 Current Learning Rate: 0.0008969952
2025-05-12 12:42:24,040 Train Loss: 0.0003594, Val Loss: 0.0006015
2025-05-12 12:42:24,040 Epoch 105/500
2025-05-12 12:42:36,822 Current Learning Rate: 0.0008950775
2025-05-12 12:42:36,832 Train Loss: 0.0003644, Val Loss: 0.0006868
2025-05-12 12:42:36,833 Epoch 106/500
2025-05-12 12:42:49,753 Current Learning Rate: 0.0008931442
2025-05-12 12:42:49,753 Train Loss: 0.0003269, Val Loss: 0.0006296
2025-05-12 12:42:49,753 Epoch 107/500
2025-05-12 12:43:02,392 Current Learning Rate: 0.0008911954
2025-05-12 12:43:02,470 Train Loss: 0.0003101, Val Loss: 0.0005840
2025-05-12 12:43:02,470 Epoch 108/500
2025-05-12 12:43:14,932 Current Learning Rate: 0.0008892312
2025-05-12 12:43:14,933 Train Loss: 0.0003199, Val Loss: 0.0006317
2025-05-12 12:43:14,933 Epoch 109/500
2025-05-12 12:43:27,634 Current Learning Rate: 0.0008872515
2025-05-12 12:43:27,634 Train Loss: 0.0003306, Val Loss: 0.0006901
2025-05-12 12:43:27,635 Epoch 110/500
2025-05-12 12:43:40,319 Current Learning Rate: 0.0008852566
2025-05-12 12:43:40,320 Train Loss: 0.0003388, Val Loss: 0.0006027
2025-05-12 12:43:40,320 Epoch 111/500
2025-05-12 12:43:52,783 Current Learning Rate: 0.0008832465
2025-05-12 12:43:52,783 Train Loss: 0.0003927, Val Loss: 0.0006527
2025-05-12 12:43:52,784 Epoch 112/500
2025-05-12 12:44:05,047 Current Learning Rate: 0.0008812213
2025-05-12 12:44:05,133 Train Loss: 0.0003164, Val Loss: 0.0005728
2025-05-12 12:44:05,133 Epoch 113/500
2025-05-12 12:44:17,442 Current Learning Rate: 0.0008791810
2025-05-12 12:44:17,442 Train Loss: 0.0002971, Val Loss: 0.0005828
2025-05-12 12:44:17,442 Epoch 114/500
2025-05-12 12:44:29,738 Current Learning Rate: 0.0008771257
2025-05-12 12:44:29,738 Train Loss: 0.0002885, Val Loss: 0.0005747
2025-05-12 12:44:29,738 Epoch 115/500
2025-05-12 12:44:42,249 Current Learning Rate: 0.0008750555
2025-05-12 12:44:42,250 Train Loss: 0.0002997, Val Loss: 0.0005900
2025-05-12 12:44:42,250 Epoch 116/500
2025-05-12 12:44:54,546 Current Learning Rate: 0.0008729706
2025-05-12 12:44:54,546 Train Loss: 0.0003042, Val Loss: 0.0005734
2025-05-12 12:44:54,546 Epoch 117/500
2025-05-12 12:45:07,163 Current Learning Rate: 0.0008708709
2025-05-12 12:45:07,163 Train Loss: 0.0002990, Val Loss: 0.0005929
2025-05-12 12:45:07,163 Epoch 118/500
2025-05-12 12:45:19,844 Current Learning Rate: 0.0008687566
2025-05-12 12:45:19,845 Train Loss: 0.0003036, Val Loss: 0.0005802
2025-05-12 12:45:19,845 Epoch 119/500
2025-05-12 12:45:32,060 Current Learning Rate: 0.0008666277
2025-05-12 12:45:32,141 Train Loss: 0.0002867, Val Loss: 0.0005715
2025-05-12 12:45:32,141 Epoch 120/500
2025-05-12 12:45:44,438 Current Learning Rate: 0.0008644843
2025-05-12 12:45:44,438 Train Loss: 0.0003516, Val Loss: 0.0005901
2025-05-12 12:45:44,439 Epoch 121/500
2025-05-12 12:45:56,573 Current Learning Rate: 0.0008623266
2025-05-12 12:45:56,661 Train Loss: 0.0002939, Val Loss: 0.0005563
2025-05-12 12:45:56,661 Epoch 122/500
2025-05-12 12:46:08,935 Current Learning Rate: 0.0008601545
2025-05-12 12:46:08,936 Train Loss: 0.0002725, Val Loss: 0.0005648
2025-05-12 12:46:08,937 Epoch 123/500
2025-05-12 12:46:21,356 Current Learning Rate: 0.0008579682
2025-05-12 12:46:21,357 Train Loss: 0.0002980, Val Loss: 0.0006227
2025-05-12 12:46:21,357 Epoch 124/500
2025-05-12 12:46:33,775 Current Learning Rate: 0.0008557678
2025-05-12 12:46:33,776 Train Loss: 0.0002844, Val Loss: 0.0005692
2025-05-12 12:46:33,776 Epoch 125/500
2025-05-12 12:46:46,417 Current Learning Rate: 0.0008535534
2025-05-12 12:46:46,490 Train Loss: 0.0002801, Val Loss: 0.0005539
2025-05-12 12:46:46,490 Epoch 126/500
2025-05-12 12:46:58,818 Current Learning Rate: 0.0008513250
2025-05-12 12:46:58,819 Train Loss: 0.0002841, Val Loss: 0.0006981
2025-05-12 12:46:58,819 Epoch 127/500
2025-05-12 12:47:11,231 Current Learning Rate: 0.0008490827
2025-05-12 12:47:11,232 Train Loss: 0.0003023, Val Loss: 0.0005816
2025-05-12 12:47:11,232 Epoch 128/500
2025-05-12 12:47:23,603 Current Learning Rate: 0.0008468267
2025-05-12 12:47:23,603 Train Loss: 0.0002680, Val Loss: 0.0005610
2025-05-12 12:47:23,603 Epoch 129/500
2025-05-12 12:47:35,896 Current Learning Rate: 0.0008445569
2025-05-12 12:47:35,897 Train Loss: 0.0002645, Val Loss: 0.0005632
2025-05-12 12:47:35,897 Epoch 130/500
2025-05-12 12:47:48,323 Current Learning Rate: 0.0008422736
2025-05-12 12:47:48,324 Train Loss: 0.0002588, Val Loss: 0.0005568
2025-05-12 12:47:48,324 Epoch 131/500
2025-05-12 12:48:00,920 Current Learning Rate: 0.0008399767
2025-05-12 12:48:00,921 Train Loss: 0.0002692, Val Loss: 0.0006163
2025-05-12 12:48:00,921 Epoch 132/500
2025-05-12 12:48:13,458 Current Learning Rate: 0.0008376664
2025-05-12 12:48:13,459 Train Loss: 0.0002928, Val Loss: 0.0005580
2025-05-12 12:48:13,459 Epoch 133/500
2025-05-12 12:48:25,734 Current Learning Rate: 0.0008353428
2025-05-12 12:48:25,734 Train Loss: 0.0002691, Val Loss: 0.0005564
2025-05-12 12:48:25,734 Epoch 134/500
2025-05-12 12:48:38,031 Current Learning Rate: 0.0008330059
2025-05-12 12:48:38,134 Train Loss: 0.0002869, Val Loss: 0.0005474
2025-05-12 12:48:38,135 Epoch 135/500
2025-05-12 12:48:50,704 Current Learning Rate: 0.0008306559
2025-05-12 12:48:50,797 Train Loss: 0.0002595, Val Loss: 0.0005361
2025-05-12 12:48:50,797 Epoch 136/500
2025-05-12 12:49:03,239 Current Learning Rate: 0.0008282929
2025-05-12 12:49:03,240 Train Loss: 0.0002556, Val Loss: 0.0005488
2025-05-12 12:49:03,240 Epoch 137/500
2025-05-12 12:49:15,695 Current Learning Rate: 0.0008259169
2025-05-12 12:49:15,775 Train Loss: 0.0002510, Val Loss: 0.0005272
2025-05-12 12:49:15,775 Epoch 138/500
2025-05-12 12:49:28,134 Current Learning Rate: 0.0008235280
2025-05-12 12:49:28,134 Train Loss: 0.0002958, Val Loss: 0.0005975
2025-05-12 12:49:28,134 Epoch 139/500
2025-05-12 12:49:40,368 Current Learning Rate: 0.0008211263
2025-05-12 12:49:40,369 Train Loss: 0.0002700, Val Loss: 0.0005482
2025-05-12 12:49:40,369 Epoch 140/500
2025-05-12 12:49:52,655 Current Learning Rate: 0.0008187120
2025-05-12 12:49:52,755 Train Loss: 0.0002340, Val Loss: 0.0005152
2025-05-12 12:49:52,755 Epoch 141/500
2025-05-12 12:50:05,101 Current Learning Rate: 0.0008162851
2025-05-12 12:50:05,201 Train Loss: 0.0002400, Val Loss: 0.0005138
2025-05-12 12:50:05,201 Epoch 142/500
2025-05-12 12:50:17,406 Current Learning Rate: 0.0008138457
2025-05-12 12:50:17,407 Train Loss: 0.0002475, Val Loss: 0.0005446
2025-05-12 12:50:17,407 Epoch 143/500
2025-05-12 12:50:29,830 Current Learning Rate: 0.0008113939
2025-05-12 12:50:29,907 Train Loss: 0.0002693, Val Loss: 0.0005095
2025-05-12 12:50:29,908 Epoch 144/500
2025-05-12 12:50:42,388 Current Learning Rate: 0.0008089298
2025-05-12 12:50:42,389 Train Loss: 0.0002378, Val Loss: 0.0005108
2025-05-12 12:50:42,389 Epoch 145/500
2025-05-12 12:50:54,825 Current Learning Rate: 0.0008064535
2025-05-12 12:50:54,826 Train Loss: 0.0002550, Val Loss: 0.0005183
2025-05-12 12:50:54,826 Epoch 146/500
2025-05-12 12:51:07,294 Current Learning Rate: 0.0008039651
2025-05-12 12:51:07,295 Train Loss: 0.0002437, Val Loss: 0.0005337
2025-05-12 12:51:07,295 Epoch 147/500
2025-05-12 12:51:19,955 Current Learning Rate: 0.0008014648
2025-05-12 12:51:19,955 Train Loss: 0.0002677, Val Loss: 0.0005512
2025-05-12 12:51:19,956 Epoch 148/500
2025-05-12 12:51:32,335 Current Learning Rate: 0.0007989525
2025-05-12 12:51:32,336 Train Loss: 0.0002442, Val Loss: 0.0005163
2025-05-12 12:51:32,336 Epoch 149/500
2025-05-12 12:51:44,879 Current Learning Rate: 0.0007964284
2025-05-12 12:51:44,880 Train Loss: 0.0002405, Val Loss: 0.0005159
2025-05-12 12:51:44,880 Epoch 150/500
2025-05-12 12:51:57,381 Current Learning Rate: 0.0007938926
2025-05-12 12:51:57,557 Saved periodic model at epoch 150 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/TurbL1_0512_LiNS2d_epoch_150.pth
2025-05-12 12:51:57,557 Train Loss: 0.0002261, Val Loss: 0.0005007
2025-05-12 12:51:57,557 Epoch 151/500
2025-05-12 12:52:09,974 Current Learning Rate: 0.0007913452
2025-05-12 12:52:09,975 Train Loss: 0.0002234, Val Loss: 0.0005480
2025-05-12 12:52:09,975 Epoch 152/500
2025-05-12 12:52:22,671 Current Learning Rate: 0.0007887864
2025-05-12 12:52:22,672 Train Loss: 0.0002439, Val Loss: 0.0005045
2025-05-12 12:52:22,672 Epoch 153/500
2025-05-12 12:52:34,878 Current Learning Rate: 0.0007862161
2025-05-12 12:52:34,975 Train Loss: 0.0002446, Val Loss: 0.0004991
2025-05-12 12:52:34,976 Epoch 154/500
2025-05-12 12:52:47,346 Current Learning Rate: 0.0007836345
2025-05-12 12:52:47,347 Train Loss: 0.0002279, Val Loss: 0.0005061
2025-05-12 12:52:47,347 Epoch 155/500
2025-05-12 12:52:59,835 Current Learning Rate: 0.0007810417
2025-05-12 12:52:59,917 Train Loss: 0.0002399, Val Loss: 0.0004917
2025-05-12 12:52:59,918 Epoch 156/500
2025-05-12 12:53:12,345 Current Learning Rate: 0.0007784378
2025-05-12 12:53:12,346 Train Loss: 0.0002236, Val Loss: 0.0005363
2025-05-12 12:53:12,346 Epoch 157/500
2025-05-12 12:53:25,030 Current Learning Rate: 0.0007758229
2025-05-12 12:53:25,116 Train Loss: 0.0002397, Val Loss: 0.0004842
2025-05-12 12:53:25,116 Epoch 158/500
2025-05-12 12:53:37,598 Current Learning Rate: 0.0007731972
2025-05-12 12:53:37,599 Train Loss: 0.0002129, Val Loss: 0.0004875
2025-05-12 12:53:37,599 Epoch 159/500
2025-05-12 12:53:49,959 Current Learning Rate: 0.0007705606
2025-05-12 12:53:49,960 Train Loss: 0.0002173, Val Loss: 0.0004895
2025-05-12 12:53:49,960 Epoch 160/500
2025-05-12 12:54:02,529 Current Learning Rate: 0.0007679134
2025-05-12 12:54:02,530 Train Loss: 0.0002105, Val Loss: 0.0005093
2025-05-12 12:54:02,530 Epoch 161/500
2025-05-12 12:54:14,943 Current Learning Rate: 0.0007652556
2025-05-12 12:54:14,943 Train Loss: 0.0002217, Val Loss: 0.0005402
2025-05-12 12:54:14,944 Epoch 162/500
2025-05-12 12:54:27,472 Current Learning Rate: 0.0007625873
2025-05-12 12:54:27,473 Train Loss: 0.0002304, Val Loss: 0.0005025
2025-05-12 12:54:27,473 Epoch 163/500
2025-05-12 12:54:39,849 Current Learning Rate: 0.0007599087
2025-05-12 12:54:39,850 Train Loss: 0.0002138, Val Loss: 0.0005059
2025-05-12 12:54:39,850 Epoch 164/500
2025-05-12 12:54:52,396 Current Learning Rate: 0.0007572198
2025-05-12 12:54:52,397 Train Loss: 0.0002082, Val Loss: 0.0005166
2025-05-12 12:54:52,397 Epoch 165/500
2025-05-12 12:55:05,165 Current Learning Rate: 0.0007545207
2025-05-12 12:55:05,166 Train Loss: 0.0002147, Val Loss: 0.0005196
2025-05-12 12:55:05,166 Epoch 166/500
2025-05-12 12:55:17,899 Current Learning Rate: 0.0007518116
2025-05-12 12:55:17,977 Train Loss: 0.0002232, Val Loss: 0.0004744
2025-05-12 12:55:17,977 Epoch 167/500
2025-05-12 12:55:30,309 Current Learning Rate: 0.0007490926
2025-05-12 12:55:30,310 Train Loss: 0.0002130, Val Loss: 0.0004919
2025-05-12 12:55:30,310 Epoch 168/500
2025-05-12 12:55:42,871 Current Learning Rate: 0.0007463637
2025-05-12 12:55:42,872 Train Loss: 0.0002100, Val Loss: 0.0004858
2025-05-12 12:55:42,872 Epoch 169/500
2025-05-12 12:55:55,506 Current Learning Rate: 0.0007436251
2025-05-12 12:55:55,507 Train Loss: 0.0002061, Val Loss: 0.0004915
2025-05-12 12:55:55,507 Epoch 170/500
2025-05-12 12:56:08,105 Current Learning Rate: 0.0007408768
2025-05-12 12:56:08,105 Train Loss: 0.0002108, Val Loss: 0.0004882
2025-05-12 12:56:08,105 Epoch 171/500
2025-05-12 12:56:20,863 Current Learning Rate: 0.0007381191
2025-05-12 12:56:20,864 Train Loss: 0.0002006, Val Loss: 0.0004869
2025-05-12 12:56:20,864 Epoch 172/500
2025-05-12 12:56:33,623 Current Learning Rate: 0.0007353520
2025-05-12 12:56:33,623 Train Loss: 0.0002071, Val Loss: 0.0004752
2025-05-12 12:56:33,624 Epoch 173/500
2025-05-12 12:56:46,283 Current Learning Rate: 0.0007325755
2025-05-12 12:56:46,283 Train Loss: 0.0001981, Val Loss: 0.0004773
2025-05-12 12:56:46,284 Epoch 174/500
2025-05-12 12:56:58,780 Current Learning Rate: 0.0007297899
2025-05-12 12:56:58,781 Train Loss: 0.0002037, Val Loss: 0.0004839
2025-05-12 12:56:58,782 Epoch 175/500
2025-05-12 12:57:11,495 Current Learning Rate: 0.0007269952
2025-05-12 12:57:11,496 Train Loss: 0.0002142, Val Loss: 0.0004906
2025-05-12 12:57:11,497 Epoch 176/500
2025-05-12 12:57:24,248 Current Learning Rate: 0.0007241916
2025-05-12 12:57:24,343 Train Loss: 0.0001996, Val Loss: 0.0004718
2025-05-12 12:57:24,344 Epoch 177/500
2025-05-12 12:57:36,831 Current Learning Rate: 0.0007213791
2025-05-12 12:57:36,929 Train Loss: 0.0001911, Val Loss: 0.0004684
2025-05-12 12:57:36,929 Epoch 178/500
2025-05-12 12:57:49,552 Current Learning Rate: 0.0007185579
2025-05-12 12:57:49,646 Train Loss: 0.0001959, Val Loss: 0.0004623
2025-05-12 12:57:49,647 Epoch 179/500
2025-05-12 12:58:02,325 Current Learning Rate: 0.0007157280
2025-05-12 12:58:02,433 Train Loss: 0.0001940, Val Loss: 0.0004583
2025-05-12 12:58:02,434 Epoch 180/500
2025-05-12 12:58:15,119 Current Learning Rate: 0.0007128896
2025-05-12 12:58:15,119 Train Loss: 0.0001921, Val Loss: 0.0004891
2025-05-12 12:58:15,120 Epoch 181/500
2025-05-12 12:58:27,805 Current Learning Rate: 0.0007100429
2025-05-12 12:58:27,923 Train Loss: 0.0001907, Val Loss: 0.0004544
2025-05-12 12:58:27,924 Epoch 182/500
2025-05-12 12:58:40,419 Current Learning Rate: 0.0007071878
2025-05-12 12:58:40,420 Train Loss: 0.0001889, Val Loss: 0.0004634
2025-05-12 12:58:40,420 Epoch 183/500
2025-05-12 12:58:53,335 Current Learning Rate: 0.0007043245
2025-05-12 12:58:53,336 Train Loss: 0.0001993, Val Loss: 0.0004830
2025-05-12 12:58:53,336 Epoch 184/500
2025-05-12 12:59:05,937 Current Learning Rate: 0.0007014532
2025-05-12 12:59:05,937 Train Loss: 0.0001902, Val Loss: 0.0004727
2025-05-12 12:59:05,937 Epoch 185/500
2025-05-12 12:59:18,836 Current Learning Rate: 0.0006985739
2025-05-12 12:59:18,946 Train Loss: 0.0001935, Val Loss: 0.0004484
2025-05-12 12:59:18,946 Epoch 186/500
2025-05-12 12:59:31,723 Current Learning Rate: 0.0006956868
2025-05-12 12:59:31,724 Train Loss: 0.0001794, Val Loss: 0.0004510
2025-05-12 12:59:31,724 Epoch 187/500
2025-05-12 12:59:44,406 Current Learning Rate: 0.0006927920
2025-05-12 12:59:44,406 Train Loss: 0.0001838, Val Loss: 0.0004551
2025-05-12 12:59:44,407 Epoch 188/500
2025-05-12 12:59:57,337 Current Learning Rate: 0.0006898895
2025-05-12 12:59:57,337 Train Loss: 0.0001893, Val Loss: 0.0004571
2025-05-12 12:59:57,338 Epoch 189/500
2025-05-12 13:00:10,000 Current Learning Rate: 0.0006869796
2025-05-12 13:00:10,000 Train Loss: 0.0001844, Val Loss: 0.0004640
2025-05-12 13:00:10,001 Epoch 190/500
2025-05-12 13:00:22,770 Current Learning Rate: 0.0006840623
2025-05-12 13:00:22,771 Train Loss: 0.0001945, Val Loss: 0.0004522
2025-05-12 13:00:22,771 Epoch 191/500
2025-05-12 13:00:35,436 Current Learning Rate: 0.0006811377
2025-05-12 13:00:35,437 Train Loss: 0.0001887, Val Loss: 0.0004583
2025-05-12 13:00:35,437 Epoch 192/500
2025-05-12 13:00:48,140 Current Learning Rate: 0.0006782059
2025-05-12 13:00:48,140 Train Loss: 0.0001838, Val Loss: 0.0004759
2025-05-12 13:00:48,140 Epoch 193/500
2025-05-12 13:01:00,798 Current Learning Rate: 0.0006752672
2025-05-12 13:01:00,895 Train Loss: 0.0001755, Val Loss: 0.0004414
2025-05-12 13:01:00,895 Epoch 194/500
2025-05-12 13:01:13,672 Current Learning Rate: 0.0006723215
2025-05-12 13:01:13,673 Train Loss: 0.0001747, Val Loss: 0.0004496
2025-05-12 13:01:13,674 Epoch 195/500
2025-05-12 13:01:26,501 Current Learning Rate: 0.0006693690
2025-05-12 13:01:26,501 Train Loss: 0.0001745, Val Loss: 0.0004561
2025-05-12 13:01:26,502 Epoch 196/500
2025-05-12 13:01:39,192 Current Learning Rate: 0.0006664098
2025-05-12 13:01:39,193 Train Loss: 0.0001736, Val Loss: 0.0004557
2025-05-12 13:01:39,194 Epoch 197/500
2025-05-12 13:01:51,377 Current Learning Rate: 0.0006634440
2025-05-12 13:01:51,378 Train Loss: 0.0001845, Val Loss: 0.0004574
2025-05-12 13:01:51,378 Epoch 198/500
2025-05-12 13:02:03,958 Current Learning Rate: 0.0006604718
2025-05-12 13:02:03,968 Train Loss: 0.0001843, Val Loss: 0.0004837
2025-05-12 13:02:03,969 Epoch 199/500
2025-05-12 13:02:16,538 Current Learning Rate: 0.0006574933
2025-05-12 13:02:16,539 Train Loss: 0.0001726, Val Loss: 0.0004474
2025-05-12 13:02:16,539 Epoch 200/500
2025-05-12 13:02:29,500 Current Learning Rate: 0.0006545085
2025-05-12 13:02:29,597 Saved periodic model at epoch 200 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/TurbL1_0512_LiNS2d_epoch_200.pth
2025-05-12 13:02:29,597 Train Loss: 0.0001694, Val Loss: 0.0004418
2025-05-12 13:02:29,598 Epoch 201/500
2025-05-12 13:02:42,111 Current Learning Rate: 0.0006515176
2025-05-12 13:02:42,221 Train Loss: 0.0001604, Val Loss: 0.0004313
2025-05-12 13:02:42,221 Epoch 202/500
2025-05-12 13:02:54,784 Current Learning Rate: 0.0006485208
2025-05-12 13:02:54,785 Train Loss: 0.0001851, Val Loss: 0.0004619
2025-05-12 13:02:54,785 Epoch 203/500
2025-05-12 13:03:07,608 Current Learning Rate: 0.0006455181
2025-05-12 13:03:07,608 Train Loss: 0.0001778, Val Loss: 0.0004405
2025-05-12 13:03:07,609 Epoch 204/500
2025-05-12 13:03:20,679 Current Learning Rate: 0.0006425096
2025-05-12 13:03:20,680 Train Loss: 0.0001659, Val Loss: 0.0004455
2025-05-12 13:03:20,680 Epoch 205/500
2025-05-12 13:03:33,185 Current Learning Rate: 0.0006394956
2025-05-12 13:03:33,186 Train Loss: 0.0001672, Val Loss: 0.0004369
2025-05-12 13:03:33,186 Epoch 206/500
2025-05-12 13:03:45,720 Current Learning Rate: 0.0006364760
2025-05-12 13:03:45,721 Train Loss: 0.0001781, Val Loss: 0.0004436
2025-05-12 13:03:45,721 Epoch 207/500
2025-05-12 13:03:58,349 Current Learning Rate: 0.0006334510
2025-05-12 13:03:58,350 Train Loss: 0.0001596, Val Loss: 0.0004383
2025-05-12 13:03:58,350 Epoch 208/500
2025-05-12 13:04:10,925 Current Learning Rate: 0.0006304208
2025-05-12 13:04:10,926 Train Loss: 0.0001537, Val Loss: 0.0004493
2025-05-12 13:04:10,926 Epoch 209/500
2025-05-12 13:04:23,544 Current Learning Rate: 0.0006273854
2025-05-12 13:04:23,643 Train Loss: 0.0001631, Val Loss: 0.0004310
2025-05-12 13:04:23,643 Epoch 210/500
2025-05-12 13:04:36,467 Current Learning Rate: 0.0006243449
2025-05-12 13:04:36,468 Train Loss: 0.0001582, Val Loss: 0.0004316
2025-05-12 13:04:36,468 Epoch 211/500
2025-05-12 13:04:48,809 Current Learning Rate: 0.0006212996
2025-05-12 13:04:48,809 Train Loss: 0.0001565, Val Loss: 0.0004314
2025-05-12 13:04:48,810 Epoch 212/500
2025-05-12 13:05:01,342 Current Learning Rate: 0.0006182495
2025-05-12 13:05:01,343 Train Loss: 0.0001732, Val Loss: 0.0004603
2025-05-12 13:05:01,343 Epoch 213/500
2025-05-12 13:05:13,910 Current Learning Rate: 0.0006151947
2025-05-12 13:05:13,911 Train Loss: 0.0001645, Val Loss: 0.0004425
2025-05-12 13:05:13,911 Epoch 214/500
2025-05-12 13:05:26,573 Current Learning Rate: 0.0006121354
2025-05-12 13:05:26,657 Train Loss: 0.0001569, Val Loss: 0.0004273
2025-05-12 13:05:26,658 Epoch 215/500
2025-05-12 13:05:39,290 Current Learning Rate: 0.0006090716
2025-05-12 13:05:39,290 Train Loss: 0.0001566, Val Loss: 0.0004281
2025-05-12 13:05:39,291 Epoch 216/500
2025-05-12 13:05:51,816 Current Learning Rate: 0.0006060036
2025-05-12 13:05:51,816 Train Loss: 0.0001565, Val Loss: 0.0004308
2025-05-12 13:05:51,817 Epoch 217/500
2025-05-12 13:06:04,298 Current Learning Rate: 0.0006029313
2025-05-12 13:06:04,403 Train Loss: 0.0001560, Val Loss: 0.0004250
2025-05-12 13:06:04,404 Epoch 218/500
2025-05-12 13:06:17,011 Current Learning Rate: 0.0005998550
2025-05-12 13:06:17,012 Train Loss: 0.0001572, Val Loss: 0.0004292
2025-05-12 13:06:17,012 Epoch 219/500
2025-05-12 13:06:29,864 Current Learning Rate: 0.0005967747
2025-05-12 13:06:29,968 Train Loss: 0.0001607, Val Loss: 0.0004210
2025-05-12 13:06:29,968 Epoch 220/500
2025-05-12 13:06:42,253 Current Learning Rate: 0.0005936907
2025-05-12 13:06:42,339 Train Loss: 0.0001456, Val Loss: 0.0004202
2025-05-12 13:06:42,339 Epoch 221/500
2025-05-12 13:06:55,005 Current Learning Rate: 0.0005906029
2025-05-12 13:06:55,005 Train Loss: 0.0001588, Val Loss: 0.0004328
2025-05-12 13:06:55,005 Epoch 222/500
2025-05-12 13:07:07,515 Current Learning Rate: 0.0005875115
2025-05-12 13:07:07,515 Train Loss: 0.0001487, Val Loss: 0.0004217
2025-05-12 13:07:07,515 Epoch 223/500
2025-05-12 13:07:20,045 Current Learning Rate: 0.0005844167
2025-05-12 13:07:20,047 Train Loss: 0.0001526, Val Loss: 0.0004251
2025-05-12 13:07:20,047 Epoch 224/500
2025-05-12 13:07:32,910 Current Learning Rate: 0.0005813186
2025-05-12 13:07:32,910 Train Loss: 0.0001570, Val Loss: 0.0004262
2025-05-12 13:07:32,910 Epoch 225/500
2025-05-12 13:07:45,314 Current Learning Rate: 0.0005782172
2025-05-12 13:07:45,315 Train Loss: 0.0001508, Val Loss: 0.0004236
2025-05-12 13:07:45,315 Epoch 226/500
2025-05-12 13:07:58,116 Current Learning Rate: 0.0005751128
2025-05-12 13:07:58,219 Train Loss: 0.0001503, Val Loss: 0.0004176
2025-05-12 13:07:58,220 Epoch 227/500
2025-05-12 13:08:10,756 Current Learning Rate: 0.0005720054
2025-05-12 13:08:10,756 Train Loss: 0.0001471, Val Loss: 0.0004368
2025-05-12 13:08:10,756 Epoch 228/500
2025-05-12 13:08:23,324 Current Learning Rate: 0.0005688951
2025-05-12 13:08:23,324 Train Loss: 0.0001545, Val Loss: 0.0004257
2025-05-12 13:08:23,325 Epoch 229/500
2025-05-12 13:08:36,055 Current Learning Rate: 0.0005657822
2025-05-12 13:08:36,055 Train Loss: 0.0001447, Val Loss: 0.0004208
2025-05-12 13:08:36,056 Epoch 230/500
2025-05-12 13:08:49,147 Current Learning Rate: 0.0005626666
2025-05-12 13:08:49,253 Train Loss: 0.0001405, Val Loss: 0.0004102
2025-05-12 13:08:49,254 Epoch 231/500
2025-05-12 13:09:02,134 Current Learning Rate: 0.0005595486
2025-05-12 13:09:02,135 Train Loss: 0.0001405, Val Loss: 0.0004155
2025-05-12 13:09:02,135 Epoch 232/500
2025-05-12 13:09:14,592 Current Learning Rate: 0.0005564282
2025-05-12 13:09:14,592 Train Loss: 0.0001480, Val Loss: 0.0004489
2025-05-12 13:09:14,592 Epoch 233/500
2025-05-12 13:09:27,011 Current Learning Rate: 0.0005533056
2025-05-12 13:09:27,104 Train Loss: 0.0001467, Val Loss: 0.0004046
2025-05-12 13:09:27,104 Epoch 234/500
2025-05-12 13:09:39,806 Current Learning Rate: 0.0005501809
2025-05-12 13:09:39,807 Train Loss: 0.0001385, Val Loss: 0.0004080
2025-05-12 13:09:39,807 Epoch 235/500
2025-05-12 13:09:52,408 Current Learning Rate: 0.0005470542
2025-05-12 13:09:52,418 Train Loss: 0.0001375, Val Loss: 0.0004161
2025-05-12 13:09:52,418 Epoch 236/500
2025-05-12 13:10:05,211 Current Learning Rate: 0.0005439256
2025-05-12 13:10:05,211 Train Loss: 0.0001441, Val Loss: 0.0004509
2025-05-12 13:10:05,211 Epoch 237/500
2025-05-12 13:10:18,038 Current Learning Rate: 0.0005407953
2025-05-12 13:10:18,038 Train Loss: 0.0001434, Val Loss: 0.0004178
2025-05-12 13:10:18,039 Epoch 238/500
2025-05-12 13:10:30,825 Current Learning Rate: 0.0005376634
2025-05-12 13:10:30,826 Train Loss: 0.0001373, Val Loss: 0.0004076
2025-05-12 13:10:30,826 Epoch 239/500
2025-05-12 13:10:43,728 Current Learning Rate: 0.0005345300
2025-05-12 13:10:43,837 Train Loss: 0.0001331, Val Loss: 0.0004044
2025-05-12 13:10:43,838 Epoch 240/500
2025-05-12 13:10:56,491 Current Learning Rate: 0.0005313953
2025-05-12 13:10:56,575 Train Loss: 0.0001315, Val Loss: 0.0004020
2025-05-12 13:10:56,576 Epoch 241/500
2025-05-12 13:11:09,187 Current Learning Rate: 0.0005282593
2025-05-12 13:11:09,188 Train Loss: 0.0001427, Val Loss: 0.0004171
2025-05-12 13:11:09,188 Epoch 242/500
2025-05-12 13:11:21,785 Current Learning Rate: 0.0005251222
2025-05-12 13:11:21,785 Train Loss: 0.0001397, Val Loss: 0.0004180
2025-05-12 13:11:21,786 Epoch 243/500
2025-05-12 13:11:34,260 Current Learning Rate: 0.0005219841
2025-05-12 13:11:34,261 Train Loss: 0.0001453, Val Loss: 0.0004065
2025-05-12 13:11:34,261 Epoch 244/500
2025-05-12 13:11:46,660 Current Learning Rate: 0.0005188451
2025-05-12 13:11:46,662 Train Loss: 0.0001368, Val Loss: 0.0004030
2025-05-12 13:11:46,663 Epoch 245/500
2025-05-12 13:11:59,196 Current Learning Rate: 0.0005157054
2025-05-12 13:11:59,197 Train Loss: 0.0001397, Val Loss: 0.0004177
2025-05-12 13:11:59,197 Epoch 246/500
2025-05-12 13:12:11,858 Current Learning Rate: 0.0005125650
2025-05-12 13:12:11,944 Train Loss: 0.0001412, Val Loss: 0.0004009
2025-05-12 13:12:11,944 Epoch 247/500
2025-05-12 13:12:24,578 Current Learning Rate: 0.0005094242
2025-05-12 13:12:24,683 Train Loss: 0.0001306, Val Loss: 0.0003980
2025-05-12 13:12:24,683 Epoch 248/500
2025-05-12 13:12:37,218 Current Learning Rate: 0.0005062830
2025-05-12 13:12:37,311 Train Loss: 0.0001303, Val Loss: 0.0003915
2025-05-12 13:12:37,311 Epoch 249/500
2025-05-12 13:12:49,784 Current Learning Rate: 0.0005031416
2025-05-12 13:12:49,785 Train Loss: 0.0001256, Val Loss: 0.0004014
2025-05-12 13:12:49,785 Epoch 250/500
2025-05-12 13:13:02,415 Current Learning Rate: 0.0005000000
2025-05-12 13:13:02,527 Saved periodic model at epoch 250 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/TurbL1_0512_LiNS2d_epoch_250.pth
2025-05-12 13:13:02,527 Train Loss: 0.0001267, Val Loss: 0.0003932
2025-05-12 13:13:02,527 Epoch 251/500
2025-05-12 13:13:15,173 Current Learning Rate: 0.0004968584
2025-05-12 13:13:15,173 Train Loss: 0.0001284, Val Loss: 0.0004020
2025-05-12 13:13:15,174 Epoch 252/500
2025-05-12 13:13:27,815 Current Learning Rate: 0.0004937170
2025-05-12 13:13:27,815 Train Loss: 0.0001282, Val Loss: 0.0003959
2025-05-12 13:13:27,816 Epoch 253/500
2025-05-12 13:13:40,831 Current Learning Rate: 0.0004905758
2025-05-12 13:13:40,832 Train Loss: 0.0001256, Val Loss: 0.0004010
2025-05-12 13:13:40,832 Epoch 254/500
2025-05-12 13:13:53,540 Current Learning Rate: 0.0004874350
2025-05-12 13:13:53,541 Train Loss: 0.0001294, Val Loss: 0.0003987
2025-05-12 13:13:53,541 Epoch 255/500
2025-05-12 13:14:06,294 Current Learning Rate: 0.0004842946
2025-05-12 13:14:06,294 Train Loss: 0.0001272, Val Loss: 0.0004086
2025-05-12 13:14:06,294 Epoch 256/500
2025-05-12 13:14:18,757 Current Learning Rate: 0.0004811549
2025-05-12 13:14:18,758 Train Loss: 0.0001311, Val Loss: 0.0003969
2025-05-12 13:14:18,758 Epoch 257/500
2025-05-12 13:14:31,601 Current Learning Rate: 0.0004780159
2025-05-12 13:14:31,601 Train Loss: 0.0001308, Val Loss: 0.0003998
2025-05-12 13:14:31,602 Epoch 258/500
2025-05-12 13:14:44,255 Current Learning Rate: 0.0004748778
2025-05-12 13:14:44,256 Train Loss: 0.0001262, Val Loss: 0.0004007
2025-05-12 13:14:44,256 Epoch 259/500
2025-05-12 13:14:56,793 Current Learning Rate: 0.0004717407
2025-05-12 13:14:56,914 Train Loss: 0.0001217, Val Loss: 0.0003895
2025-05-12 13:14:56,915 Epoch 260/500
2025-05-12 13:15:09,786 Current Learning Rate: 0.0004686047
2025-05-12 13:15:09,787 Train Loss: 0.0001251, Val Loss: 0.0003901
2025-05-12 13:15:09,787 Epoch 261/500
2025-05-12 13:15:22,487 Current Learning Rate: 0.0004654700
2025-05-12 13:15:22,488 Train Loss: 0.0001206, Val Loss: 0.0003908
2025-05-12 13:15:22,489 Epoch 262/500
2025-05-12 13:15:35,094 Current Learning Rate: 0.0004623366
2025-05-12 13:15:35,186 Train Loss: 0.0001206, Val Loss: 0.0003877
2025-05-12 13:15:35,186 Epoch 263/500
2025-05-12 13:15:47,716 Current Learning Rate: 0.0004592047
2025-05-12 13:15:47,716 Train Loss: 0.0001206, Val Loss: 0.0003916
2025-05-12 13:15:47,716 Epoch 264/500
2025-05-12 13:16:00,531 Current Learning Rate: 0.0004560744
2025-05-12 13:16:00,532 Train Loss: 0.0001225, Val Loss: 0.0003901
2025-05-12 13:16:00,532 Epoch 265/500
2025-05-12 13:16:13,165 Current Learning Rate: 0.0004529458
2025-05-12 13:16:13,252 Train Loss: 0.0001245, Val Loss: 0.0003871
2025-05-12 13:16:13,252 Epoch 266/500
2025-05-12 13:16:25,652 Current Learning Rate: 0.0004498191
2025-05-12 13:16:25,729 Train Loss: 0.0001210, Val Loss: 0.0003821
2025-05-12 13:16:25,730 Epoch 267/500
2025-05-12 13:16:38,104 Current Learning Rate: 0.0004466944
2025-05-12 13:16:38,105 Train Loss: 0.0001265, Val Loss: 0.0004002
2025-05-12 13:16:38,105 Epoch 268/500
2025-05-12 13:16:50,980 Current Learning Rate: 0.0004435718
2025-05-12 13:16:50,981 Train Loss: 0.0001199, Val Loss: 0.0003834
2025-05-12 13:16:50,981 Epoch 269/500
2025-05-12 13:17:03,559 Current Learning Rate: 0.0004404514
2025-05-12 13:17:03,560 Train Loss: 0.0001211, Val Loss: 0.0003877
2025-05-12 13:17:03,560 Epoch 270/500
2025-05-12 13:17:16,239 Current Learning Rate: 0.0004373334
2025-05-12 13:17:16,328 Train Loss: 0.0001158, Val Loss: 0.0003821
2025-05-12 13:17:16,329 Epoch 271/500
2025-05-12 13:17:28,959 Current Learning Rate: 0.0004342178
2025-05-12 13:17:29,063 Train Loss: 0.0001165, Val Loss: 0.0003801
2025-05-12 13:17:29,063 Epoch 272/500
2025-05-12 13:17:41,384 Current Learning Rate: 0.0004311049
2025-05-12 13:17:41,384 Train Loss: 0.0001157, Val Loss: 0.0003857
2025-05-12 13:17:41,384 Epoch 273/500
2025-05-12 13:17:53,585 Current Learning Rate: 0.0004279946
2025-05-12 13:17:53,586 Train Loss: 0.0001157, Val Loss: 0.0003959
2025-05-12 13:17:53,586 Epoch 274/500
2025-05-12 13:18:06,073 Current Learning Rate: 0.0004248872
2025-05-12 13:18:06,074 Train Loss: 0.0001205, Val Loss: 0.0003808
2025-05-12 13:18:06,074 Epoch 275/500
2025-05-12 13:18:18,535 Current Learning Rate: 0.0004217828
2025-05-12 13:18:18,535 Train Loss: 0.0001140, Val Loss: 0.0003822
2025-05-12 13:18:18,535 Epoch 276/500
2025-05-12 13:18:31,007 Current Learning Rate: 0.0004186814
2025-05-12 13:18:31,007 Train Loss: 0.0001200, Val Loss: 0.0003813
2025-05-12 13:18:31,008 Epoch 277/500
2025-05-12 13:18:43,564 Current Learning Rate: 0.0004155833
2025-05-12 13:18:43,564 Train Loss: 0.0001140, Val Loss: 0.0003816
2025-05-12 13:18:43,565 Epoch 278/500
2025-05-12 13:18:56,205 Current Learning Rate: 0.0004124885
2025-05-12 13:18:56,206 Train Loss: 0.0001170, Val Loss: 0.0003856
2025-05-12 13:18:56,206 Epoch 279/500
2025-05-12 13:19:08,767 Current Learning Rate: 0.0004093971
2025-05-12 13:19:08,768 Train Loss: 0.0001130, Val Loss: 0.0003805
2025-05-12 13:19:08,768 Epoch 280/500
2025-05-12 13:19:21,278 Current Learning Rate: 0.0004063093
2025-05-12 13:19:21,279 Train Loss: 0.0001122, Val Loss: 0.0003822
2025-05-12 13:19:21,279 Epoch 281/500
2025-05-12 13:19:33,990 Current Learning Rate: 0.0004032253
2025-05-12 13:19:33,991 Train Loss: 0.0001143, Val Loss: 0.0003820
2025-05-12 13:19:33,991 Epoch 282/500
2025-05-12 13:19:46,656 Current Learning Rate: 0.0004001450
2025-05-12 13:19:46,735 Train Loss: 0.0001100, Val Loss: 0.0003792
2025-05-12 13:19:46,735 Epoch 283/500
2025-05-12 13:19:59,168 Current Learning Rate: 0.0003970687
2025-05-12 13:19:59,168 Train Loss: 0.0001092, Val Loss: 0.0003862
2025-05-12 13:19:59,168 Epoch 284/500
2025-05-12 13:20:11,891 Current Learning Rate: 0.0003939964
2025-05-12 13:20:11,986 Train Loss: 0.0001119, Val Loss: 0.0003768
2025-05-12 13:20:11,986 Epoch 285/500
2025-05-12 13:20:24,610 Current Learning Rate: 0.0003909284
2025-05-12 13:20:24,610 Train Loss: 0.0001101, Val Loss: 0.0003841
2025-05-12 13:20:24,610 Epoch 286/500
2025-05-12 13:20:37,218 Current Learning Rate: 0.0003878646
2025-05-12 13:20:37,218 Train Loss: 0.0001123, Val Loss: 0.0003782
2025-05-12 13:20:37,218 Epoch 287/500
2025-05-12 13:20:49,621 Current Learning Rate: 0.0003848053
2025-05-12 13:20:49,621 Train Loss: 0.0001104, Val Loss: 0.0003871
2025-05-12 13:20:49,621 Epoch 288/500
2025-05-12 13:21:02,464 Current Learning Rate: 0.0003817505
2025-05-12 13:21:02,464 Train Loss: 0.0001119, Val Loss: 0.0003783
2025-05-12 13:21:02,465 Epoch 289/500
2025-05-12 13:21:15,088 Current Learning Rate: 0.0003787004
2025-05-12 13:21:15,186 Train Loss: 0.0001074, Val Loss: 0.0003716
2025-05-12 13:21:15,186 Epoch 290/500
2025-05-12 13:21:27,730 Current Learning Rate: 0.0003756551
2025-05-12 13:21:27,730 Train Loss: 0.0001136, Val Loss: 0.0003736
2025-05-12 13:21:27,730 Epoch 291/500
2025-05-12 13:21:40,268 Current Learning Rate: 0.0003726146
2025-05-12 13:21:40,269 Train Loss: 0.0001055, Val Loss: 0.0003742
2025-05-12 13:21:40,269 Epoch 292/500
2025-05-12 13:21:52,913 Current Learning Rate: 0.0003695792
2025-05-12 13:21:53,005 Train Loss: 0.0001020, Val Loss: 0.0003678
2025-05-12 13:21:53,005 Epoch 293/500
2025-05-12 13:22:05,545 Current Learning Rate: 0.0003665490
2025-05-12 13:22:05,545 Train Loss: 0.0001054, Val Loss: 0.0003705
2025-05-12 13:22:05,545 Epoch 294/500
2025-05-12 13:22:18,115 Current Learning Rate: 0.0003635240
2025-05-12 13:22:18,116 Train Loss: 0.0001071, Val Loss: 0.0003704
2025-05-12 13:22:18,116 Epoch 295/500
2025-05-12 13:22:30,713 Current Learning Rate: 0.0003605044
2025-05-12 13:22:30,714 Train Loss: 0.0001077, Val Loss: 0.0003700
2025-05-12 13:22:30,714 Epoch 296/500
2025-05-12 13:22:43,217 Current Learning Rate: 0.0003574904
2025-05-12 13:22:43,217 Train Loss: 0.0001056, Val Loss: 0.0003712
2025-05-12 13:22:43,217 Epoch 297/500
2025-05-12 13:22:55,705 Current Learning Rate: 0.0003544819
2025-05-12 13:22:55,705 Train Loss: 0.0001054, Val Loss: 0.0003694
2025-05-12 13:22:55,706 Epoch 298/500
2025-05-12 13:23:08,322 Current Learning Rate: 0.0003514792
2025-05-12 13:23:08,407 Train Loss: 0.0001020, Val Loss: 0.0003664
2025-05-12 13:23:08,408 Epoch 299/500
2025-05-12 13:23:20,449 Current Learning Rate: 0.0003484824
2025-05-12 13:23:20,450 Train Loss: 0.0001062, Val Loss: 0.0003699
2025-05-12 13:23:20,450 Epoch 300/500
2025-05-12 13:23:33,048 Current Learning Rate: 0.0003454915
2025-05-12 13:23:33,142 Saved periodic model at epoch 300 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/TurbL1_0512_LiNS2d_epoch_300.pth
2025-05-12 13:23:33,142 Train Loss: 0.0001041, Val Loss: 0.0003672
2025-05-12 13:23:33,142 Epoch 301/500
2025-05-12 13:23:45,491 Current Learning Rate: 0.0003425067
2025-05-12 13:23:45,492 Train Loss: 0.0001012, Val Loss: 0.0003721
2025-05-12 13:23:45,492 Epoch 302/500
2025-05-12 13:23:58,232 Current Learning Rate: 0.0003395282
2025-05-12 13:23:58,332 Train Loss: 0.0001022, Val Loss: 0.0003630
2025-05-12 13:23:58,333 Epoch 303/500
2025-05-12 13:24:10,631 Current Learning Rate: 0.0003365560
2025-05-12 13:24:10,632 Train Loss: 0.0001020, Val Loss: 0.0003661
2025-05-12 13:24:10,632 Epoch 304/500
2025-05-12 13:24:23,185 Current Learning Rate: 0.0003335902
2025-05-12 13:24:23,185 Train Loss: 0.0000988, Val Loss: 0.0003654
2025-05-12 13:24:23,186 Epoch 305/500
2025-05-12 13:24:35,853 Current Learning Rate: 0.0003306310
2025-05-12 13:24:35,854 Train Loss: 0.0001034, Val Loss: 0.0003674
2025-05-12 13:24:35,854 Epoch 306/500
2025-05-12 13:24:48,543 Current Learning Rate: 0.0003276785
2025-05-12 13:24:48,543 Train Loss: 0.0000993, Val Loss: 0.0003697
2025-05-12 13:24:48,543 Epoch 307/500
2025-05-12 13:25:01,126 Current Learning Rate: 0.0003247328
2025-05-12 13:25:01,127 Train Loss: 0.0000991, Val Loss: 0.0003666
2025-05-12 13:25:01,127 Epoch 308/500
2025-05-12 13:25:13,873 Current Learning Rate: 0.0003217941
2025-05-12 13:25:13,883 Train Loss: 0.0000997, Val Loss: 0.0003690
2025-05-12 13:25:13,883 Epoch 309/500
2025-05-12 13:25:26,552 Current Learning Rate: 0.0003188623
2025-05-12 13:25:26,553 Train Loss: 0.0001013, Val Loss: 0.0003655
2025-05-12 13:25:26,553 Epoch 310/500
2025-05-12 13:25:39,116 Current Learning Rate: 0.0003159377
2025-05-12 13:25:39,117 Train Loss: 0.0001017, Val Loss: 0.0003658
2025-05-12 13:25:39,117 Epoch 311/500
2025-05-12 13:25:51,793 Current Learning Rate: 0.0003130204
2025-05-12 13:25:51,893 Train Loss: 0.0000975, Val Loss: 0.0003605
2025-05-12 13:25:51,893 Epoch 312/500
2025-05-12 13:26:04,409 Current Learning Rate: 0.0003101105
2025-05-12 13:26:04,410 Train Loss: 0.0000967, Val Loss: 0.0003649
2025-05-12 13:26:04,410 Epoch 313/500
2025-05-12 13:26:17,226 Current Learning Rate: 0.0003072080
2025-05-12 13:26:17,226 Train Loss: 0.0000967, Val Loss: 0.0003608
2025-05-12 13:26:17,226 Epoch 314/500
2025-05-12 13:26:29,922 Current Learning Rate: 0.0003043132
2025-05-12 13:26:29,922 Train Loss: 0.0000969, Val Loss: 0.0003643
2025-05-12 13:26:29,923 Epoch 315/500
2025-05-12 13:26:42,597 Current Learning Rate: 0.0003014261
2025-05-12 13:26:42,598 Train Loss: 0.0000960, Val Loss: 0.0003609
2025-05-12 13:26:42,598 Epoch 316/500
2025-05-12 13:26:55,227 Current Learning Rate: 0.0002985468
2025-05-12 13:26:55,329 Train Loss: 0.0000963, Val Loss: 0.0003603
2025-05-12 13:26:55,329 Epoch 317/500
2025-05-12 13:27:07,749 Current Learning Rate: 0.0002956755
2025-05-12 13:27:07,750 Train Loss: 0.0000953, Val Loss: 0.0003633
2025-05-12 13:27:07,750 Epoch 318/500
2025-05-12 13:27:20,133 Current Learning Rate: 0.0002928122
2025-05-12 13:27:20,133 Train Loss: 0.0000979, Val Loss: 0.0003626
2025-05-12 13:27:20,133 Epoch 319/500
2025-05-12 13:27:32,971 Current Learning Rate: 0.0002899571
2025-05-12 13:27:32,971 Train Loss: 0.0000938, Val Loss: 0.0003610
2025-05-12 13:27:32,973 Epoch 320/500
2025-05-12 13:27:45,818 Current Learning Rate: 0.0002871104
2025-05-12 13:27:45,819 Train Loss: 0.0000970, Val Loss: 0.0003609
2025-05-12 13:27:45,820 Epoch 321/500
2025-05-12 13:27:58,666 Current Learning Rate: 0.0002842720
2025-05-12 13:27:58,753 Train Loss: 0.0000954, Val Loss: 0.0003571
2025-05-12 13:27:58,753 Epoch 322/500
2025-05-12 13:28:11,461 Current Learning Rate: 0.0002814421
2025-05-12 13:28:11,462 Train Loss: 0.0000956, Val Loss: 0.0003608
2025-05-12 13:28:11,462 Epoch 323/500
2025-05-12 13:28:24,412 Current Learning Rate: 0.0002786209
2025-05-12 13:28:24,495 Train Loss: 0.0000941, Val Loss: 0.0003558
2025-05-12 13:28:24,495 Epoch 324/500
2025-05-12 13:28:37,301 Current Learning Rate: 0.0002758084
2025-05-12 13:28:37,301 Train Loss: 0.0000926, Val Loss: 0.0003564
2025-05-12 13:28:37,301 Epoch 325/500
2025-05-12 13:28:49,903 Current Learning Rate: 0.0002730048
2025-05-12 13:28:49,993 Train Loss: 0.0000939, Val Loss: 0.0003543
2025-05-12 13:28:49,993 Epoch 326/500
2025-05-12 13:29:02,775 Current Learning Rate: 0.0002702101
2025-05-12 13:29:02,886 Train Loss: 0.0000915, Val Loss: 0.0003516
2025-05-12 13:29:02,886 Epoch 327/500
2025-05-12 13:29:15,805 Current Learning Rate: 0.0002674245
2025-05-12 13:29:15,805 Train Loss: 0.0000912, Val Loss: 0.0003536
2025-05-12 13:29:15,805 Epoch 328/500
2025-05-12 13:29:28,461 Current Learning Rate: 0.0002646480
2025-05-12 13:29:28,462 Train Loss: 0.0000927, Val Loss: 0.0003537
2025-05-12 13:29:28,462 Epoch 329/500
2025-05-12 13:29:41,040 Current Learning Rate: 0.0002618809
2025-05-12 13:29:41,041 Train Loss: 0.0000907, Val Loss: 0.0003560
2025-05-12 13:29:41,041 Epoch 330/500
2025-05-12 13:29:53,871 Current Learning Rate: 0.0002591232
2025-05-12 13:29:53,871 Train Loss: 0.0000898, Val Loss: 0.0003578
2025-05-12 13:29:53,871 Epoch 331/500
2025-05-12 13:30:06,463 Current Learning Rate: 0.0002563749
2025-05-12 13:30:06,464 Train Loss: 0.0000917, Val Loss: 0.0003539
2025-05-12 13:30:06,464 Epoch 332/500
2025-05-12 13:30:18,845 Current Learning Rate: 0.0002536363
2025-05-12 13:30:18,846 Train Loss: 0.0000884, Val Loss: 0.0003540
2025-05-12 13:30:18,846 Epoch 333/500
2025-05-12 13:30:31,355 Current Learning Rate: 0.0002509074
2025-05-12 13:30:31,355 Train Loss: 0.0000908, Val Loss: 0.0003549
2025-05-12 13:30:31,355 Epoch 334/500
2025-05-12 13:30:43,850 Current Learning Rate: 0.0002481884
2025-05-12 13:30:43,850 Train Loss: 0.0000893, Val Loss: 0.0003544
2025-05-12 13:30:43,851 Epoch 335/500
2025-05-12 13:30:56,355 Current Learning Rate: 0.0002454793
2025-05-12 13:30:56,355 Train Loss: 0.0000904, Val Loss: 0.0003557
2025-05-12 13:30:56,355 Epoch 336/500
2025-05-12 13:31:08,821 Current Learning Rate: 0.0002427802
2025-05-12 13:31:08,822 Train Loss: 0.0000924, Val Loss: 0.0003518
2025-05-12 13:31:08,822 Epoch 337/500
2025-05-12 13:31:21,661 Current Learning Rate: 0.0002400913
2025-05-12 13:31:21,662 Train Loss: 0.0000907, Val Loss: 0.0003555
2025-05-12 13:31:21,662 Epoch 338/500
2025-05-12 13:31:34,098 Current Learning Rate: 0.0002374127
2025-05-12 13:31:34,237 Train Loss: 0.0000904, Val Loss: 0.0003500
2025-05-12 13:31:34,238 Epoch 339/500
2025-05-12 13:31:47,191 Current Learning Rate: 0.0002347444
2025-05-12 13:31:47,192 Train Loss: 0.0000905, Val Loss: 0.0003500
2025-05-12 13:31:47,192 Epoch 340/500
2025-05-12 13:32:10,332 Current Learning Rate: 0.0002320866
2025-05-12 13:32:10,445 Train Loss: 0.0000859, Val Loss: 0.0003485
2025-05-12 13:32:10,445 Epoch 341/500
2025-05-12 13:32:32,983 Current Learning Rate: 0.0002294394
2025-05-12 13:32:33,122 Train Loss: 0.0000878, Val Loss: 0.0003483
2025-05-12 13:32:33,123 Epoch 342/500
2025-05-12 13:32:56,449 Current Learning Rate: 0.0002268028
2025-05-12 13:32:56,450 Train Loss: 0.0000876, Val Loss: 0.0003498
2025-05-12 13:32:56,450 Epoch 343/500
2025-05-12 13:33:18,677 Current Learning Rate: 0.0002241771
2025-05-12 13:33:18,677 Train Loss: 0.0000860, Val Loss: 0.0003527
2025-05-12 13:33:18,677 Epoch 344/500
2025-05-12 13:33:41,009 Current Learning Rate: 0.0002215622
2025-05-12 13:33:41,010 Train Loss: 0.0000883, Val Loss: 0.0003508
2025-05-12 13:33:41,010 Epoch 345/500
2025-05-12 13:34:04,889 Current Learning Rate: 0.0002189583
2025-05-12 13:34:04,889 Train Loss: 0.0000858, Val Loss: 0.0003495
2025-05-12 13:34:04,890 Epoch 346/500
2025-05-12 13:34:27,657 Current Learning Rate: 0.0002163655
2025-05-12 13:34:27,658 Train Loss: 0.0000863, Val Loss: 0.0003517
2025-05-12 13:34:27,658 Epoch 347/500
2025-05-12 13:34:50,165 Current Learning Rate: 0.0002137839
2025-05-12 13:34:50,252 Train Loss: 0.0000862, Val Loss: 0.0003462
2025-05-12 13:34:50,253 Epoch 348/500
2025-05-12 13:35:13,367 Current Learning Rate: 0.0002112136
2025-05-12 13:35:13,368 Train Loss: 0.0000863, Val Loss: 0.0003514
2025-05-12 13:35:13,368 Epoch 349/500
2025-05-12 13:35:35,630 Current Learning Rate: 0.0002086548
2025-05-12 13:35:35,737 Train Loss: 0.0000845, Val Loss: 0.0003450
2025-05-12 13:35:35,738 Epoch 350/500
2025-05-12 13:35:58,451 Current Learning Rate: 0.0002061074
2025-05-12 13:35:58,550 Saved periodic model at epoch 350 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/TurbL1_0512_LiNS2d_epoch_350.pth
2025-05-12 13:35:58,550 Train Loss: 0.0000843, Val Loss: 0.0003497
2025-05-12 13:35:58,550 Epoch 351/500
2025-05-12 13:36:21,933 Current Learning Rate: 0.0002035716
2025-05-12 13:36:21,934 Train Loss: 0.0000849, Val Loss: 0.0003455
2025-05-12 13:36:21,934 Epoch 352/500
2025-05-12 13:36:44,139 Current Learning Rate: 0.0002010475
2025-05-12 13:36:44,139 Train Loss: 0.0000852, Val Loss: 0.0003466
2025-05-12 13:36:44,139 Epoch 353/500
2025-05-12 13:37:07,680 Current Learning Rate: 0.0001985352
2025-05-12 13:37:07,780 Train Loss: 0.0000869, Val Loss: 0.0003433
2025-05-12 13:37:07,780 Epoch 354/500
2025-05-12 13:37:30,331 Current Learning Rate: 0.0001960349
2025-05-12 13:37:30,331 Train Loss: 0.0000828, Val Loss: 0.0003445
2025-05-12 13:37:30,334 Epoch 355/500
2025-05-12 13:37:52,532 Current Learning Rate: 0.0001935465
2025-05-12 13:37:52,623 Train Loss: 0.0000815, Val Loss: 0.0003420
2025-05-12 13:37:52,623 Epoch 356/500
2025-05-12 13:38:15,936 Current Learning Rate: 0.0001910702
2025-05-12 13:38:15,937 Train Loss: 0.0000829, Val Loss: 0.0003440
2025-05-12 13:38:15,937 Epoch 357/500
2025-05-12 13:38:38,598 Current Learning Rate: 0.0001886061
2025-05-12 13:38:38,598 Train Loss: 0.0000822, Val Loss: 0.0003458
2025-05-12 13:38:38,598 Epoch 358/500
2025-05-12 13:39:00,964 Current Learning Rate: 0.0001861543
2025-05-12 13:39:00,964 Train Loss: 0.0000819, Val Loss: 0.0003441
2025-05-12 13:39:00,964 Epoch 359/500
2025-05-12 13:39:24,727 Current Learning Rate: 0.0001837149
2025-05-12 13:39:24,727 Train Loss: 0.0000854, Val Loss: 0.0003436
2025-05-12 13:39:24,728 Epoch 360/500
2025-05-12 13:39:47,475 Current Learning Rate: 0.0001812880
2025-05-12 13:39:47,475 Train Loss: 0.0000822, Val Loss: 0.0003452
2025-05-12 13:39:47,475 Epoch 361/500
2025-05-12 13:40:10,122 Current Learning Rate: 0.0001788737
2025-05-12 13:40:10,123 Train Loss: 0.0000814, Val Loss: 0.0003444
2025-05-12 13:40:10,123 Epoch 362/500
2025-05-12 13:40:33,544 Current Learning Rate: 0.0001764720
2025-05-12 13:40:33,544 Train Loss: 0.0000822, Val Loss: 0.0003461
2025-05-12 13:40:33,545 Epoch 363/500
2025-05-12 13:40:56,418 Current Learning Rate: 0.0001740831
2025-05-12 13:40:56,418 Train Loss: 0.0000811, Val Loss: 0.0003446
2025-05-12 13:40:56,418 Epoch 364/500
2025-05-12 13:41:20,147 Current Learning Rate: 0.0001717071
2025-05-12 13:41:20,296 Train Loss: 0.0000806, Val Loss: 0.0003417
2025-05-12 13:41:20,297 Epoch 365/500
2025-05-12 13:41:44,101 Current Learning Rate: 0.0001693441
2025-05-12 13:41:44,102 Train Loss: 0.0000794, Val Loss: 0.0003432
2025-05-12 13:41:44,103 Epoch 366/500
2025-05-12 13:42:06,915 Current Learning Rate: 0.0001669941
2025-05-12 13:42:06,916 Train Loss: 0.0000805, Val Loss: 0.0003418
2025-05-12 13:42:06,916 Epoch 367/500
2025-05-12 13:42:30,534 Current Learning Rate: 0.0001646572
2025-05-12 13:42:30,632 Train Loss: 0.0000796, Val Loss: 0.0003396
2025-05-12 13:42:30,632 Epoch 368/500
2025-05-12 13:42:53,552 Current Learning Rate: 0.0001623336
2025-05-12 13:42:53,556 Train Loss: 0.0000782, Val Loss: 0.0003404
2025-05-12 13:42:53,556 Epoch 369/500
2025-05-12 13:43:16,411 Current Learning Rate: 0.0001600233
2025-05-12 13:43:16,412 Train Loss: 0.0000808, Val Loss: 0.0003400
2025-05-12 13:43:16,412 Epoch 370/500
2025-05-12 13:43:39,851 Current Learning Rate: 0.0001577264
2025-05-12 13:43:39,851 Train Loss: 0.0000805, Val Loss: 0.0003409
2025-05-12 13:43:39,851 Epoch 371/500
2025-05-12 13:44:02,081 Current Learning Rate: 0.0001554431
2025-05-12 13:44:02,082 Train Loss: 0.0000813, Val Loss: 0.0003398
2025-05-12 13:44:02,082 Epoch 372/500
2025-05-12 13:44:24,223 Current Learning Rate: 0.0001531733
2025-05-12 13:44:24,223 Train Loss: 0.0000785, Val Loss: 0.0003401
2025-05-12 13:44:24,224 Epoch 373/500
2025-05-12 13:44:48,087 Current Learning Rate: 0.0001509173
2025-05-12 13:44:48,224 Train Loss: 0.0000774, Val Loss: 0.0003390
2025-05-12 13:44:48,224 Epoch 374/500
2025-05-12 13:45:10,827 Current Learning Rate: 0.0001486750
2025-05-12 13:45:10,828 Train Loss: 0.0000814, Val Loss: 0.0003400
2025-05-12 13:45:10,828 Epoch 375/500
2025-05-12 13:45:34,255 Current Learning Rate: 0.0001464466
2025-05-12 13:45:34,255 Train Loss: 0.0000775, Val Loss: 0.0003422
2025-05-12 13:45:34,255 Epoch 376/500
2025-05-12 13:45:57,775 Current Learning Rate: 0.0001442322
2025-05-12 13:45:57,775 Train Loss: 0.0000789, Val Loss: 0.0003390
2025-05-12 13:45:57,775 Epoch 377/500
2025-05-12 13:46:20,912 Current Learning Rate: 0.0001420318
2025-05-12 13:46:21,044 Train Loss: 0.0000764, Val Loss: 0.0003380
2025-05-12 13:46:21,045 Epoch 378/500
2025-05-12 13:46:44,521 Current Learning Rate: 0.0001398455
2025-05-12 13:46:44,636 Train Loss: 0.0000754, Val Loss: 0.0003374
2025-05-12 13:46:44,636 Epoch 379/500
2025-05-12 13:47:06,958 Current Learning Rate: 0.0001376734
2025-05-12 13:47:06,959 Train Loss: 0.0000766, Val Loss: 0.0003389
2025-05-12 13:47:06,959 Epoch 380/500
2025-05-12 13:47:29,492 Current Learning Rate: 0.0001355157
2025-05-12 13:47:29,493 Train Loss: 0.0000776, Val Loss: 0.0003381
2025-05-12 13:47:29,493 Epoch 381/500
2025-05-12 13:47:53,388 Current Learning Rate: 0.0001333723
2025-05-12 13:47:53,389 Train Loss: 0.0000780, Val Loss: 0.0003380
2025-05-12 13:47:53,389 Epoch 382/500
2025-05-12 13:48:16,052 Current Learning Rate: 0.0001312434
2025-05-12 13:48:16,053 Train Loss: 0.0000766, Val Loss: 0.0003376
2025-05-12 13:48:16,053 Epoch 383/500
2025-05-12 13:48:39,608 Current Learning Rate: 0.0001291291
2025-05-12 13:48:39,741 Train Loss: 0.0000773, Val Loss: 0.0003368
2025-05-12 13:48:39,742 Epoch 384/500
2025-05-12 13:49:03,710 Current Learning Rate: 0.0001270294
2025-05-12 13:49:03,835 Train Loss: 0.0000792, Val Loss: 0.0003363
2025-05-12 13:49:03,835 Epoch 385/500
2025-05-12 13:49:26,546 Current Learning Rate: 0.0001249445
2025-05-12 13:49:26,547 Train Loss: 0.0000754, Val Loss: 0.0003364
2025-05-12 13:49:26,547 Epoch 386/500
2025-05-12 13:49:50,241 Current Learning Rate: 0.0001228743
2025-05-12 13:49:50,241 Train Loss: 0.0000758, Val Loss: 0.0003372
2025-05-12 13:49:50,242 Epoch 387/500
2025-05-12 13:50:14,021 Current Learning Rate: 0.0001208190
2025-05-12 13:50:14,026 Train Loss: 0.0000751, Val Loss: 0.0003363
2025-05-12 13:50:14,026 Epoch 388/500
2025-05-12 13:50:37,016 Current Learning Rate: 0.0001187787
2025-05-12 13:50:37,168 Train Loss: 0.0000755, Val Loss: 0.0003361
2025-05-12 13:50:37,168 Epoch 389/500
2025-05-12 13:51:01,815 Current Learning Rate: 0.0001167535
2025-05-12 13:51:01,815 Train Loss: 0.0000749, Val Loss: 0.0003362
2025-05-12 13:51:01,815 Epoch 390/500
2025-05-12 13:51:24,593 Current Learning Rate: 0.0001147434
2025-05-12 13:51:24,729 Train Loss: 0.0000757, Val Loss: 0.0003358
2025-05-12 13:51:24,729 Epoch 391/500
2025-05-12 13:51:47,589 Current Learning Rate: 0.0001127485
2025-05-12 13:51:47,590 Train Loss: 0.0000750, Val Loss: 0.0003369
2025-05-12 13:51:47,590 Epoch 392/500
2025-05-12 13:52:11,275 Current Learning Rate: 0.0001107688
2025-05-12 13:52:11,428 Train Loss: 0.0000767, Val Loss: 0.0003339
2025-05-12 13:52:11,428 Epoch 393/500
2025-05-12 13:52:34,613 Current Learning Rate: 0.0001088046
2025-05-12 13:52:34,613 Train Loss: 0.0000744, Val Loss: 0.0003355
2025-05-12 13:52:34,613 Epoch 394/500
2025-05-12 13:52:57,846 Current Learning Rate: 0.0001068558
2025-05-12 13:52:57,846 Train Loss: 0.0000751, Val Loss: 0.0003350
2025-05-12 13:52:57,846 Epoch 395/500
2025-05-12 13:53:21,506 Current Learning Rate: 0.0001049225
2025-05-12 13:53:21,620 Train Loss: 0.0000758, Val Loss: 0.0003337
2025-05-12 13:53:21,620 Epoch 396/500
2025-05-12 13:53:43,482 Current Learning Rate: 0.0001030048
2025-05-12 13:53:43,605 Train Loss: 0.0000734, Val Loss: 0.0003336
2025-05-12 13:53:43,605 Epoch 397/500
2025-05-12 13:54:07,055 Current Learning Rate: 0.0001011028
2025-05-12 13:54:07,179 Train Loss: 0.0000732, Val Loss: 0.0003336
2025-05-12 13:54:07,179 Epoch 398/500
2025-05-12 13:54:29,780 Current Learning Rate: 0.0000992165
2025-05-12 13:54:29,781 Train Loss: 0.0000728, Val Loss: 0.0003345
2025-05-12 13:54:29,781 Epoch 399/500
2025-05-12 13:54:52,194 Current Learning Rate: 0.0000973461
2025-05-12 13:54:52,194 Train Loss: 0.0000747, Val Loss: 0.0003345
2025-05-12 13:54:52,194 Epoch 400/500
2025-05-12 13:55:16,028 Current Learning Rate: 0.0000954915
2025-05-12 13:55:16,131 Saved periodic model at epoch 400 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/TurbL1_0512_LiNS2d_epoch_400.pth
2025-05-12 13:55:16,131 Train Loss: 0.0000734, Val Loss: 0.0003340
2025-05-12 13:55:16,131 Epoch 401/500
2025-05-12 13:55:38,954 Current Learning Rate: 0.0000936529
2025-05-12 13:55:39,115 Train Loss: 0.0000731, Val Loss: 0.0003328
2025-05-12 13:55:39,115 Epoch 402/500
2025-05-12 13:56:02,369 Current Learning Rate: 0.0000918304
2025-05-12 13:56:02,370 Train Loss: 0.0000746, Val Loss: 0.0003334
2025-05-12 13:56:02,371 Epoch 403/500
2025-05-12 13:56:26,635 Current Learning Rate: 0.0000900239
2025-05-12 13:56:26,784 Train Loss: 0.0000729, Val Loss: 0.0003324
2025-05-12 13:56:26,785 Epoch 404/500
2025-05-12 13:56:49,783 Current Learning Rate: 0.0000882337
2025-05-12 13:56:49,903 Train Loss: 0.0000729, Val Loss: 0.0003317
2025-05-12 13:56:49,903 Epoch 405/500
2025-05-12 13:57:13,780 Current Learning Rate: 0.0000864597
2025-05-12 13:57:13,917 Train Loss: 0.0000741, Val Loss: 0.0003316
2025-05-12 13:57:13,918 Epoch 406/500
2025-05-12 13:57:37,729 Current Learning Rate: 0.0000847021
2025-05-12 13:57:37,835 Train Loss: 0.0000734, Val Loss: 0.0003312
2025-05-12 13:57:37,835 Epoch 407/500
2025-05-12 13:58:00,708 Current Learning Rate: 0.0000829608
2025-05-12 13:58:00,708 Train Loss: 0.0000729, Val Loss: 0.0003323
2025-05-12 13:58:00,708 Epoch 408/500
2025-05-12 13:58:24,163 Current Learning Rate: 0.0000812360
2025-05-12 13:58:24,163 Train Loss: 0.0000729, Val Loss: 0.0003335
2025-05-12 13:58:24,164 Epoch 409/500
2025-05-12 13:58:47,739 Current Learning Rate: 0.0000795277
2025-05-12 13:58:47,739 Train Loss: 0.0000722, Val Loss: 0.0003325
2025-05-12 13:58:47,740 Epoch 410/500
2025-05-12 13:59:10,782 Current Learning Rate: 0.0000778360
2025-05-12 13:59:10,782 Train Loss: 0.0000721, Val Loss: 0.0003317
2025-05-12 13:59:10,782 Epoch 411/500
2025-05-12 13:59:34,936 Current Learning Rate: 0.0000761610
2025-05-12 13:59:35,052 Train Loss: 0.0000725, Val Loss: 0.0003303
2025-05-12 13:59:35,053 Epoch 412/500
2025-05-12 13:59:58,714 Current Learning Rate: 0.0000745028
2025-05-12 13:59:58,715 Train Loss: 0.0000721, Val Loss: 0.0003307
2025-05-12 13:59:58,715 Epoch 413/500
2025-05-12 14:00:21,679 Current Learning Rate: 0.0000728613
2025-05-12 14:00:21,679 Train Loss: 0.0000716, Val Loss: 0.0003309
2025-05-12 14:00:21,679 Epoch 414/500
2025-05-12 14:00:46,082 Current Learning Rate: 0.0000712367
2025-05-12 14:00:46,082 Train Loss: 0.0000723, Val Loss: 0.0003310
2025-05-12 14:00:46,091 Epoch 415/500
2025-05-12 14:01:09,245 Current Learning Rate: 0.0000696290
2025-05-12 14:01:09,391 Train Loss: 0.0000718, Val Loss: 0.0003299
2025-05-12 14:01:09,391 Epoch 416/500
2025-05-12 14:01:32,771 Current Learning Rate: 0.0000680383
2025-05-12 14:01:32,772 Train Loss: 0.0000714, Val Loss: 0.0003300
2025-05-12 14:01:32,772 Epoch 417/500
2025-05-12 14:01:56,464 Current Learning Rate: 0.0000664646
2025-05-12 14:01:56,467 Train Loss: 0.0000716, Val Loss: 0.0003302
2025-05-12 14:01:56,467 Epoch 418/500
2025-05-12 14:02:18,763 Current Learning Rate: 0.0000649081
2025-05-12 14:02:18,879 Train Loss: 0.0000725, Val Loss: 0.0003298
2025-05-12 14:02:18,880 Epoch 419/500
2025-05-12 14:02:42,335 Current Learning Rate: 0.0000633688
2025-05-12 14:02:42,448 Train Loss: 0.0000717, Val Loss: 0.0003298
2025-05-12 14:02:42,448 Epoch 420/500
2025-05-12 14:03:05,108 Current Learning Rate: 0.0000618467
2025-05-12 14:03:05,108 Train Loss: 0.0000695, Val Loss: 0.0003299
2025-05-12 14:03:05,109 Epoch 421/500
2025-05-12 14:03:27,552 Current Learning Rate: 0.0000603418
2025-05-12 14:03:27,661 Train Loss: 0.0000702, Val Loss: 0.0003294
2025-05-12 14:03:27,661 Epoch 422/500
2025-05-12 14:03:51,171 Current Learning Rate: 0.0000588544
2025-05-12 14:03:51,282 Train Loss: 0.0000712, Val Loss: 0.0003290
2025-05-12 14:03:51,282 Epoch 423/500
2025-05-12 14:04:13,864 Current Learning Rate: 0.0000573843
2025-05-12 14:04:13,967 Train Loss: 0.0000715, Val Loss: 0.0003288
2025-05-12 14:04:13,968 Epoch 424/500
2025-05-12 14:04:36,145 Current Learning Rate: 0.0000559318
2025-05-12 14:04:36,146 Train Loss: 0.0000706, Val Loss: 0.0003296
2025-05-12 14:04:36,147 Epoch 425/500
2025-05-12 14:04:59,843 Current Learning Rate: 0.0000544967
2025-05-12 14:04:59,962 Train Loss: 0.0000699, Val Loss: 0.0003285
2025-05-12 14:04:59,962 Epoch 426/500
2025-05-12 14:05:22,111 Current Learning Rate: 0.0000530793
2025-05-12 14:05:22,111 Train Loss: 0.0000709, Val Loss: 0.0003289
2025-05-12 14:05:22,112 Epoch 427/500
2025-05-12 14:05:44,946 Current Learning Rate: 0.0000516795
2025-05-12 14:05:44,947 Train Loss: 0.0000705, Val Loss: 0.0003289
2025-05-12 14:05:44,947 Epoch 428/500
2025-05-12 14:06:08,609 Current Learning Rate: 0.0000502974
2025-05-12 14:06:08,610 Train Loss: 0.0000706, Val Loss: 0.0003287
2025-05-12 14:06:08,610 Epoch 429/500
2025-05-12 14:06:31,070 Current Learning Rate: 0.0000489330
2025-05-12 14:06:31,071 Train Loss: 0.0000690, Val Loss: 0.0003294
2025-05-12 14:06:31,072 Epoch 430/500
2025-05-12 14:06:54,783 Current Learning Rate: 0.0000475865
2025-05-12 14:06:54,784 Train Loss: 0.0000703, Val Loss: 0.0003286
2025-05-12 14:06:54,784 Epoch 431/500
2025-05-12 14:07:18,104 Current Learning Rate: 0.0000462578
2025-05-12 14:07:18,104 Train Loss: 0.0000692, Val Loss: 0.0003287
2025-05-12 14:07:18,105 Epoch 432/500
2025-05-12 14:07:39,983 Current Learning Rate: 0.0000449470
2025-05-12 14:07:39,984 Train Loss: 0.0000702, Val Loss: 0.0003290
2025-05-12 14:07:39,984 Epoch 433/500
2025-05-12 14:08:03,354 Current Learning Rate: 0.0000436542
2025-05-12 14:08:03,487 Train Loss: 0.0000701, Val Loss: 0.0003280
2025-05-12 14:08:03,488 Epoch 434/500
2025-05-12 14:08:26,197 Current Learning Rate: 0.0000423794
2025-05-12 14:08:26,292 Train Loss: 0.0000695, Val Loss: 0.0003277
2025-05-12 14:08:26,292 Epoch 435/500
2025-05-12 14:08:48,471 Current Learning Rate: 0.0000411227
2025-05-12 14:08:48,471 Train Loss: 0.0000698, Val Loss: 0.0003279
2025-05-12 14:08:48,471 Epoch 436/500
2025-05-12 14:09:12,208 Current Learning Rate: 0.0000398841
2025-05-12 14:09:12,209 Train Loss: 0.0000689, Val Loss: 0.0003285
2025-05-12 14:09:12,209 Epoch 437/500
2025-05-12 14:09:34,680 Current Learning Rate: 0.0000386636
2025-05-12 14:09:34,680 Train Loss: 0.0000686, Val Loss: 0.0003282
2025-05-12 14:09:34,680 Epoch 438/500
2025-05-12 14:09:57,888 Current Learning Rate: 0.0000374614
2025-05-12 14:09:57,971 Train Loss: 0.0000688, Val Loss: 0.0003271
2025-05-12 14:09:57,971 Epoch 439/500
2025-05-12 14:10:21,520 Current Learning Rate: 0.0000362774
2025-05-12 14:10:21,521 Train Loss: 0.0000691, Val Loss: 0.0003274
2025-05-12 14:10:21,521 Epoch 440/500
2025-05-12 14:10:44,165 Current Learning Rate: 0.0000351118
2025-05-12 14:10:44,166 Train Loss: 0.0000696, Val Loss: 0.0003278
2025-05-12 14:10:44,166 Epoch 441/500
2025-05-12 14:11:07,399 Current Learning Rate: 0.0000339644
2025-05-12 14:11:07,534 Train Loss: 0.0000695, Val Loss: 0.0003269
2025-05-12 14:11:07,534 Epoch 442/500
2025-05-12 14:11:30,133 Current Learning Rate: 0.0000328355
2025-05-12 14:11:30,133 Train Loss: 0.0000680, Val Loss: 0.0003274
2025-05-12 14:11:30,134 Epoch 443/500
2025-05-12 14:11:53,011 Current Learning Rate: 0.0000317251
2025-05-12 14:11:53,135 Train Loss: 0.0000687, Val Loss: 0.0003269
2025-05-12 14:11:53,136 Epoch 444/500
2025-05-12 14:12:17,012 Current Learning Rate: 0.0000306331
2025-05-12 14:12:17,013 Train Loss: 0.0000685, Val Loss: 0.0003269
2025-05-12 14:12:17,013 Epoch 445/500
2025-05-12 14:12:39,681 Current Learning Rate: 0.0000295596
2025-05-12 14:12:39,790 Train Loss: 0.0000694, Val Loss: 0.0003265
2025-05-12 14:12:39,790 Epoch 446/500
2025-05-12 14:13:02,482 Current Learning Rate: 0.0000285047
2025-05-12 14:13:02,580 Train Loss: 0.0000693, Val Loss: 0.0003262
2025-05-12 14:13:02,580 Epoch 447/500
2025-05-12 14:13:25,934 Current Learning Rate: 0.0000274685
2025-05-12 14:13:25,934 Train Loss: 0.0000680, Val Loss: 0.0003272
2025-05-12 14:13:25,934 Epoch 448/500
2025-05-12 14:13:48,602 Current Learning Rate: 0.0000264508
2025-05-12 14:13:48,603 Train Loss: 0.0000694, Val Loss: 0.0003266
2025-05-12 14:13:48,603 Epoch 449/500
2025-05-12 14:14:11,592 Current Learning Rate: 0.0000254519
2025-05-12 14:14:11,592 Train Loss: 0.0000688, Val Loss: 0.0003263
2025-05-12 14:14:11,592 Epoch 450/500
2025-05-12 14:14:35,604 Current Learning Rate: 0.0000244717
2025-05-12 14:14:35,807 Saved periodic model at epoch 450 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/TurbL1_0512_LiNS2d_epoch_450.pth
2025-05-12 14:14:35,807 Train Loss: 0.0000682, Val Loss: 0.0003260
2025-05-12 14:14:35,807 Epoch 451/500
2025-05-12 14:14:58,603 Current Learning Rate: 0.0000235103
2025-05-12 14:14:58,603 Train Loss: 0.0000667, Val Loss: 0.0003264
2025-05-12 14:14:58,604 Epoch 452/500
2025-05-12 14:15:22,056 Current Learning Rate: 0.0000225677
2025-05-12 14:15:22,057 Train Loss: 0.0000696, Val Loss: 0.0003264
2025-05-12 14:15:22,057 Epoch 453/500
2025-05-12 14:15:46,272 Current Learning Rate: 0.0000216440
2025-05-12 14:15:46,273 Train Loss: 0.0000679, Val Loss: 0.0003261
2025-05-12 14:15:46,273 Epoch 454/500
2025-05-12 14:16:08,388 Current Learning Rate: 0.0000207391
2025-05-12 14:16:08,515 Train Loss: 0.0000696, Val Loss: 0.0003258
2025-05-12 14:16:08,515 Epoch 455/500
2025-05-12 14:16:31,769 Current Learning Rate: 0.0000198532
2025-05-12 14:16:31,854 Train Loss: 0.0000677, Val Loss: 0.0003255
2025-05-12 14:16:31,854 Epoch 456/500
2025-05-12 14:16:54,853 Current Learning Rate: 0.0000189862
2025-05-12 14:16:54,854 Train Loss: 0.0000693, Val Loss: 0.0003268
2025-05-12 14:16:54,854 Epoch 457/500
2025-05-12 14:17:17,002 Current Learning Rate: 0.0000181382
2025-05-12 14:17:17,003 Train Loss: 0.0000687, Val Loss: 0.0003261
2025-05-12 14:17:17,003 Epoch 458/500
2025-05-12 14:17:41,149 Current Learning Rate: 0.0000173092
2025-05-12 14:17:41,150 Train Loss: 0.0000687, Val Loss: 0.0003262
2025-05-12 14:17:41,150 Epoch 459/500
2025-05-12 14:18:04,003 Current Learning Rate: 0.0000164993
2025-05-12 14:18:04,004 Train Loss: 0.0000670, Val Loss: 0.0003256
2025-05-12 14:18:04,004 Epoch 460/500
2025-05-12 14:18:26,733 Current Learning Rate: 0.0000157084
2025-05-12 14:18:26,734 Train Loss: 0.0000667, Val Loss: 0.0003257
2025-05-12 14:18:26,734 Epoch 461/500
2025-05-12 14:18:50,376 Current Learning Rate: 0.0000149367
2025-05-12 14:18:50,376 Train Loss: 0.0000675, Val Loss: 0.0003260
2025-05-12 14:18:50,376 Epoch 462/500
2025-05-12 14:19:13,281 Current Learning Rate: 0.0000141841
2025-05-12 14:19:13,282 Train Loss: 0.0000669, Val Loss: 0.0003260
2025-05-12 14:19:13,282 Epoch 463/500
2025-05-12 14:19:36,444 Current Learning Rate: 0.0000134507
2025-05-12 14:19:36,444 Train Loss: 0.0000661, Val Loss: 0.0003256
2025-05-12 14:19:36,445 Epoch 464/500
2025-05-12 14:19:59,696 Current Learning Rate: 0.0000127366
2025-05-12 14:19:59,697 Train Loss: 0.0000667, Val Loss: 0.0003257
2025-05-12 14:19:59,697 Epoch 465/500
2025-05-12 14:20:22,269 Current Learning Rate: 0.0000120416
2025-05-12 14:20:22,370 Train Loss: 0.0000670, Val Loss: 0.0003255
2025-05-12 14:20:22,371 Epoch 466/500
2025-05-12 14:20:46,336 Current Learning Rate: 0.0000113659
2025-05-12 14:20:46,549 Train Loss: 0.0000669, Val Loss: 0.0003255
2025-05-12 14:20:46,550 Epoch 467/500
2025-05-12 14:21:09,754 Current Learning Rate: 0.0000107095
2025-05-12 14:21:09,755 Train Loss: 0.0000681, Val Loss: 0.0003255
2025-05-12 14:21:09,755 Epoch 468/500
2025-05-12 14:21:31,836 Current Learning Rate: 0.0000100725
2025-05-12 14:21:31,961 Train Loss: 0.0000656, Val Loss: 0.0003253
2025-05-12 14:21:31,962 Epoch 469/500
2025-05-12 14:21:55,713 Current Learning Rate: 0.0000094547
2025-05-12 14:21:55,713 Train Loss: 0.0000645, Val Loss: 0.0003256
2025-05-12 14:21:55,713 Epoch 470/500
2025-05-12 14:22:18,421 Current Learning Rate: 0.0000088564
2025-05-12 14:22:18,422 Train Loss: 0.0000677, Val Loss: 0.0003255
2025-05-12 14:22:18,422 Epoch 471/500
2025-05-12 14:22:41,165 Current Learning Rate: 0.0000082774
2025-05-12 14:22:41,322 Train Loss: 0.0000687, Val Loss: 0.0003252
2025-05-12 14:22:41,322 Epoch 472/500
2025-05-12 14:23:05,024 Current Learning Rate: 0.0000077178
2025-05-12 14:23:05,025 Train Loss: 0.0000674, Val Loss: 0.0003255
2025-05-12 14:23:05,025 Epoch 473/500
2025-05-12 14:23:28,018 Current Learning Rate: 0.0000071777
2025-05-12 14:23:28,160 Train Loss: 0.0000667, Val Loss: 0.0003252
2025-05-12 14:23:28,160 Epoch 474/500
2025-05-12 14:23:51,148 Current Learning Rate: 0.0000066570
2025-05-12 14:23:51,295 Train Loss: 0.0000684, Val Loss: 0.0003251
2025-05-12 14:23:51,295 Epoch 475/500
2025-05-12 14:24:14,967 Current Learning Rate: 0.0000061558
2025-05-12 14:24:14,967 Train Loss: 0.0000671, Val Loss: 0.0003253
2025-05-12 14:24:14,968 Epoch 476/500
2025-05-12 14:24:37,439 Current Learning Rate: 0.0000056741
2025-05-12 14:24:37,439 Train Loss: 0.0000672, Val Loss: 0.0003252
2025-05-12 14:24:37,440 Epoch 477/500
2025-05-12 14:25:00,656 Current Learning Rate: 0.0000052119
2025-05-12 14:25:00,763 Train Loss: 0.0000664, Val Loss: 0.0003250
2025-05-12 14:25:00,763 Epoch 478/500
2025-05-12 14:25:23,892 Current Learning Rate: 0.0000047693
2025-05-12 14:25:23,893 Train Loss: 0.0000666, Val Loss: 0.0003251
2025-05-12 14:25:23,893 Epoch 479/500
2025-05-12 14:25:46,527 Current Learning Rate: 0.0000043462
2025-05-12 14:25:46,528 Train Loss: 0.0000659, Val Loss: 0.0003254
2025-05-12 14:25:46,528 Epoch 480/500
2025-05-12 14:26:10,183 Current Learning Rate: 0.0000039426
2025-05-12 14:26:10,184 Train Loss: 0.0000655, Val Loss: 0.0003252
2025-05-12 14:26:10,184 Epoch 481/500
2025-05-12 14:26:32,573 Current Learning Rate: 0.0000035587
2025-05-12 14:26:32,670 Train Loss: 0.0000660, Val Loss: 0.0003249
2025-05-12 14:26:32,671 Epoch 482/500
2025-05-12 14:26:54,724 Current Learning Rate: 0.0000031943
2025-05-12 14:26:54,724 Train Loss: 0.0000664, Val Loss: 0.0003252
2025-05-12 14:26:54,724 Epoch 483/500
2025-05-12 14:27:17,775 Current Learning Rate: 0.0000028496
2025-05-12 14:27:17,886 Train Loss: 0.0000661, Val Loss: 0.0003249
2025-05-12 14:27:17,886 Epoch 484/500
2025-05-12 14:27:39,742 Current Learning Rate: 0.0000025245
2025-05-12 14:27:39,742 Train Loss: 0.0000663, Val Loss: 0.0003250
2025-05-12 14:27:39,742 Epoch 485/500
2025-05-12 14:28:02,020 Current Learning Rate: 0.0000022190
2025-05-12 14:28:02,020 Train Loss: 0.0000671, Val Loss: 0.0003249
2025-05-12 14:28:02,021 Epoch 486/500
2025-05-12 14:28:25,234 Current Learning Rate: 0.0000019332
2025-05-12 14:28:25,235 Train Loss: 0.0000662, Val Loss: 0.0003249
2025-05-12 14:28:25,235 Epoch 487/500
2025-05-12 14:28:46,797 Current Learning Rate: 0.0000016670
2025-05-12 14:28:46,798 Train Loss: 0.0000676, Val Loss: 0.0003250
2025-05-12 14:28:46,798 Epoch 488/500
2025-05-12 14:29:09,760 Current Learning Rate: 0.0000014205
2025-05-12 14:29:09,761 Train Loss: 0.0000681, Val Loss: 0.0003252
2025-05-12 14:29:09,761 Epoch 489/500
2025-05-12 14:29:32,882 Current Learning Rate: 0.0000011937
2025-05-12 14:29:32,883 Train Loss: 0.0000664, Val Loss: 0.0003251
2025-05-12 14:29:32,883 Epoch 490/500
2025-05-12 14:29:54,981 Current Learning Rate: 0.0000009866
2025-05-12 14:29:54,982 Train Loss: 0.0000660, Val Loss: 0.0003250
2025-05-12 14:29:54,982 Epoch 491/500
2025-05-12 14:30:18,207 Current Learning Rate: 0.0000007992
2025-05-12 14:30:18,207 Train Loss: 0.0000668, Val Loss: 0.0003250
2025-05-12 14:30:18,207 Epoch 492/500
2025-05-12 14:30:40,212 Current Learning Rate: 0.0000006315
2025-05-12 14:30:40,212 Train Loss: 0.0000668, Val Loss: 0.0003250
2025-05-12 14:30:40,212 Epoch 493/500
2025-05-12 14:31:02,109 Current Learning Rate: 0.0000004835
2025-05-12 14:31:02,110 Train Loss: 0.0000666, Val Loss: 0.0003249
2025-05-12 14:31:02,110 Epoch 494/500
2025-05-12 14:31:25,422 Current Learning Rate: 0.0000003553
2025-05-12 14:31:25,423 Train Loss: 0.0000671, Val Loss: 0.0003249
2025-05-12 14:31:25,423 Epoch 495/500
2025-05-12 14:31:47,794 Current Learning Rate: 0.0000002467
2025-05-12 14:31:47,795 Train Loss: 0.0000674, Val Loss: 0.0003249
2025-05-12 14:31:47,795 Epoch 496/500
2025-05-12 14:32:10,050 Current Learning Rate: 0.0000001579
2025-05-12 14:32:10,051 Train Loss: 0.0000670, Val Loss: 0.0003250
2025-05-12 14:32:10,051 Epoch 497/500
2025-05-12 14:32:33,833 Current Learning Rate: 0.0000000888
2025-05-12 14:32:33,834 Train Loss: 0.0000669, Val Loss: 0.0003250
2025-05-12 14:32:33,834 Epoch 498/500
2025-05-12 14:32:56,383 Current Learning Rate: 0.0000000395
2025-05-12 14:32:56,383 Train Loss: 0.0000668, Val Loss: 0.0003250
2025-05-12 14:32:56,383 Epoch 499/500
2025-05-12 14:33:19,680 Current Learning Rate: 0.0000000099
2025-05-12 14:33:19,681 Train Loss: 0.0000662, Val Loss: 0.0003249
2025-05-12 14:33:19,681 Epoch 500/500
2025-05-12 14:33:43,322 Current Learning Rate: 0.0000000000
2025-05-12 14:33:43,433 Saved periodic model at epoch 500 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/TurbL1_0512_LiNS2d_epoch_500.pth
2025-05-12 14:33:43,433 Train Loss: 0.0000659, Val Loss: 0.0003250
