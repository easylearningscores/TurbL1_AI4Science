2025-05-11 12:41:33,234 Epoch 1/500
2025-05-11 12:43:49,044 Current Learning Rate: 0.0009999901
2025-05-11 12:43:49,119 Train Loss: 0.0210340, Val Loss: 0.0123088
2025-05-11 12:43:49,119 Epoch 2/500
2025-05-11 12:46:04,028 Current Learning Rate: 0.0009999605
2025-05-11 12:46:04,101 Train Loss: 0.0069627, Val Loss: 0.0040550
2025-05-11 12:46:04,101 Epoch 3/500
2025-05-11 12:48:19,064 Current Learning Rate: 0.0009999112
2025-05-11 12:48:19,139 Train Loss: 0.0028938, Val Loss: 0.0022799
2025-05-11 12:48:19,140 Epoch 4/500
2025-05-11 12:50:34,383 Current Learning Rate: 0.0009998421
2025-05-11 12:50:34,458 Train Loss: 0.0017587, Val Loss: 0.0014385
2025-05-11 12:50:34,458 Epoch 5/500
2025-05-11 12:52:49,762 Current Learning Rate: 0.0009997533
2025-05-11 12:52:49,840 Train Loss: 0.0012428, Val Loss: 0.0010605
2025-05-11 12:52:49,841 Epoch 6/500
2025-05-11 12:55:05,223 Current Learning Rate: 0.0009996447
2025-05-11 12:55:05,317 Train Loss: 0.0009846, Val Loss: 0.0009851
2025-05-11 12:55:05,317 Epoch 7/500
2025-05-11 12:57:21,277 Current Learning Rate: 0.0009995165
2025-05-11 12:57:21,368 Train Loss: 0.0008154, Val Loss: 0.0007961
2025-05-11 12:57:21,369 Epoch 8/500
2025-05-11 12:59:37,235 Current Learning Rate: 0.0009993685
2025-05-11 12:59:37,306 Train Loss: 0.0007220, Val Loss: 0.0006550
2025-05-11 12:59:37,306 Epoch 9/500
2025-05-11 13:01:52,912 Current Learning Rate: 0.0009992008
2025-05-11 13:01:53,003 Train Loss: 0.0006437, Val Loss: 0.0006075
2025-05-11 13:01:53,003 Epoch 10/500
2025-05-11 13:04:08,573 Current Learning Rate: 0.0009990134
2025-05-11 13:04:08,667 Train Loss: 0.0005907, Val Loss: 0.0005803
2025-05-11 13:04:08,667 Epoch 11/500
2025-05-11 13:06:24,219 Current Learning Rate: 0.0009988063
2025-05-11 13:06:24,304 Train Loss: 0.0005320, Val Loss: 0.0005029
2025-05-11 13:06:24,304 Epoch 12/500
2025-05-11 13:08:39,652 Current Learning Rate: 0.0009985795
2025-05-11 13:08:39,739 Train Loss: 0.0004962, Val Loss: 0.0004771
2025-05-11 13:08:39,740 Epoch 13/500
2025-05-11 13:10:55,256 Current Learning Rate: 0.0009983330
2025-05-11 13:10:55,328 Train Loss: 0.0004535, Val Loss: 0.0004212
2025-05-11 13:10:55,328 Epoch 14/500
2025-05-11 13:13:10,249 Current Learning Rate: 0.0009980668
2025-05-11 13:13:10,250 Train Loss: 0.0004240, Val Loss: 0.0004686
2025-05-11 13:13:10,250 Epoch 15/500
2025-05-11 13:15:26,008 Current Learning Rate: 0.0009977810
2025-05-11 13:15:26,094 Train Loss: 0.0004000, Val Loss: 0.0003908
2025-05-11 13:15:26,094 Epoch 16/500
2025-05-11 13:17:41,715 Current Learning Rate: 0.0009974755
2025-05-11 13:17:41,795 Train Loss: 0.0003814, Val Loss: 0.0003712
2025-05-11 13:17:41,795 Epoch 17/500
2025-05-11 13:19:57,169 Current Learning Rate: 0.0009971504
2025-05-11 13:19:57,169 Train Loss: 0.0003535, Val Loss: 0.0004628
2025-05-11 13:19:57,170 Epoch 18/500
2025-05-11 13:22:12,500 Current Learning Rate: 0.0009968057
2025-05-11 13:22:12,577 Train Loss: 0.0003369, Val Loss: 0.0002979
2025-05-11 13:22:12,578 Epoch 19/500
2025-05-11 13:24:27,849 Current Learning Rate: 0.0009964413
2025-05-11 13:24:27,926 Train Loss: 0.0003194, Val Loss: 0.0002764
2025-05-11 13:24:27,927 Epoch 20/500
2025-05-11 13:26:43,344 Current Learning Rate: 0.0009960574
2025-05-11 13:26:43,344 Train Loss: 0.0003047, Val Loss: 0.0003272
2025-05-11 13:26:43,345 Epoch 21/500
2025-05-11 13:28:58,753 Current Learning Rate: 0.0009956538
2025-05-11 13:28:58,754 Train Loss: 0.0002938, Val Loss: 0.0002962
2025-05-11 13:28:58,754 Epoch 22/500
2025-05-11 13:31:14,250 Current Learning Rate: 0.0009952307
2025-05-11 13:31:14,250 Train Loss: 0.0002780, Val Loss: 0.0002800
2025-05-11 13:31:14,250 Epoch 23/500
2025-05-11 13:33:29,798 Current Learning Rate: 0.0009947881
2025-05-11 13:33:29,799 Train Loss: 0.0002618, Val Loss: 0.0002816
2025-05-11 13:33:29,799 Epoch 24/500
2025-05-11 13:35:45,263 Current Learning Rate: 0.0009943259
2025-05-11 13:35:45,334 Train Loss: 0.0002561, Val Loss: 0.0002586
2025-05-11 13:35:45,335 Epoch 25/500
2025-05-11 13:38:00,806 Current Learning Rate: 0.0009938442
2025-05-11 13:38:00,882 Train Loss: 0.0002459, Val Loss: 0.0002439
2025-05-11 13:38:00,882 Epoch 26/500
2025-05-11 13:40:16,163 Current Learning Rate: 0.0009933430
2025-05-11 13:40:16,164 Train Loss: 0.0002372, Val Loss: 0.0002770
2025-05-11 13:40:16,164 Epoch 27/500
2025-05-11 13:42:31,375 Current Learning Rate: 0.0009928223
2025-05-11 13:42:31,376 Train Loss: 0.0002299, Val Loss: 0.0002963
2025-05-11 13:42:31,376 Epoch 28/500
2025-05-11 13:44:46,772 Current Learning Rate: 0.0009922822
2025-05-11 13:44:46,852 Train Loss: 0.0002182, Val Loss: 0.0002428
2025-05-11 13:44:46,852 Epoch 29/500
2025-05-11 13:47:02,257 Current Learning Rate: 0.0009917226
2025-05-11 13:47:02,337 Train Loss: 0.0002161, Val Loss: 0.0002155
2025-05-11 13:47:02,337 Epoch 30/500
2025-05-11 13:49:17,696 Current Learning Rate: 0.0009911436
2025-05-11 13:49:17,778 Train Loss: 0.0002058, Val Loss: 0.0002054
2025-05-11 13:49:17,778 Epoch 31/500
2025-05-11 13:51:33,192 Current Learning Rate: 0.0009905453
2025-05-11 13:51:33,193 Train Loss: 0.0002012, Val Loss: 0.0002060
2025-05-11 13:51:33,193 Epoch 32/500
2025-05-11 13:53:48,511 Current Learning Rate: 0.0009899275
2025-05-11 13:53:48,587 Train Loss: 0.0001916, Val Loss: 0.0002048
2025-05-11 13:53:48,587 Epoch 33/500
2025-05-11 13:56:04,042 Current Learning Rate: 0.0009892905
2025-05-11 13:56:04,123 Train Loss: 0.0001910, Val Loss: 0.0001725
2025-05-11 13:56:04,123 Epoch 34/500
2025-05-11 13:58:19,775 Current Learning Rate: 0.0009886341
2025-05-11 13:58:19,776 Train Loss: 0.0001839, Val Loss: 0.0001754
2025-05-11 13:58:19,776 Epoch 35/500
2025-05-11 14:00:35,518 Current Learning Rate: 0.0009879584
2025-05-11 14:00:35,518 Train Loss: 0.0001786, Val Loss: 0.0001785
2025-05-11 14:00:35,519 Epoch 36/500
2025-05-11 14:02:51,236 Current Learning Rate: 0.0009872634
2025-05-11 14:02:51,311 Train Loss: 0.0001727, Val Loss: 0.0001552
2025-05-11 14:02:51,311 Epoch 37/500
2025-05-11 14:05:07,051 Current Learning Rate: 0.0009865493
2025-05-11 14:05:07,051 Train Loss: 0.0001714, Val Loss: 0.0001564
2025-05-11 14:05:07,051 Epoch 38/500
2025-05-11 14:07:22,518 Current Learning Rate: 0.0009858159
2025-05-11 14:07:22,590 Train Loss: 0.0001651, Val Loss: 0.0001520
2025-05-11 14:07:22,591 Epoch 39/500
2025-05-11 14:09:37,998 Current Learning Rate: 0.0009850633
2025-05-11 14:09:38,074 Train Loss: 0.0001612, Val Loss: 0.0001436
2025-05-11 14:09:38,075 Epoch 40/500
2025-05-11 14:11:53,666 Current Learning Rate: 0.0009842916
2025-05-11 14:11:53,667 Train Loss: 0.0001619, Val Loss: 0.0001836
2025-05-11 14:11:53,668 Epoch 41/500
2025-05-11 14:14:09,026 Current Learning Rate: 0.0009835007
2025-05-11 14:14:09,027 Train Loss: 0.0001536, Val Loss: 0.0001460
2025-05-11 14:14:09,027 Epoch 42/500
2025-05-11 14:16:24,738 Current Learning Rate: 0.0009826908
2025-05-11 14:16:24,739 Train Loss: 0.0001508, Val Loss: 0.0001638
2025-05-11 14:16:24,739 Epoch 43/500
2025-05-11 14:18:40,430 Current Learning Rate: 0.0009818618
2025-05-11 14:18:40,431 Train Loss: 0.0001478, Val Loss: 0.0001518
2025-05-11 14:18:40,431 Epoch 44/500
2025-05-11 14:20:55,998 Current Learning Rate: 0.0009810138
2025-05-11 14:20:56,075 Train Loss: 0.0001459, Val Loss: 0.0001407
2025-05-11 14:20:56,076 Epoch 45/500
2025-05-11 14:23:11,744 Current Learning Rate: 0.0009801468
2025-05-11 14:23:11,744 Train Loss: 0.0001416, Val Loss: 0.0002011
2025-05-11 14:23:11,745 Epoch 46/500
2025-05-11 14:25:27,332 Current Learning Rate: 0.0009792609
2025-05-11 14:25:27,417 Train Loss: 0.0001429, Val Loss: 0.0001380
2025-05-11 14:25:27,418 Epoch 47/500
2025-05-11 14:27:43,107 Current Learning Rate: 0.0009783560
2025-05-11 14:27:43,182 Train Loss: 0.0001363, Val Loss: 0.0001291
2025-05-11 14:27:43,183 Epoch 48/500
2025-05-11 14:29:59,197 Current Learning Rate: 0.0009774323
2025-05-11 14:29:59,198 Train Loss: 0.0001372, Val Loss: 0.0001394
2025-05-11 14:29:59,198 Epoch 49/500
2025-05-11 14:32:14,996 Current Learning Rate: 0.0009764897
2025-05-11 14:32:14,997 Train Loss: 0.0001348, Val Loss: 0.0001402
2025-05-11 14:32:14,997 Epoch 50/500
2025-05-11 14:34:30,603 Current Learning Rate: 0.0009755283
2025-05-11 14:34:30,701 Saved periodic model at epoch 50 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/TurbL1_0511_McWilliams2d_epoch_50.pth
2025-05-11 14:34:30,702 Train Loss: 0.0001272, Val Loss: 0.0001404
2025-05-11 14:34:30,702 Epoch 51/500
2025-05-11 14:36:46,583 Current Learning Rate: 0.0009745481
2025-05-11 14:36:46,657 Train Loss: 0.0001257, Val Loss: 0.0001199
2025-05-11 14:36:46,657 Epoch 52/500
2025-05-11 14:39:02,343 Current Learning Rate: 0.0009735492
2025-05-11 14:39:02,343 Train Loss: 0.0001273, Val Loss: 0.0001207
2025-05-11 14:39:02,344 Epoch 53/500
2025-05-11 14:41:17,986 Current Learning Rate: 0.0009725315
2025-05-11 14:41:17,987 Train Loss: 0.0001233, Val Loss: 0.0001231
2025-05-11 14:41:17,987 Epoch 54/500
2025-05-11 14:43:33,548 Current Learning Rate: 0.0009714953
2025-05-11 14:43:33,550 Train Loss: 0.0001239, Val Loss: 0.0001591
2025-05-11 14:43:33,550 Epoch 55/500
2025-05-11 14:45:49,291 Current Learning Rate: 0.0009704404
2025-05-11 14:45:49,292 Train Loss: 0.0001182, Val Loss: 0.0001297
2025-05-11 14:45:49,293 Epoch 56/500
2025-05-11 14:48:04,986 Current Learning Rate: 0.0009693669
2025-05-11 14:48:04,987 Train Loss: 0.0001197, Val Loss: 0.0001252
2025-05-11 14:48:04,987 Epoch 57/500
2025-05-11 14:50:20,366 Current Learning Rate: 0.0009682749
2025-05-11 14:50:20,450 Train Loss: 0.0001148, Val Loss: 0.0001109
2025-05-11 14:50:20,450 Epoch 58/500
2025-05-11 14:52:35,901 Current Learning Rate: 0.0009671645
2025-05-11 14:52:35,976 Train Loss: 0.0001152, Val Loss: 0.0001046
2025-05-11 14:52:35,977 Epoch 59/500
2025-05-11 14:54:51,238 Current Learning Rate: 0.0009660356
2025-05-11 14:54:51,240 Train Loss: 0.0001106, Val Loss: 0.0001407
2025-05-11 14:54:51,240 Epoch 60/500
2025-05-11 14:57:06,247 Current Learning Rate: 0.0009648882
2025-05-11 14:57:06,322 Train Loss: 0.0001129, Val Loss: 0.0001003
2025-05-11 14:57:06,323 Epoch 61/500
2025-05-11 14:59:21,494 Current Learning Rate: 0.0009637226
2025-05-11 14:59:21,495 Train Loss: 0.0001096, Val Loss: 0.0001162
2025-05-11 14:59:21,495 Epoch 62/500
2025-05-11 15:01:36,957 Current Learning Rate: 0.0009625386
2025-05-11 15:01:36,958 Train Loss: 0.0001108, Val Loss: 0.0001060
2025-05-11 15:01:36,958 Epoch 63/500
2025-05-11 15:03:52,344 Current Learning Rate: 0.0009613364
2025-05-11 15:03:52,346 Train Loss: 0.0011931, Val Loss: 0.0214365
2025-05-11 15:03:52,347 Epoch 64/500
2025-05-11 15:06:07,792 Current Learning Rate: 0.0009601159
2025-05-11 15:06:07,793 Train Loss: 0.0056970, Val Loss: 0.0013479
2025-05-11 15:06:07,793 Epoch 65/500
2025-05-11 15:08:23,422 Current Learning Rate: 0.0009588773
2025-05-11 15:08:23,422 Train Loss: 0.0010186, Val Loss: 0.0008816
2025-05-11 15:08:23,423 Epoch 66/500
2025-05-11 15:10:38,981 Current Learning Rate: 0.0009576206
2025-05-11 15:10:38,982 Train Loss: 0.0006486, Val Loss: 0.0005923
2025-05-11 15:10:38,983 Epoch 67/500
2025-05-11 15:12:54,574 Current Learning Rate: 0.0009563458
2025-05-11 15:12:54,576 Train Loss: 0.0004124, Val Loss: 0.0003543
2025-05-11 15:12:54,576 Epoch 68/500
2025-05-11 15:15:10,282 Current Learning Rate: 0.0009550530
2025-05-11 15:15:10,282 Train Loss: 0.0003179, Val Loss: 0.0002691
2025-05-11 15:15:10,283 Epoch 69/500
2025-05-11 15:17:25,935 Current Learning Rate: 0.0009537422
2025-05-11 15:17:25,936 Train Loss: 0.0002643, Val Loss: 0.0002498
2025-05-11 15:17:25,936 Epoch 70/500
2025-05-11 15:19:41,792 Current Learning Rate: 0.0009524135
2025-05-11 15:19:41,793 Train Loss: 0.0002272, Val Loss: 0.0002229
2025-05-11 15:19:41,793 Epoch 71/500
2025-05-11 15:21:57,810 Current Learning Rate: 0.0009510670
2025-05-11 15:21:57,810 Train Loss: 0.0002016, Val Loss: 0.0001941
2025-05-11 15:21:57,810 Epoch 72/500
2025-05-11 15:24:13,870 Current Learning Rate: 0.0009497026
2025-05-11 15:24:13,871 Train Loss: 0.0001814, Val Loss: 0.0001710
2025-05-11 15:24:13,871 Epoch 73/500
2025-05-11 15:26:29,278 Current Learning Rate: 0.0009483205
2025-05-11 15:26:29,279 Train Loss: 0.0001629, Val Loss: 0.0001627
2025-05-11 15:26:29,279 Epoch 74/500
2025-05-11 15:28:44,567 Current Learning Rate: 0.0009469207
2025-05-11 15:28:44,568 Train Loss: 0.0001511, Val Loss: 0.0001479
2025-05-11 15:28:44,569 Epoch 75/500
2025-05-11 15:31:00,146 Current Learning Rate: 0.0009455033
2025-05-11 15:31:00,147 Train Loss: 0.0001394, Val Loss: 0.0001334
2025-05-11 15:31:00,147 Epoch 76/500
2025-05-11 15:33:15,867 Current Learning Rate: 0.0009440682
2025-05-11 15:33:15,868 Train Loss: 0.0001318, Val Loss: 0.0001492
2025-05-11 15:33:15,868 Epoch 77/500
2025-05-11 15:35:31,433 Current Learning Rate: 0.0009426157
2025-05-11 15:35:31,433 Train Loss: 0.0001248, Val Loss: 0.0001236
2025-05-11 15:35:31,433 Epoch 78/500
2025-05-11 15:37:47,012 Current Learning Rate: 0.0009411456
2025-05-11 15:37:47,013 Train Loss: 0.0001229, Val Loss: 0.0001313
2025-05-11 15:37:47,013 Epoch 79/500
2025-05-11 15:40:02,439 Current Learning Rate: 0.0009396582
2025-05-11 15:40:02,439 Train Loss: 0.0001159, Val Loss: 0.0001184
2025-05-11 15:40:02,439 Epoch 80/500
2025-05-11 15:42:18,295 Current Learning Rate: 0.0009381533
2025-05-11 15:42:18,296 Train Loss: 0.0001116, Val Loss: 0.0001060
2025-05-11 15:42:18,296 Epoch 81/500
2025-05-11 15:44:33,995 Current Learning Rate: 0.0009366312
2025-05-11 15:44:33,996 Train Loss: 0.0001107, Val Loss: 0.0001135
2025-05-11 15:44:33,997 Epoch 82/500
2025-05-11 15:46:49,290 Current Learning Rate: 0.0009350919
2025-05-11 15:46:49,291 Train Loss: 0.0001069, Val Loss: 0.0001086
2025-05-11 15:46:49,292 Epoch 83/500
2025-05-11 15:49:04,430 Current Learning Rate: 0.0009335354
2025-05-11 15:49:04,432 Train Loss: 0.0001034, Val Loss: 0.0001209
2025-05-11 15:49:04,432 Epoch 84/500
2025-05-11 15:51:19,801 Current Learning Rate: 0.0009319617
2025-05-11 15:51:19,802 Train Loss: 0.0001018, Val Loss: 0.0001157
2025-05-11 15:51:19,803 Epoch 85/500
2025-05-11 15:53:35,234 Current Learning Rate: 0.0009303710
2025-05-11 15:53:35,308 Train Loss: 0.0001017, Val Loss: 0.0000937
2025-05-11 15:53:35,309 Epoch 86/500
2025-05-11 15:55:50,668 Current Learning Rate: 0.0009287633
2025-05-11 15:55:50,669 Train Loss: 0.0000995, Val Loss: 0.0001330
2025-05-11 15:55:50,670 Epoch 87/500
2025-05-11 15:58:06,144 Current Learning Rate: 0.0009271387
2025-05-11 15:58:06,144 Train Loss: 0.0000945, Val Loss: 0.0000952
2025-05-11 15:58:06,145 Epoch 88/500
2025-05-11 16:00:21,524 Current Learning Rate: 0.0009254972
2025-05-11 16:00:21,525 Train Loss: 0.0000950, Val Loss: 0.0000939
2025-05-11 16:00:21,526 Epoch 89/500
2025-05-11 16:02:36,980 Current Learning Rate: 0.0009238390
2025-05-11 16:02:36,981 Train Loss: 0.0000930, Val Loss: 0.0000938
2025-05-11 16:02:36,982 Epoch 90/500
2025-05-11 16:04:52,301 Current Learning Rate: 0.0009221640
2025-05-11 16:04:52,302 Train Loss: 0.0000903, Val Loss: 0.0000955
2025-05-11 16:04:52,303 Epoch 91/500
2025-05-11 16:07:07,664 Current Learning Rate: 0.0009204723
2025-05-11 16:07:07,665 Train Loss: 0.0000914, Val Loss: 0.0001013
2025-05-11 16:07:07,665 Epoch 92/500
2025-05-11 16:09:22,946 Current Learning Rate: 0.0009187640
2025-05-11 16:09:22,947 Train Loss: 0.0000869, Val Loss: 0.0000939
2025-05-11 16:09:22,948 Epoch 93/500
2025-05-11 16:11:38,423 Current Learning Rate: 0.0009170392
2025-05-11 16:11:38,493 Train Loss: 0.0000874, Val Loss: 0.0000917
2025-05-11 16:11:38,493 Epoch 94/500
2025-05-11 16:13:54,122 Current Learning Rate: 0.0009152979
2025-05-11 16:13:54,200 Train Loss: 0.0000866, Val Loss: 0.0000849
2025-05-11 16:13:54,200 Epoch 95/500
2025-05-11 16:16:09,556 Current Learning Rate: 0.0009135403
2025-05-11 16:16:09,557 Train Loss: 0.0000845, Val Loss: 0.0000916
2025-05-11 16:16:09,557 Epoch 96/500
2025-05-11 16:18:24,993 Current Learning Rate: 0.0009117663
2025-05-11 16:18:25,072 Train Loss: 0.0000854, Val Loss: 0.0000817
2025-05-11 16:18:25,073 Epoch 97/500
2025-05-11 16:20:40,556 Current Learning Rate: 0.0009099761
2025-05-11 16:20:40,557 Train Loss: 0.0000867, Val Loss: 0.0000861
2025-05-11 16:20:40,557 Epoch 98/500
2025-05-11 16:22:55,892 Current Learning Rate: 0.0009081696
2025-05-11 16:22:55,893 Train Loss: 0.0000814, Val Loss: 0.0000857
2025-05-11 16:22:55,893 Epoch 99/500
2025-05-11 16:25:11,244 Current Learning Rate: 0.0009063471
2025-05-11 16:25:11,245 Train Loss: 0.0000838, Val Loss: 0.0000843
2025-05-11 16:25:11,245 Epoch 100/500
2025-05-11 16:27:26,590 Current Learning Rate: 0.0009045085
2025-05-11 16:27:26,669 Saved periodic model at epoch 100 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/TurbL1_0511_McWilliams2d_epoch_100.pth
2025-05-11 16:27:26,670 Train Loss: 0.0000808, Val Loss: 0.0000870
2025-05-11 16:27:26,670 Epoch 101/500
2025-05-11 16:29:42,144 Current Learning Rate: 0.0009026539
2025-05-11 16:29:42,227 Train Loss: 0.0000814, Val Loss: 0.0000794
2025-05-11 16:29:42,227 Epoch 102/500
2025-05-11 16:31:57,672 Current Learning Rate: 0.0009007835
2025-05-11 16:31:57,743 Train Loss: 0.0000803, Val Loss: 0.0000776
2025-05-11 16:31:57,744 Epoch 103/500
2025-05-11 16:34:13,162 Current Learning Rate: 0.0008988972
2025-05-11 16:34:13,163 Train Loss: 0.0000783, Val Loss: 0.0000839
2025-05-11 16:34:13,163 Epoch 104/500
2025-05-11 16:36:28,676 Current Learning Rate: 0.0008969952
2025-05-11 16:36:28,677 Train Loss: 0.0000767, Val Loss: 0.0000778
2025-05-11 16:36:28,677 Epoch 105/500
2025-05-11 16:38:44,307 Current Learning Rate: 0.0008950775
2025-05-11 16:38:44,309 Train Loss: 0.0000765, Val Loss: 0.0000936
2025-05-11 16:38:44,309 Epoch 106/500
2025-05-11 16:40:59,789 Current Learning Rate: 0.0008931442
2025-05-11 16:40:59,790 Train Loss: 0.0000763, Val Loss: 0.0000994
2025-05-11 16:40:59,790 Epoch 107/500
2025-05-11 16:43:15,237 Current Learning Rate: 0.0008911954
2025-05-11 16:43:15,320 Train Loss: 0.0000767, Val Loss: 0.0000762
2025-05-11 16:43:15,320 Epoch 108/500
2025-05-11 16:45:30,789 Current Learning Rate: 0.0008892312
2025-05-11 16:45:30,867 Train Loss: 0.0000734, Val Loss: 0.0000736
2025-05-11 16:45:30,867 Epoch 109/500
2025-05-11 16:47:46,214 Current Learning Rate: 0.0008872515
2025-05-11 16:47:46,290 Train Loss: 0.0000880, Val Loss: 0.0000735
2025-05-11 16:47:46,290 Epoch 110/500
2025-05-11 16:50:01,679 Current Learning Rate: 0.0008852566
2025-05-11 16:50:01,764 Train Loss: 0.0000699, Val Loss: 0.0000728
2025-05-11 16:50:01,764 Epoch 111/500
2025-05-11 16:52:17,081 Current Learning Rate: 0.0008832465
2025-05-11 16:52:17,082 Train Loss: 0.0000737, Val Loss: 0.0000807
2025-05-11 16:52:17,082 Epoch 112/500
2025-05-11 16:54:32,423 Current Learning Rate: 0.0008812213
2025-05-11 16:54:32,524 Train Loss: 0.0000718, Val Loss: 0.0000721
2025-05-11 16:54:32,524 Epoch 113/500
2025-05-11 16:56:47,748 Current Learning Rate: 0.0008791810
2025-05-11 16:56:47,819 Train Loss: 0.0000719, Val Loss: 0.0000701
2025-05-11 16:56:47,819 Epoch 114/500
2025-05-11 16:59:03,488 Current Learning Rate: 0.0008771257
2025-05-11 16:59:03,489 Train Loss: 0.0000708, Val Loss: 0.0000776
2025-05-11 16:59:03,489 Epoch 115/500
2025-05-11 17:01:19,184 Current Learning Rate: 0.0008750555
2025-05-11 17:01:19,185 Train Loss: 0.0000693, Val Loss: 0.0000734
2025-05-11 17:01:19,185 Epoch 116/500
2025-05-11 17:03:34,927 Current Learning Rate: 0.0008729706
2025-05-11 17:03:34,928 Train Loss: 0.0000695, Val Loss: 0.0000718
2025-05-11 17:03:34,929 Epoch 117/500
2025-05-11 17:05:50,699 Current Learning Rate: 0.0008708709
2025-05-11 17:05:50,700 Train Loss: 0.0000699, Val Loss: 0.0000738
2025-05-11 17:05:50,701 Epoch 118/500
2025-05-11 17:08:06,283 Current Learning Rate: 0.0008687566
2025-05-11 17:08:06,284 Train Loss: 0.0000686, Val Loss: 0.0000891
2025-05-11 17:08:06,284 Epoch 119/500
2025-05-11 17:10:21,693 Current Learning Rate: 0.0008666277
2025-05-11 17:10:21,774 Train Loss: 0.0000735, Val Loss: 0.0000692
2025-05-11 17:10:21,775 Epoch 120/500
2025-05-11 17:12:37,168 Current Learning Rate: 0.0008644843
2025-05-11 17:12:37,169 Train Loss: 0.0000672, Val Loss: 0.0000752
2025-05-11 17:12:37,169 Epoch 121/500
2025-05-11 17:14:52,621 Current Learning Rate: 0.0008623266
2025-05-11 17:14:52,622 Train Loss: 0.0000850, Val Loss: 0.0000735
2025-05-11 17:14:52,623 Epoch 122/500
2025-05-11 17:17:08,044 Current Learning Rate: 0.0008601545
2025-05-11 17:17:08,045 Train Loss: 0.0000645, Val Loss: 0.0000792
2025-05-11 17:17:08,045 Epoch 123/500
2025-05-11 17:19:23,500 Current Learning Rate: 0.0008579682
2025-05-11 17:19:23,501 Train Loss: 0.0000658, Val Loss: 0.0000945
2025-05-11 17:19:23,502 Epoch 124/500
2025-05-11 17:21:38,882 Current Learning Rate: 0.0008557678
2025-05-11 17:21:38,958 Train Loss: 0.0000652, Val Loss: 0.0000691
2025-05-11 17:21:38,959 Epoch 125/500
2025-05-11 17:23:54,445 Current Learning Rate: 0.0008535534
2025-05-11 17:23:54,445 Train Loss: 0.0000667, Val Loss: 0.0000775
2025-05-11 17:23:54,446 Epoch 126/500
2025-05-11 17:26:09,827 Current Learning Rate: 0.0008513250
2025-05-11 17:26:09,901 Train Loss: 0.0000662, Val Loss: 0.0000670
2025-05-11 17:26:09,901 Epoch 127/500
2025-05-11 17:28:25,193 Current Learning Rate: 0.0008490827
2025-05-11 17:28:25,194 Train Loss: 0.0000696, Val Loss: 0.0000675
2025-05-11 17:28:25,195 Epoch 128/500
2025-05-11 17:30:40,643 Current Learning Rate: 0.0008468267
2025-05-11 17:30:40,720 Train Loss: 0.0000667, Val Loss: 0.0000643
2025-05-11 17:30:40,720 Epoch 129/500
2025-05-11 17:32:56,194 Current Learning Rate: 0.0008445569
2025-05-11 17:32:56,195 Train Loss: 0.0000627, Val Loss: 0.0000724
2025-05-11 17:32:56,195 Epoch 130/500
2025-05-11 17:35:11,706 Current Learning Rate: 0.0008422736
2025-05-11 17:35:11,707 Train Loss: 0.0000633, Val Loss: 0.0000682
2025-05-11 17:35:11,708 Epoch 131/500
2025-05-11 17:37:27,262 Current Learning Rate: 0.0008399767
2025-05-11 17:37:27,343 Train Loss: 0.0000620, Val Loss: 0.0000626
2025-05-11 17:37:27,343 Epoch 132/500
2025-05-11 17:39:42,806 Current Learning Rate: 0.0008376664
2025-05-11 17:39:42,807 Train Loss: 0.0000626, Val Loss: 0.0000658
2025-05-11 17:39:42,807 Epoch 133/500
2025-05-11 17:41:58,307 Current Learning Rate: 0.0008353428
2025-05-11 17:41:58,388 Train Loss: 0.0000634, Val Loss: 0.0000619
2025-05-11 17:41:58,389 Epoch 134/500
2025-05-11 17:44:13,824 Current Learning Rate: 0.0008330059
2025-05-11 17:44:13,825 Train Loss: 0.0000615, Val Loss: 0.0000653
2025-05-11 17:44:13,825 Epoch 135/500
2025-05-11 17:46:29,288 Current Learning Rate: 0.0008306559
2025-05-11 17:46:29,289 Train Loss: 0.0000645, Val Loss: 0.0000620
2025-05-11 17:46:29,289 Epoch 136/500
2025-05-11 17:48:44,526 Current Learning Rate: 0.0008282929
2025-05-11 17:48:44,610 Train Loss: 0.0000595, Val Loss: 0.0000611
2025-05-11 17:48:44,611 Epoch 137/500
2025-05-11 17:50:59,799 Current Learning Rate: 0.0008259169
2025-05-11 17:50:59,801 Train Loss: 0.0000604, Val Loss: 0.0000674
2025-05-11 17:50:59,801 Epoch 138/500
2025-05-11 17:53:14,992 Current Learning Rate: 0.0008235280
2025-05-11 17:53:14,993 Train Loss: 0.0000609, Val Loss: 0.0000641
2025-05-11 17:53:14,993 Epoch 139/500
2025-05-11 17:55:30,290 Current Learning Rate: 0.0008211263
2025-05-11 17:55:30,291 Train Loss: 0.0000592, Val Loss: 0.0000763
2025-05-11 17:55:30,291 Epoch 140/500
2025-05-11 17:57:45,435 Current Learning Rate: 0.0008187120
2025-05-11 17:57:45,520 Train Loss: 0.0000588, Val Loss: 0.0000603
2025-05-11 17:57:45,520 Epoch 141/500
2025-05-11 18:00:00,775 Current Learning Rate: 0.0008162851
2025-05-11 18:00:00,776 Train Loss: 0.0000614, Val Loss: 0.0000605
2025-05-11 18:00:00,776 Epoch 142/500
2025-05-11 18:02:16,086 Current Learning Rate: 0.0008138457
2025-05-11 18:02:16,087 Train Loss: 0.0000583, Val Loss: 0.0000708
2025-05-11 18:02:16,087 Epoch 143/500
2025-05-11 18:04:31,240 Current Learning Rate: 0.0008113939
2025-05-11 18:04:31,242 Train Loss: 0.0000588, Val Loss: 0.0000653
2025-05-11 18:04:31,243 Epoch 144/500
2025-05-11 18:06:46,375 Current Learning Rate: 0.0008089298
2025-05-11 18:06:46,376 Train Loss: 0.0000591, Val Loss: 0.0000649
2025-05-11 18:06:46,377 Epoch 145/500
2025-05-11 18:09:01,582 Current Learning Rate: 0.0008064535
2025-05-11 18:09:01,583 Train Loss: 0.0000587, Val Loss: 0.0000680
2025-05-11 18:09:01,583 Epoch 146/500
2025-05-11 18:11:16,728 Current Learning Rate: 0.0008039651
2025-05-11 18:11:16,729 Train Loss: 0.0000588, Val Loss: 0.0000607
2025-05-11 18:11:16,729 Epoch 147/500
2025-05-11 18:13:31,954 Current Learning Rate: 0.0008014648
2025-05-11 18:13:31,955 Train Loss: 0.0000568, Val Loss: 0.0000627
2025-05-11 18:13:31,955 Epoch 148/500
2025-05-11 18:15:47,306 Current Learning Rate: 0.0007989525
2025-05-11 18:15:47,387 Train Loss: 0.0000577, Val Loss: 0.0000580
2025-05-11 18:15:47,387 Epoch 149/500
2025-05-11 18:18:02,769 Current Learning Rate: 0.0007964284
2025-05-11 18:18:02,770 Train Loss: 0.0000569, Val Loss: 0.0000614
2025-05-11 18:18:02,770 Epoch 150/500
2025-05-11 18:20:17,919 Current Learning Rate: 0.0007938926
2025-05-11 18:20:18,013 Saved periodic model at epoch 150 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/TurbL1_0511_McWilliams2d_epoch_150.pth
2025-05-11 18:20:18,013 Train Loss: 0.0000561, Val Loss: 0.0000582
2025-05-11 18:20:18,013 Epoch 151/500
2025-05-11 18:22:32,969 Current Learning Rate: 0.0007913452
2025-05-11 18:22:32,970 Train Loss: 0.0000551, Val Loss: 0.0000591
2025-05-11 18:22:32,970 Epoch 152/500
2025-05-11 18:24:48,029 Current Learning Rate: 0.0007887864
2025-05-11 18:24:48,030 Train Loss: 0.0000555, Val Loss: 0.0000609
2025-05-11 18:24:48,030 Epoch 153/500
2025-05-11 18:27:03,057 Current Learning Rate: 0.0007862161
2025-05-11 18:27:03,058 Train Loss: 0.0000552, Val Loss: 0.0000626
2025-05-11 18:27:03,058 Epoch 154/500
2025-05-11 18:29:18,020 Current Learning Rate: 0.0007836345
2025-05-11 18:29:18,022 Train Loss: 0.0000548, Val Loss: 0.0000598
2025-05-11 18:29:18,023 Epoch 155/500
2025-05-11 18:31:33,004 Current Learning Rate: 0.0007810417
2025-05-11 18:31:33,083 Train Loss: 0.0000534, Val Loss: 0.0000556
2025-05-11 18:31:33,083 Epoch 156/500
2025-05-11 18:33:48,110 Current Learning Rate: 0.0007784378
2025-05-11 18:33:48,111 Train Loss: 0.0000549, Val Loss: 0.0000597
2025-05-11 18:33:48,112 Epoch 157/500
2025-05-11 18:36:03,163 Current Learning Rate: 0.0007758229
2025-05-11 18:36:03,165 Train Loss: 0.0000543, Val Loss: 0.0000561
2025-05-11 18:36:03,165 Epoch 158/500
2025-05-11 18:38:18,373 Current Learning Rate: 0.0007731972
2025-05-11 18:38:18,374 Train Loss: 0.0000544, Val Loss: 0.0000568
2025-05-11 18:38:18,375 Epoch 159/500
2025-05-11 18:40:33,690 Current Learning Rate: 0.0007705606
2025-05-11 18:40:33,691 Train Loss: 0.0000534, Val Loss: 0.0000622
2025-05-11 18:40:33,692 Epoch 160/500
2025-05-11 18:42:48,943 Current Learning Rate: 0.0007679134
2025-05-11 18:42:48,944 Train Loss: 0.0000537, Val Loss: 0.0000799
2025-05-11 18:42:48,944 Epoch 161/500
2025-05-11 18:45:04,318 Current Learning Rate: 0.0007652556
2025-05-11 18:45:04,397 Train Loss: 0.0000521, Val Loss: 0.0000549
2025-05-11 18:45:04,397 Epoch 162/500
2025-05-11 18:47:19,824 Current Learning Rate: 0.0007625873
2025-05-11 18:47:19,824 Train Loss: 0.0000537, Val Loss: 0.0000643
2025-05-11 18:47:19,825 Epoch 163/500
2025-05-11 18:49:35,223 Current Learning Rate: 0.0007599087
2025-05-11 18:49:35,224 Train Loss: 0.0000526, Val Loss: 0.0000597
2025-05-11 18:49:35,224 Epoch 164/500
2025-05-11 18:51:50,689 Current Learning Rate: 0.0007572198
2025-05-11 18:51:50,761 Train Loss: 0.0000540, Val Loss: 0.0000530
2025-05-11 18:51:50,762 Epoch 165/500
2025-05-11 18:54:06,371 Current Learning Rate: 0.0007545207
2025-05-11 18:54:06,371 Train Loss: 0.0000513, Val Loss: 0.0000590
2025-05-11 18:54:06,371 Epoch 166/500
2025-05-11 18:56:21,926 Current Learning Rate: 0.0007518116
2025-05-11 18:56:21,928 Train Loss: 0.0000513, Val Loss: 0.0000600
2025-05-11 18:56:21,929 Epoch 167/500
2025-05-11 18:58:37,434 Current Learning Rate: 0.0007490926
2025-05-11 18:58:37,435 Train Loss: 0.0000521, Val Loss: 0.0000576
2025-05-11 18:58:37,435 Epoch 168/500
2025-05-11 19:00:52,921 Current Learning Rate: 0.0007463637
2025-05-11 19:00:53,008 Train Loss: 0.0000509, Val Loss: 0.0000522
2025-05-11 19:00:53,009 Epoch 169/500
2025-05-11 19:03:08,534 Current Learning Rate: 0.0007436251
2025-05-11 19:03:08,534 Train Loss: 0.0000507, Val Loss: 0.0000543
2025-05-11 19:03:08,535 Epoch 170/500
2025-05-11 19:05:24,054 Current Learning Rate: 0.0007408768
2025-05-11 19:05:24,055 Train Loss: 0.0000537, Val Loss: 0.0000577
2025-05-11 19:05:24,055 Epoch 171/500
2025-05-11 19:07:39,504 Current Learning Rate: 0.0007381191
2025-05-11 19:07:39,505 Train Loss: 0.0000509, Val Loss: 0.0000580
2025-05-11 19:07:39,506 Epoch 172/500
2025-05-11 19:09:54,682 Current Learning Rate: 0.0007353520
2025-05-11 19:09:54,786 Train Loss: 0.0000535, Val Loss: 0.0000520
2025-05-11 19:09:54,786 Epoch 173/500
2025-05-11 19:12:10,059 Current Learning Rate: 0.0007325755
2025-05-11 19:12:10,060 Train Loss: 0.0000490, Val Loss: 0.0000540
2025-05-11 19:12:10,061 Epoch 174/500
2025-05-11 19:14:25,335 Current Learning Rate: 0.0007297899
2025-05-11 19:14:25,336 Train Loss: 0.0000526, Val Loss: 0.0000558
2025-05-11 19:14:25,337 Epoch 175/500
2025-05-11 19:16:40,540 Current Learning Rate: 0.0007269952
2025-05-11 19:16:40,541 Train Loss: 0.0000482, Val Loss: 0.0000532
2025-05-11 19:16:40,541 Epoch 176/500
2025-05-11 19:18:56,033 Current Learning Rate: 0.0007241916
2025-05-11 19:18:56,035 Train Loss: 0.0000492, Val Loss: 0.0000584
2025-05-11 19:18:56,036 Epoch 177/500
2025-05-11 19:21:11,771 Current Learning Rate: 0.0007213791
2025-05-11 19:21:11,844 Train Loss: 0.0000490, Val Loss: 0.0000503
2025-05-11 19:21:11,844 Epoch 178/500
2025-05-11 19:23:27,700 Current Learning Rate: 0.0007185579
2025-05-11 19:23:27,701 Train Loss: 0.0000492, Val Loss: 0.0000538
2025-05-11 19:23:27,701 Epoch 179/500
2025-05-11 19:25:43,554 Current Learning Rate: 0.0007157280
2025-05-11 19:25:43,555 Train Loss: 0.0000492, Val Loss: 0.0000524
2025-05-11 19:25:43,555 Epoch 180/500
2025-05-11 19:27:59,331 Current Learning Rate: 0.0007128896
2025-05-11 19:27:59,332 Train Loss: 0.0000483, Val Loss: 0.0000540
2025-05-11 19:27:59,332 Epoch 181/500
2025-05-11 19:30:14,639 Current Learning Rate: 0.0007100429
2025-05-11 19:30:14,640 Train Loss: 0.0000488, Val Loss: 0.0000503
2025-05-11 19:30:14,640 Epoch 182/500
2025-05-11 19:32:29,932 Current Learning Rate: 0.0007071878
2025-05-11 19:32:29,933 Train Loss: 0.0000487, Val Loss: 0.0000508
2025-05-11 19:32:29,933 Epoch 183/500
2025-05-11 19:34:45,549 Current Learning Rate: 0.0007043245
2025-05-11 19:34:45,549 Train Loss: 0.0000499, Val Loss: 0.0000513
2025-05-11 19:34:45,550 Epoch 184/500
2025-05-11 19:37:01,142 Current Learning Rate: 0.0007014532
2025-05-11 19:37:01,220 Train Loss: 0.0000473, Val Loss: 0.0000499
2025-05-11 19:37:01,220 Epoch 185/500
2025-05-11 19:39:16,424 Current Learning Rate: 0.0006985739
2025-05-11 19:39:16,425 Train Loss: 0.0000480, Val Loss: 0.0000502
2025-05-11 19:39:16,425 Epoch 186/500
2025-05-11 19:41:31,689 Current Learning Rate: 0.0006956868
2025-05-11 19:41:31,690 Train Loss: 0.0000475, Val Loss: 0.0000564
2025-05-11 19:41:31,691 Epoch 187/500
2025-05-11 19:43:46,851 Current Learning Rate: 0.0006927920
2025-05-11 19:43:46,852 Train Loss: 0.0000502, Val Loss: 0.0000541
2025-05-11 19:43:46,853 Epoch 188/500
2025-05-11 19:46:02,034 Current Learning Rate: 0.0006898895
2025-05-11 19:46:02,291 Train Loss: 0.0000470, Val Loss: 0.0000488
2025-05-11 19:46:02,292 Epoch 189/500
2025-05-11 19:48:17,373 Current Learning Rate: 0.0006869796
2025-05-11 19:48:17,375 Train Loss: 0.0000476, Val Loss: 0.0000512
2025-05-11 19:48:17,375 Epoch 190/500
2025-05-11 19:50:32,529 Current Learning Rate: 0.0006840623
2025-05-11 19:50:32,530 Train Loss: 0.0000470, Val Loss: 0.0000563
2025-05-11 19:50:32,531 Epoch 191/500
2025-05-11 19:52:47,792 Current Learning Rate: 0.0006811377
2025-05-11 19:52:47,793 Train Loss: 0.0000458, Val Loss: 0.0000581
2025-05-11 19:52:47,794 Epoch 192/500
2025-05-11 19:55:03,024 Current Learning Rate: 0.0006782059
2025-05-11 19:55:03,026 Train Loss: 0.0000462, Val Loss: 0.0000496
2025-05-11 19:55:03,026 Epoch 193/500
2025-05-11 19:57:18,073 Current Learning Rate: 0.0006752672
2025-05-11 19:57:18,150 Train Loss: 0.0000465, Val Loss: 0.0000477
2025-05-11 19:57:18,151 Epoch 194/500
2025-05-11 19:59:33,606 Current Learning Rate: 0.0006723215
2025-05-11 19:59:33,678 Train Loss: 0.0000465, Val Loss: 0.0000474
2025-05-11 19:59:33,679 Epoch 195/500
2025-05-11 20:01:49,126 Current Learning Rate: 0.0006693690
2025-05-11 20:01:49,127 Train Loss: 0.0000453, Val Loss: 0.0000498
2025-05-11 20:01:49,127 Epoch 196/500
2025-05-11 20:04:04,820 Current Learning Rate: 0.0006664098
2025-05-11 20:04:04,821 Train Loss: 0.0000461, Val Loss: 0.0000484
2025-05-11 20:04:04,822 Epoch 197/500
2025-05-11 20:06:20,095 Current Learning Rate: 0.0006634440
2025-05-11 20:06:20,096 Train Loss: 0.0000457, Val Loss: 0.0000496
2025-05-11 20:06:20,096 Epoch 198/500
2025-05-11 20:08:35,562 Current Learning Rate: 0.0006604718
2025-05-11 20:08:35,564 Train Loss: 0.0000451, Val Loss: 0.0000495
2025-05-11 20:08:35,564 Epoch 199/500
2025-05-11 20:10:50,917 Current Learning Rate: 0.0006574933
2025-05-11 20:10:50,917 Train Loss: 0.0000451, Val Loss: 0.0000534
2025-05-11 20:10:50,918 Epoch 200/500
2025-05-11 20:13:06,358 Current Learning Rate: 0.0006545085
2025-05-11 20:13:06,440 Saved periodic model at epoch 200 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/TurbL1_0511_McWilliams2d_epoch_200.pth
2025-05-11 20:13:06,442 Train Loss: 0.0000460, Val Loss: 0.0000594
2025-05-11 20:13:06,443 Epoch 201/500
2025-05-11 20:15:21,947 Current Learning Rate: 0.0006515176
2025-05-11 20:15:22,276 Train Loss: 0.0000442, Val Loss: 0.0000472
2025-05-11 20:15:22,276 Epoch 202/500
2025-05-11 20:17:37,789 Current Learning Rate: 0.0006485208
2025-05-11 20:17:37,869 Train Loss: 0.0000446, Val Loss: 0.0000471
2025-05-11 20:17:37,871 Epoch 203/500
2025-05-11 20:19:53,095 Current Learning Rate: 0.0006455181
2025-05-11 20:19:53,168 Train Loss: 0.0000442, Val Loss: 0.0000462
2025-05-11 20:19:53,169 Epoch 204/500
2025-05-11 20:22:08,312 Current Learning Rate: 0.0006425096
2025-05-11 20:22:08,387 Train Loss: 0.0000442, Val Loss: 0.0000459
2025-05-11 20:22:08,387 Epoch 205/500
2025-05-11 20:24:23,633 Current Learning Rate: 0.0006394956
2025-05-11 20:24:23,634 Train Loss: 0.0000435, Val Loss: 0.0000489
2025-05-11 20:24:23,635 Epoch 206/500
2025-05-11 20:26:38,797 Current Learning Rate: 0.0006364760
2025-05-11 20:26:38,799 Train Loss: 0.0000440, Val Loss: 0.0000477
2025-05-11 20:26:38,799 Epoch 207/500
2025-05-11 20:28:53,921 Current Learning Rate: 0.0006334510
2025-05-11 20:28:53,922 Train Loss: 0.0000448, Val Loss: 0.0000517
2025-05-11 20:28:53,927 Epoch 208/500
2025-05-11 20:31:09,103 Current Learning Rate: 0.0006304208
2025-05-11 20:31:09,104 Train Loss: 0.0000425, Val Loss: 0.0000480
2025-05-11 20:31:09,105 Epoch 209/500
2025-05-11 20:33:24,277 Current Learning Rate: 0.0006273854
2025-05-11 20:33:24,278 Train Loss: 0.0000428, Val Loss: 0.0000482
2025-05-11 20:33:24,279 Epoch 210/500
2025-05-11 20:35:39,356 Current Learning Rate: 0.0006243449
2025-05-11 20:35:39,363 Train Loss: 0.0000437, Val Loss: 0.0000511
2025-05-11 20:35:39,363 Epoch 211/500
2025-05-11 20:37:54,547 Current Learning Rate: 0.0006212996
2025-05-11 20:37:54,548 Train Loss: 0.0000428, Val Loss: 0.0000474
2025-05-11 20:37:54,549 Epoch 212/500
2025-05-11 20:40:09,751 Current Learning Rate: 0.0006182495
2025-05-11 20:40:09,751 Train Loss: 0.0000437, Val Loss: 0.0000547
2025-05-11 20:40:09,752 Epoch 213/500
2025-05-11 20:42:25,281 Current Learning Rate: 0.0006151947
2025-05-11 20:42:25,282 Train Loss: 0.0000435, Val Loss: 0.0000566
2025-05-11 20:42:25,282 Epoch 214/500
2025-05-11 20:44:41,343 Current Learning Rate: 0.0006121354
2025-05-11 20:44:41,432 Train Loss: 0.0000437, Val Loss: 0.0000457
2025-05-11 20:44:41,433 Epoch 215/500
2025-05-11 20:46:56,624 Current Learning Rate: 0.0006090716
2025-05-11 20:46:56,625 Train Loss: 0.0000414, Val Loss: 0.0000480
2025-05-11 20:46:56,625 Epoch 216/500
2025-05-11 20:49:11,775 Current Learning Rate: 0.0006060036
2025-05-11 20:49:11,776 Train Loss: 0.0000426, Val Loss: 0.0000473
2025-05-11 20:49:11,776 Epoch 217/500
2025-05-11 20:51:26,819 Current Learning Rate: 0.0006029313
2025-05-11 20:51:26,819 Train Loss: 0.0000419, Val Loss: 0.0000487
2025-05-11 20:51:26,819 Epoch 218/500
2025-05-11 20:53:42,002 Current Learning Rate: 0.0005998550
2025-05-11 20:53:42,082 Train Loss: 0.0000416, Val Loss: 0.0000441
2025-05-11 20:53:42,082 Epoch 219/500
2025-05-11 20:55:57,603 Current Learning Rate: 0.0005967747
2025-05-11 20:55:57,604 Train Loss: 0.0000412, Val Loss: 0.0000500
2025-05-11 20:55:57,604 Epoch 220/500
2025-05-11 20:58:13,159 Current Learning Rate: 0.0005936907
2025-05-11 20:58:13,160 Train Loss: 0.0000419, Val Loss: 0.0000477
2025-05-11 20:58:13,160 Epoch 221/500
2025-05-11 21:00:28,459 Current Learning Rate: 0.0005906029
2025-05-11 21:00:28,460 Train Loss: 0.0000438, Val Loss: 0.0000466
2025-05-11 21:00:28,460 Epoch 222/500
2025-05-11 21:02:43,899 Current Learning Rate: 0.0005875115
2025-05-11 21:02:43,899 Train Loss: 0.0000417, Val Loss: 0.0000463
2025-05-11 21:02:43,900 Epoch 223/500
2025-05-11 21:04:59,335 Current Learning Rate: 0.0005844167
2025-05-11 21:04:59,336 Train Loss: 0.0000421, Val Loss: 0.0000500
2025-05-11 21:04:59,337 Epoch 224/500
2025-05-11 21:07:14,715 Current Learning Rate: 0.0005813186
2025-05-11 21:07:14,716 Train Loss: 0.0000422, Val Loss: 0.0000663
2025-05-11 21:07:14,717 Epoch 225/500
2025-05-11 21:09:30,143 Current Learning Rate: 0.0005782172
2025-05-11 21:09:30,144 Train Loss: 0.0000413, Val Loss: 0.0000489
2025-05-11 21:09:30,144 Epoch 226/500
2025-05-11 21:11:45,341 Current Learning Rate: 0.0005751128
2025-05-11 21:11:45,342 Train Loss: 0.0000410, Val Loss: 0.0000443
2025-05-11 21:11:45,342 Epoch 227/500
2025-05-11 21:14:00,512 Current Learning Rate: 0.0005720054
2025-05-11 21:14:00,512 Train Loss: 0.0000413, Val Loss: 0.0000457
2025-05-11 21:14:00,513 Epoch 228/500
2025-05-11 21:16:15,672 Current Learning Rate: 0.0005688951
2025-05-11 21:16:15,673 Train Loss: 0.0000405, Val Loss: 0.0000457
2025-05-11 21:16:15,674 Epoch 229/500
2025-05-11 21:18:31,016 Current Learning Rate: 0.0005657822
2025-05-11 21:18:31,018 Train Loss: 0.0000407, Val Loss: 0.0000444
2025-05-11 21:18:31,018 Epoch 230/500
2025-05-11 21:20:46,402 Current Learning Rate: 0.0005626666
2025-05-11 21:20:46,403 Train Loss: 0.0000400, Val Loss: 0.0000493
2025-05-11 21:20:46,404 Epoch 231/500
2025-05-11 21:23:01,900 Current Learning Rate: 0.0005595486
2025-05-11 21:23:01,902 Train Loss: 0.0000411, Val Loss: 0.0000452
2025-05-11 21:23:01,902 Epoch 232/500
2025-05-11 21:25:17,824 Current Learning Rate: 0.0005564282
2025-05-11 21:25:17,903 Train Loss: 0.0000412, Val Loss: 0.0000438
2025-05-11 21:25:17,903 Epoch 233/500
2025-05-11 21:27:34,038 Current Learning Rate: 0.0005533056
2025-05-11 21:27:34,039 Train Loss: 0.0000401, Val Loss: 0.0000491
2025-05-11 21:27:34,039 Epoch 234/500
2025-05-11 21:29:49,908 Current Learning Rate: 0.0005501809
2025-05-11 21:29:49,996 Train Loss: 0.0000402, Val Loss: 0.0000433
2025-05-11 21:29:49,997 Epoch 235/500
2025-05-11 21:32:05,602 Current Learning Rate: 0.0005470542
2025-05-11 21:32:05,603 Train Loss: 0.0000391, Val Loss: 0.0000434
2025-05-11 21:32:05,604 Epoch 236/500
2025-05-11 21:34:21,183 Current Learning Rate: 0.0005439256
2025-05-11 21:34:21,183 Train Loss: 0.0000392, Val Loss: 0.0000452
2025-05-11 21:34:21,184 Epoch 237/500
2025-05-11 21:36:36,950 Current Learning Rate: 0.0005407953
2025-05-11 21:36:36,951 Train Loss: 0.0000391, Val Loss: 0.0000443
2025-05-11 21:36:36,951 Epoch 238/500
2025-05-11 21:38:52,414 Current Learning Rate: 0.0005376634
2025-05-11 21:38:52,416 Train Loss: 0.0000409, Val Loss: 0.0000468
2025-05-11 21:38:52,417 Epoch 239/500
2025-05-11 21:41:07,874 Current Learning Rate: 0.0005345300
2025-05-11 21:41:07,960 Train Loss: 0.0000409, Val Loss: 0.0000425
2025-05-11 21:41:07,961 Epoch 240/500
2025-05-11 21:43:23,420 Current Learning Rate: 0.0005313953
2025-05-11 21:43:23,421 Train Loss: 0.0000380, Val Loss: 0.0000429
2025-05-11 21:43:23,421 Epoch 241/500
2025-05-11 21:45:38,742 Current Learning Rate: 0.0005282593
2025-05-11 21:45:38,743 Train Loss: 0.0000392, Val Loss: 0.0000481
2025-05-11 21:45:38,743 Epoch 242/500
2025-05-11 21:47:54,189 Current Learning Rate: 0.0005251222
2025-05-11 21:47:54,190 Train Loss: 0.0000393, Val Loss: 0.0000431
2025-05-11 21:47:54,190 Epoch 243/500
2025-05-11 21:50:09,550 Current Learning Rate: 0.0005219841
2025-05-11 21:50:09,551 Train Loss: 0.0000394, Val Loss: 0.0000469
2025-05-11 21:50:09,551 Epoch 244/500
2025-05-11 21:52:25,058 Current Learning Rate: 0.0005188451
2025-05-11 21:52:25,059 Train Loss: 0.0000383, Val Loss: 0.0000480
2025-05-11 21:52:25,059 Epoch 245/500
2025-05-11 21:54:40,692 Current Learning Rate: 0.0005157054
2025-05-11 21:54:40,769 Train Loss: 0.0000402, Val Loss: 0.0000417
2025-05-11 21:54:40,769 Epoch 246/500
2025-05-11 21:56:56,261 Current Learning Rate: 0.0005125650
2025-05-11 21:56:56,263 Train Loss: 0.0000381, Val Loss: 0.0000433
2025-05-11 21:56:56,263 Epoch 247/500
2025-05-11 21:59:11,734 Current Learning Rate: 0.0005094242
2025-05-11 21:59:11,735 Train Loss: 0.0000388, Val Loss: 0.0000445
2025-05-11 21:59:11,736 Epoch 248/500
2025-05-11 22:01:27,228 Current Learning Rate: 0.0005062830
2025-05-11 22:01:27,229 Train Loss: 0.0000378, Val Loss: 0.0000434
2025-05-11 22:01:27,229 Epoch 249/500
2025-05-11 22:03:42,462 Current Learning Rate: 0.0005031416
2025-05-11 22:03:42,544 Train Loss: 0.0000380, Val Loss: 0.0000415
2025-05-11 22:03:42,544 Epoch 250/500
2025-05-11 22:05:57,715 Current Learning Rate: 0.0005000000
2025-05-11 22:05:57,787 Saved periodic model at epoch 250 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/TurbL1_0511_McWilliams2d_epoch_250.pth
2025-05-11 22:05:57,787 Train Loss: 0.0000373, Val Loss: 0.0000416
2025-05-11 22:05:57,788 Epoch 251/500
2025-05-11 22:08:12,976 Current Learning Rate: 0.0004968584
2025-05-11 22:08:12,978 Train Loss: 0.0000394, Val Loss: 0.0000417
2025-05-11 22:08:12,978 Epoch 252/500
2025-05-11 22:10:28,289 Current Learning Rate: 0.0004937170
2025-05-11 22:10:28,290 Train Loss: 0.0000376, Val Loss: 0.0000437
2025-05-11 22:10:28,290 Epoch 253/500
2025-05-11 22:12:43,624 Current Learning Rate: 0.0004905758
2025-05-11 22:12:43,625 Train Loss: 0.0000382, Val Loss: 0.0000421
2025-05-11 22:12:43,626 Epoch 254/500
2025-05-11 22:14:59,025 Current Learning Rate: 0.0004874350
2025-05-11 22:14:59,027 Train Loss: 0.0000383, Val Loss: 0.0000417
2025-05-11 22:14:59,027 Epoch 255/500
2025-05-11 22:17:14,367 Current Learning Rate: 0.0004842946
2025-05-11 22:17:14,440 Train Loss: 0.0000363, Val Loss: 0.0000413
2025-05-11 22:17:14,440 Epoch 256/500
2025-05-11 22:19:29,804 Current Learning Rate: 0.0004811549
2025-05-11 22:19:29,805 Train Loss: 0.0000373, Val Loss: 0.0000457
2025-05-11 22:19:29,805 Epoch 257/500
2025-05-11 22:21:45,030 Current Learning Rate: 0.0004780159
2025-05-11 22:21:45,102 Train Loss: 0.0000376, Val Loss: 0.0000404
2025-05-11 22:21:45,102 Epoch 258/500
2025-05-11 22:24:00,469 Current Learning Rate: 0.0004748778
2025-05-11 22:24:00,470 Train Loss: 0.0000375, Val Loss: 0.0000413
2025-05-11 22:24:00,470 Epoch 259/500
2025-05-11 22:26:15,758 Current Learning Rate: 0.0004717407
2025-05-11 22:26:15,759 Train Loss: 0.0000367, Val Loss: 0.0000417
2025-05-11 22:26:15,759 Epoch 260/500
2025-05-11 22:28:31,253 Current Learning Rate: 0.0004686047
2025-05-11 22:28:31,254 Train Loss: 0.0000364, Val Loss: 0.0000407
2025-05-11 22:28:31,254 Epoch 261/500
2025-05-11 22:30:46,897 Current Learning Rate: 0.0004654700
2025-05-11 22:30:46,899 Train Loss: 0.0000372, Val Loss: 0.0000430
2025-05-11 22:30:46,899 Epoch 262/500
2025-05-11 22:33:02,528 Current Learning Rate: 0.0004623366
2025-05-11 22:33:02,528 Train Loss: 0.0000360, Val Loss: 0.0000415
2025-05-11 22:33:02,529 Epoch 263/500
2025-05-11 22:35:18,167 Current Learning Rate: 0.0004592047
2025-05-11 22:35:18,168 Train Loss: 0.0000374, Val Loss: 0.0000417
2025-05-11 22:35:18,169 Epoch 264/500
2025-05-11 22:37:33,680 Current Learning Rate: 0.0004560744
2025-05-11 22:37:33,681 Train Loss: 0.0000365, Val Loss: 0.0000420
2025-05-11 22:37:33,681 Epoch 265/500
2025-05-11 22:39:48,941 Current Learning Rate: 0.0004529458
2025-05-11 22:39:48,942 Train Loss: 0.0000375, Val Loss: 0.0000409
2025-05-11 22:39:48,943 Epoch 266/500
2025-05-11 22:42:04,042 Current Learning Rate: 0.0004498191
2025-05-11 22:42:04,042 Train Loss: 0.0000358, Val Loss: 0.0000411
2025-05-11 22:42:04,043 Epoch 267/500
2025-05-11 22:44:19,323 Current Learning Rate: 0.0004466944
2025-05-11 22:44:19,324 Train Loss: 0.0000358, Val Loss: 0.0000420
2025-05-11 22:44:19,324 Epoch 268/500
2025-05-11 22:46:34,595 Current Learning Rate: 0.0004435718
2025-05-11 22:46:34,596 Train Loss: 0.0000359, Val Loss: 0.0000405
2025-05-11 22:46:34,597 Epoch 269/500
2025-05-11 22:48:50,096 Current Learning Rate: 0.0004404514
2025-05-11 22:48:50,097 Train Loss: 0.0000365, Val Loss: 0.0000404
2025-05-11 22:48:50,098 Epoch 270/500
2025-05-11 22:51:05,342 Current Learning Rate: 0.0004373334
2025-05-11 22:51:05,343 Train Loss: 0.0000352, Val Loss: 0.0000428
2025-05-11 22:51:05,343 Epoch 271/500
2025-05-11 22:53:20,890 Current Learning Rate: 0.0004342178
2025-05-11 22:53:20,979 Train Loss: 0.0000357, Val Loss: 0.0000396
2025-05-11 22:53:20,979 Epoch 272/500
2025-05-11 22:55:36,883 Current Learning Rate: 0.0004311049
2025-05-11 22:55:36,883 Train Loss: 0.0000367, Val Loss: 0.0000400
2025-05-11 22:55:36,884 Epoch 273/500
2025-05-11 22:57:52,735 Current Learning Rate: 0.0004279946
2025-05-11 22:57:52,735 Train Loss: 0.0000352, Val Loss: 0.0000501
2025-05-11 22:57:52,736 Epoch 274/500
2025-05-11 23:00:08,492 Current Learning Rate: 0.0004248872
2025-05-11 23:00:08,560 Train Loss: 0.0000350, Val Loss: 0.0000391
2025-05-11 23:00:08,560 Epoch 275/500
2025-05-11 23:02:24,144 Current Learning Rate: 0.0004217828
2025-05-11 23:02:24,145 Train Loss: 0.0000354, Val Loss: 0.0000395
2025-05-11 23:02:24,146 Epoch 276/500
2025-05-11 23:04:39,753 Current Learning Rate: 0.0004186814
2025-05-11 23:04:39,754 Train Loss: 0.0000353, Val Loss: 0.0000408
2025-05-11 23:04:39,754 Epoch 277/500
2025-05-11 23:06:55,122 Current Learning Rate: 0.0004155833
2025-05-11 23:06:55,122 Train Loss: 0.0000374, Val Loss: 0.0000435
2025-05-11 23:06:55,123 Epoch 278/500
2025-05-11 23:09:10,593 Current Learning Rate: 0.0004124885
2025-05-11 23:09:10,681 Train Loss: 0.0000347, Val Loss: 0.0000390
2025-05-11 23:09:10,682 Epoch 279/500
2025-05-11 23:11:26,265 Current Learning Rate: 0.0004093971
2025-05-11 23:11:26,266 Train Loss: 0.0000372, Val Loss: 0.0000408
2025-05-11 23:11:26,266 Epoch 280/500
2025-05-11 23:13:42,001 Current Learning Rate: 0.0004063093
2025-05-11 23:13:42,002 Train Loss: 0.0000354, Val Loss: 0.0000408
2025-05-11 23:13:42,002 Epoch 281/500
2025-05-11 23:15:57,861 Current Learning Rate: 0.0004032253
2025-05-11 23:15:57,862 Train Loss: 0.0000342, Val Loss: 0.0000392
2025-05-11 23:15:57,862 Epoch 282/500
2025-05-11 23:18:13,707 Current Learning Rate: 0.0004001450
2025-05-11 23:18:13,708 Train Loss: 0.0000350, Val Loss: 0.0000406
2025-05-11 23:18:13,708 Epoch 283/500
2025-05-11 23:20:29,491 Current Learning Rate: 0.0003970687
2025-05-11 23:20:29,491 Train Loss: 0.0000343, Val Loss: 0.0000393
2025-05-11 23:20:29,492 Epoch 284/500
2025-05-11 23:22:45,130 Current Learning Rate: 0.0003939964
2025-05-11 23:22:45,131 Train Loss: 0.0000343, Val Loss: 0.0000396
2025-05-11 23:22:45,131 Epoch 285/500
2025-05-11 23:25:00,715 Current Learning Rate: 0.0003909284
2025-05-11 23:25:00,717 Train Loss: 0.0000348, Val Loss: 0.0000391
2025-05-11 23:25:00,717 Epoch 286/500
2025-05-11 23:27:16,466 Current Learning Rate: 0.0003878646
2025-05-11 23:27:16,467 Train Loss: 0.0000340, Val Loss: 0.0000393
2025-05-11 23:27:16,468 Epoch 287/500
2025-05-11 23:29:32,372 Current Learning Rate: 0.0003848053
2025-05-11 23:29:32,373 Train Loss: 0.0000347, Val Loss: 0.0000392
2025-05-11 23:29:32,373 Epoch 288/500
2025-05-11 23:31:48,324 Current Learning Rate: 0.0003817505
2025-05-11 23:31:48,394 Train Loss: 0.0000346, Val Loss: 0.0000386
2025-05-11 23:31:48,394 Epoch 289/500
2025-05-11 23:34:04,241 Current Learning Rate: 0.0003787004
2025-05-11 23:34:04,242 Train Loss: 0.0000339, Val Loss: 0.0000393
2025-05-11 23:34:04,243 Epoch 290/500
2025-05-11 23:36:20,100 Current Learning Rate: 0.0003756551
2025-05-11 23:36:20,101 Train Loss: 0.0000343, Val Loss: 0.0000388
2025-05-11 23:36:20,101 Epoch 291/500
2025-05-11 23:38:36,348 Current Learning Rate: 0.0003726146
2025-05-11 23:38:36,420 Train Loss: 0.0000338, Val Loss: 0.0000384
2025-05-11 23:38:36,420 Epoch 292/500
2025-05-11 23:40:51,769 Current Learning Rate: 0.0003695792
2025-05-11 23:40:51,769 Train Loss: 0.0000336, Val Loss: 0.0000389
2025-05-11 23:40:51,769 Epoch 293/500
2025-05-11 23:43:06,945 Current Learning Rate: 0.0003665490
2025-05-11 23:43:07,019 Train Loss: 0.0000345, Val Loss: 0.0000380
2025-05-11 23:43:07,021 Epoch 294/500
2025-05-11 23:45:22,614 Current Learning Rate: 0.0003635240
2025-05-11 23:45:22,693 Train Loss: 0.0000335, Val Loss: 0.0000378
2025-05-11 23:45:22,694 Epoch 295/500
2025-05-11 23:47:38,418 Current Learning Rate: 0.0003605044
2025-05-11 23:47:38,418 Train Loss: 0.0000334, Val Loss: 0.0000380
2025-05-11 23:47:38,418 Epoch 296/500
2025-05-11 23:49:54,301 Current Learning Rate: 0.0003574904
2025-05-11 23:49:54,303 Train Loss: 0.0000333, Val Loss: 0.0000418
2025-05-11 23:49:54,303 Epoch 297/500
2025-05-11 23:52:09,975 Current Learning Rate: 0.0003544819
2025-05-11 23:52:10,055 Train Loss: 0.0000333, Val Loss: 0.0000374
2025-05-11 23:52:10,055 Epoch 298/500
2025-05-11 23:54:25,722 Current Learning Rate: 0.0003514792
2025-05-11 23:54:25,723 Train Loss: 0.0000334, Val Loss: 0.0000380
2025-05-11 23:54:25,723 Epoch 299/500
2025-05-11 23:56:41,345 Current Learning Rate: 0.0003484824
2025-05-11 23:56:41,346 Train Loss: 0.0000339, Val Loss: 0.0000375
2025-05-11 23:56:41,347 Epoch 300/500
2025-05-11 23:58:57,014 Current Learning Rate: 0.0003454915
2025-05-11 23:58:57,097 Saved periodic model at epoch 300 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/TurbL1_0511_McWilliams2d_epoch_300.pth
2025-05-11 23:58:57,098 Train Loss: 0.0000328, Val Loss: 0.0000378
2025-05-11 23:58:57,098 Epoch 301/500
2025-05-12 00:01:12,672 Current Learning Rate: 0.0003425067
2025-05-12 00:01:12,674 Train Loss: 0.0000342, Val Loss: 0.0000375
2025-05-12 00:01:12,675 Epoch 302/500
2025-05-12 00:03:28,282 Current Learning Rate: 0.0003395282
2025-05-12 00:03:28,284 Train Loss: 0.0000333, Val Loss: 0.0000382
2025-05-12 00:03:28,284 Epoch 303/500
2025-05-12 00:05:43,772 Current Learning Rate: 0.0003365560
2025-05-12 00:05:43,773 Train Loss: 0.0000334, Val Loss: 0.0000381
2025-05-12 00:05:43,773 Epoch 304/500
2025-05-12 00:07:58,861 Current Learning Rate: 0.0003335902
2025-05-12 00:07:58,942 Train Loss: 0.0000325, Val Loss: 0.0000372
2025-05-12 00:07:58,943 Epoch 305/500
2025-05-12 00:10:14,103 Current Learning Rate: 0.0003306310
2025-05-12 00:10:14,104 Train Loss: 0.0000326, Val Loss: 0.0000384
2025-05-12 00:10:14,105 Epoch 306/500
2025-05-12 00:12:29,278 Current Learning Rate: 0.0003276785
2025-05-12 00:12:29,279 Train Loss: 0.0000325, Val Loss: 0.0000380
2025-05-12 00:12:29,279 Epoch 307/500
2025-05-12 00:14:44,362 Current Learning Rate: 0.0003247328
2025-05-12 00:14:44,363 Train Loss: 0.0000325, Val Loss: 0.0000385
2025-05-12 00:14:44,364 Epoch 308/500
2025-05-12 00:16:59,679 Current Learning Rate: 0.0003217941
2025-05-12 00:16:59,679 Train Loss: 0.0000325, Val Loss: 0.0000393
2025-05-12 00:16:59,680 Epoch 309/500
2025-05-12 00:19:15,092 Current Learning Rate: 0.0003188623
2025-05-12 00:19:15,093 Train Loss: 0.0000332, Val Loss: 0.0000372
2025-05-12 00:19:15,093 Epoch 310/500
2025-05-12 00:21:30,613 Current Learning Rate: 0.0003159377
2025-05-12 00:21:30,695 Train Loss: 0.0000319, Val Loss: 0.0000369
2025-05-12 00:21:30,695 Epoch 311/500
2025-05-12 00:23:46,087 Current Learning Rate: 0.0003130204
2025-05-12 00:23:46,088 Train Loss: 0.0000320, Val Loss: 0.0000371
2025-05-12 00:23:46,089 Epoch 312/500
2025-05-12 00:26:01,547 Current Learning Rate: 0.0003101105
2025-05-12 00:26:01,548 Train Loss: 0.0000321, Val Loss: 0.0000372
2025-05-12 00:26:01,548 Epoch 313/500
2025-05-12 00:28:17,135 Current Learning Rate: 0.0003072080
2025-05-12 00:28:17,214 Train Loss: 0.0000318, Val Loss: 0.0000366
2025-05-12 00:28:17,214 Epoch 314/500
2025-05-12 00:30:33,611 Current Learning Rate: 0.0003043132
2025-05-12 00:30:33,612 Train Loss: 0.0000324, Val Loss: 0.0000372
2025-05-12 00:30:33,612 Epoch 315/500
2025-05-12 00:32:49,852 Current Learning Rate: 0.0003014261
2025-05-12 00:32:49,925 Train Loss: 0.0000318, Val Loss: 0.0000364
2025-05-12 00:32:49,925 Epoch 316/500
2025-05-12 00:35:05,089 Current Learning Rate: 0.0002985468
2025-05-12 00:35:05,170 Train Loss: 0.0000321, Val Loss: 0.0000363
2025-05-12 00:35:05,170 Epoch 317/500
2025-05-12 00:37:20,404 Current Learning Rate: 0.0002956755
2025-05-12 00:37:20,405 Train Loss: 0.0000319, Val Loss: 0.0000369
2025-05-12 00:37:20,405 Epoch 318/500
2025-05-12 00:39:35,578 Current Learning Rate: 0.0002928122
2025-05-12 00:39:35,579 Train Loss: 0.0000319, Val Loss: 0.0000383
2025-05-12 00:39:35,580 Epoch 319/500
2025-05-12 00:41:51,003 Current Learning Rate: 0.0002899571
2025-05-12 00:41:51,088 Train Loss: 0.0000315, Val Loss: 0.0000362
2025-05-12 00:41:51,089 Epoch 320/500
2025-05-12 00:44:06,423 Current Learning Rate: 0.0002871104
2025-05-12 00:44:06,424 Train Loss: 0.0000318, Val Loss: 0.0000363
2025-05-12 00:44:06,424 Epoch 321/500
2025-05-12 00:46:21,851 Current Learning Rate: 0.0002842720
2025-05-12 00:46:21,851 Train Loss: 0.0000325, Val Loss: 0.0000395
2025-05-12 00:46:21,852 Epoch 322/500
2025-05-12 00:48:37,439 Current Learning Rate: 0.0002814421
2025-05-12 00:48:37,440 Train Loss: 0.0000313, Val Loss: 0.0000363
2025-05-12 00:48:37,440 Epoch 323/500
2025-05-12 00:50:52,922 Current Learning Rate: 0.0002786209
2025-05-12 00:50:53,000 Train Loss: 0.0000315, Val Loss: 0.0000362
2025-05-12 00:50:53,001 Epoch 324/500
2025-05-12 00:53:08,583 Current Learning Rate: 0.0002758084
2025-05-12 00:53:08,663 Train Loss: 0.0000317, Val Loss: 0.0000361
2025-05-12 00:53:08,664 Epoch 325/500
2025-05-12 00:55:24,043 Current Learning Rate: 0.0002730048
2025-05-12 00:55:24,043 Train Loss: 0.0000312, Val Loss: 0.0000366
2025-05-12 00:55:24,044 Epoch 326/500
2025-05-12 00:57:39,607 Current Learning Rate: 0.0002702101
2025-05-12 00:57:39,608 Train Loss: 0.0000311, Val Loss: 0.0000364
2025-05-12 00:57:39,608 Epoch 327/500
2025-05-12 00:59:55,200 Current Learning Rate: 0.0002674245
2025-05-12 00:59:55,271 Train Loss: 0.0000314, Val Loss: 0.0000360
2025-05-12 00:59:55,271 Epoch 328/500
2025-05-12 01:02:11,101 Current Learning Rate: 0.0002646480
2025-05-12 01:02:11,177 Train Loss: 0.0000310, Val Loss: 0.0000359
2025-05-12 01:02:11,177 Epoch 329/500
2025-05-12 01:04:27,140 Current Learning Rate: 0.0002618809
2025-05-12 01:04:27,214 Train Loss: 0.0000308, Val Loss: 0.0000356
2025-05-12 01:04:27,214 Epoch 330/500
2025-05-12 01:06:43,037 Current Learning Rate: 0.0002591232
2025-05-12 01:06:43,039 Train Loss: 0.0000307, Val Loss: 0.0000373
2025-05-12 01:06:43,039 Epoch 331/500
2025-05-12 01:08:58,814 Current Learning Rate: 0.0002563749
2025-05-12 01:08:58,815 Train Loss: 0.0000310, Val Loss: 0.0000356
2025-05-12 01:08:58,815 Epoch 332/500
2025-05-12 01:11:14,343 Current Learning Rate: 0.0002536363
2025-05-12 01:11:14,344 Train Loss: 0.0000305, Val Loss: 0.0000358
2025-05-12 01:11:14,344 Epoch 333/500
2025-05-12 01:13:29,837 Current Learning Rate: 0.0002509074
2025-05-12 01:13:29,838 Train Loss: 0.0000312, Val Loss: 0.0000362
2025-05-12 01:13:29,838 Epoch 334/500
2025-05-12 01:15:45,196 Current Learning Rate: 0.0002481884
2025-05-12 01:15:45,196 Train Loss: 0.0000304, Val Loss: 0.0000357
2025-05-12 01:15:45,196 Epoch 335/500
2025-05-12 01:18:00,669 Current Learning Rate: 0.0002454793
2025-05-12 01:18:00,740 Train Loss: 0.0000312, Val Loss: 0.0000352
2025-05-12 01:18:00,740 Epoch 336/500
2025-05-12 01:20:16,033 Current Learning Rate: 0.0002427802
2025-05-12 01:20:16,034 Train Loss: 0.0000302, Val Loss: 0.0000358
2025-05-12 01:20:16,034 Epoch 337/500
2025-05-12 01:22:31,587 Current Learning Rate: 0.0002400913
2025-05-12 01:22:31,588 Train Loss: 0.0000303, Val Loss: 0.0000362
2025-05-12 01:22:31,588 Epoch 338/500
2025-05-12 01:24:47,176 Current Learning Rate: 0.0002374127
2025-05-12 01:24:47,178 Train Loss: 0.0000305, Val Loss: 0.0000358
2025-05-12 01:24:47,179 Epoch 339/500
2025-05-12 01:27:02,391 Current Learning Rate: 0.0002347444
2025-05-12 01:27:02,392 Train Loss: 0.0000309, Val Loss: 0.0000363
2025-05-12 01:27:02,392 Epoch 340/500
2025-05-12 01:29:17,878 Current Learning Rate: 0.0002320866
2025-05-12 01:29:17,878 Train Loss: 0.0000302, Val Loss: 0.0000359
2025-05-12 01:29:17,879 Epoch 341/500
2025-05-12 01:31:33,715 Current Learning Rate: 0.0002294394
2025-05-12 01:31:33,716 Train Loss: 0.0000300, Val Loss: 0.0000354
2025-05-12 01:31:33,716 Epoch 342/500
2025-05-12 01:33:49,511 Current Learning Rate: 0.0002268028
2025-05-12 01:33:49,511 Train Loss: 0.0000301, Val Loss: 0.0000359
2025-05-12 01:33:49,512 Epoch 343/500
2025-05-12 01:36:05,273 Current Learning Rate: 0.0002241771
2025-05-12 01:36:05,346 Train Loss: 0.0000301, Val Loss: 0.0000351
2025-05-12 01:36:05,346 Epoch 344/500
2025-05-12 01:38:20,858 Current Learning Rate: 0.0002215622
2025-05-12 01:38:20,859 Train Loss: 0.0000303, Val Loss: 0.0000355
2025-05-12 01:38:20,859 Epoch 345/500
2025-05-12 01:40:36,225 Current Learning Rate: 0.0002189583
2025-05-12 01:40:36,226 Train Loss: 0.0000303, Val Loss: 0.0000352
2025-05-12 01:40:36,226 Epoch 346/500
2025-05-12 01:42:51,607 Current Learning Rate: 0.0002163655
2025-05-12 01:42:51,608 Train Loss: 0.0000298, Val Loss: 0.0000353
2025-05-12 01:42:51,608 Epoch 347/500
2025-05-12 01:45:07,130 Current Learning Rate: 0.0002137839
2025-05-12 01:45:07,131 Train Loss: 0.0000305, Val Loss: 0.0000354
2025-05-12 01:45:07,132 Epoch 348/500
2025-05-12 01:47:22,750 Current Learning Rate: 0.0002112136
2025-05-12 01:47:22,821 Train Loss: 0.0000300, Val Loss: 0.0000348
2025-05-12 01:47:22,822 Epoch 349/500
2025-05-12 01:49:38,383 Current Learning Rate: 0.0002086548
2025-05-12 01:49:38,459 Train Loss: 0.0000296, Val Loss: 0.0000347
2025-05-12 01:49:38,459 Epoch 350/500
2025-05-12 01:51:54,074 Current Learning Rate: 0.0002061074
2025-05-12 01:51:54,142 Saved periodic model at epoch 350 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/TurbL1_0511_McWilliams2d_epoch_350.pth
2025-05-12 01:51:54,143 Train Loss: 0.0000295, Val Loss: 0.0000352
2025-05-12 01:51:54,143 Epoch 351/500
2025-05-12 01:54:09,666 Current Learning Rate: 0.0002035716
2025-05-12 01:54:09,748 Train Loss: 0.0000299, Val Loss: 0.0000347
2025-05-12 01:54:09,749 Epoch 352/500
2025-05-12 01:56:25,417 Current Learning Rate: 0.0002010475
2025-05-12 01:56:25,419 Train Loss: 0.0000294, Val Loss: 0.0000360
2025-05-12 01:56:25,419 Epoch 353/500
2025-05-12 01:58:41,089 Current Learning Rate: 0.0001985352
2025-05-12 01:58:41,089 Train Loss: 0.0000297, Val Loss: 0.0000351
2025-05-12 01:58:41,090 Epoch 354/500
2025-05-12 02:00:56,598 Current Learning Rate: 0.0001960349
2025-05-12 02:00:56,599 Train Loss: 0.0000295, Val Loss: 0.0000348
2025-05-12 02:00:56,599 Epoch 355/500
2025-05-12 02:03:12,291 Current Learning Rate: 0.0001935465
2025-05-12 02:03:12,292 Train Loss: 0.0000296, Val Loss: 0.0000355
2025-05-12 02:03:12,292 Epoch 356/500
2025-05-12 02:05:27,823 Current Learning Rate: 0.0001910702
2025-05-12 02:05:27,823 Train Loss: 0.0000291, Val Loss: 0.0000347
2025-05-12 02:05:27,823 Epoch 357/500
2025-05-12 02:07:43,156 Current Learning Rate: 0.0001886061
2025-05-12 02:07:43,157 Train Loss: 0.0000293, Val Loss: 0.0000349
2025-05-12 02:07:43,158 Epoch 358/500
2025-05-12 02:09:58,438 Current Learning Rate: 0.0001861543
2025-05-12 02:09:58,518 Train Loss: 0.0000295, Val Loss: 0.0000342
2025-05-12 02:09:58,518 Epoch 359/500
2025-05-12 02:12:13,836 Current Learning Rate: 0.0001837149
2025-05-12 02:12:13,837 Train Loss: 0.0000294, Val Loss: 0.0000350
2025-05-12 02:12:13,837 Epoch 360/500
2025-05-12 02:14:29,616 Current Learning Rate: 0.0001812880
2025-05-12 02:14:29,721 Train Loss: 0.0000295, Val Loss: 0.0000340
2025-05-12 02:14:29,722 Epoch 361/500
2025-05-12 02:16:45,379 Current Learning Rate: 0.0001788737
2025-05-12 02:16:45,468 Train Loss: 0.0000301, Val Loss: 0.0000340
2025-05-12 02:16:45,469 Epoch 362/500
2025-05-12 02:19:01,073 Current Learning Rate: 0.0001764720
2025-05-12 02:19:01,073 Train Loss: 0.0000288, Val Loss: 0.0000346
2025-05-12 02:19:01,073 Epoch 363/500
2025-05-12 02:21:16,722 Current Learning Rate: 0.0001740831
2025-05-12 02:21:16,722 Train Loss: 0.0000296, Val Loss: 0.0000341
2025-05-12 02:21:16,723 Epoch 364/500
2025-05-12 02:23:32,272 Current Learning Rate: 0.0001717071
2025-05-12 02:23:32,273 Train Loss: 0.0000289, Val Loss: 0.0000341
2025-05-12 02:23:32,273 Epoch 365/500
2025-05-12 02:25:47,776 Current Learning Rate: 0.0001693441
2025-05-12 02:25:47,777 Train Loss: 0.0000290, Val Loss: 0.0000343
2025-05-12 02:25:47,777 Epoch 366/500
2025-05-12 02:28:03,247 Current Learning Rate: 0.0001669941
2025-05-12 02:28:03,248 Train Loss: 0.0000291, Val Loss: 0.0000340
2025-05-12 02:28:03,248 Epoch 367/500
2025-05-12 02:30:18,784 Current Learning Rate: 0.0001646572
2025-05-12 02:30:18,785 Train Loss: 0.0000294, Val Loss: 0.0000345
2025-05-12 02:30:18,785 Epoch 368/500
2025-05-12 02:32:34,308 Current Learning Rate: 0.0001623336
2025-05-12 02:32:34,310 Train Loss: 0.0000285, Val Loss: 0.0000342
2025-05-12 02:32:34,311 Epoch 369/500
2025-05-12 02:34:49,823 Current Learning Rate: 0.0001600233
2025-05-12 02:34:49,824 Train Loss: 0.0000287, Val Loss: 0.0000343
2025-05-12 02:34:49,825 Epoch 370/500
2025-05-12 02:37:05,127 Current Learning Rate: 0.0001577264
2025-05-12 02:37:05,206 Train Loss: 0.0000290, Val Loss: 0.0000336
2025-05-12 02:37:05,206 Epoch 371/500
2025-05-12 02:39:20,676 Current Learning Rate: 0.0001554431
2025-05-12 02:39:20,677 Train Loss: 0.0000286, Val Loss: 0.0000340
2025-05-12 02:39:20,678 Epoch 372/500
2025-05-12 02:41:36,294 Current Learning Rate: 0.0001531733
2025-05-12 02:41:36,295 Train Loss: 0.0000285, Val Loss: 0.0000341
2025-05-12 02:41:36,296 Epoch 373/500
2025-05-12 02:43:51,728 Current Learning Rate: 0.0001509173
2025-05-12 02:43:51,728 Train Loss: 0.0000284, Val Loss: 0.0000338
2025-05-12 02:43:51,729 Epoch 374/500
2025-05-12 02:46:06,935 Current Learning Rate: 0.0001486750
2025-05-12 02:46:06,935 Train Loss: 0.0000291, Val Loss: 0.0000342
2025-05-12 02:46:06,936 Epoch 375/500
2025-05-12 02:48:22,651 Current Learning Rate: 0.0001464466
2025-05-12 02:48:22,652 Train Loss: 0.0000285, Val Loss: 0.0000341
2025-05-12 02:48:22,652 Epoch 376/500
2025-05-12 02:50:38,199 Current Learning Rate: 0.0001442322
2025-05-12 02:50:38,199 Train Loss: 0.0000286, Val Loss: 0.0000338
2025-05-12 02:50:38,199 Epoch 377/500
2025-05-12 02:52:53,625 Current Learning Rate: 0.0001420318
2025-05-12 02:52:53,626 Train Loss: 0.0000284, Val Loss: 0.0000337
2025-05-12 02:52:53,626 Epoch 378/500
2025-05-12 02:55:09,244 Current Learning Rate: 0.0001398455
2025-05-12 02:55:09,245 Train Loss: 0.0000284, Val Loss: 0.0000342
2025-05-12 02:55:09,245 Epoch 379/500
2025-05-12 02:57:24,920 Current Learning Rate: 0.0001376734
2025-05-12 02:57:24,920 Train Loss: 0.0000284, Val Loss: 0.0000340
2025-05-12 02:57:24,921 Epoch 380/500
2025-05-12 02:59:40,510 Current Learning Rate: 0.0001355157
2025-05-12 02:59:40,595 Train Loss: 0.0000284, Val Loss: 0.0000333
2025-05-12 02:59:40,595 Epoch 381/500
2025-05-12 03:01:56,145 Current Learning Rate: 0.0001333723
2025-05-12 03:01:56,147 Train Loss: 0.0000281, Val Loss: 0.0000334
2025-05-12 03:01:56,147 Epoch 382/500
2025-05-12 03:04:11,743 Current Learning Rate: 0.0001312434
2025-05-12 03:04:11,743 Train Loss: 0.0000284, Val Loss: 0.0000346
2025-05-12 03:04:11,744 Epoch 383/500
2025-05-12 03:06:27,333 Current Learning Rate: 0.0001291291
2025-05-12 03:06:27,334 Train Loss: 0.0000286, Val Loss: 0.0000337
2025-05-12 03:06:27,335 Epoch 384/500
2025-05-12 03:08:42,940 Current Learning Rate: 0.0001270294
2025-05-12 03:08:43,021 Train Loss: 0.0000281, Val Loss: 0.0000333
2025-05-12 03:08:43,022 Epoch 385/500
2025-05-12 03:10:58,867 Current Learning Rate: 0.0001249445
2025-05-12 03:10:58,868 Train Loss: 0.0000284, Val Loss: 0.0000336
2025-05-12 03:10:58,869 Epoch 386/500
2025-05-12 03:13:14,427 Current Learning Rate: 0.0001228743
2025-05-12 03:13:14,427 Train Loss: 0.0000280, Val Loss: 0.0000335
2025-05-12 03:13:14,428 Epoch 387/500
2025-05-12 03:15:30,111 Current Learning Rate: 0.0001208190
2025-05-12 03:15:30,112 Train Loss: 0.0000280, Val Loss: 0.0000336
2025-05-12 03:15:30,112 Epoch 388/500
2025-05-12 03:17:45,624 Current Learning Rate: 0.0001187787
2025-05-12 03:17:45,625 Train Loss: 0.0000278, Val Loss: 0.0000333
2025-05-12 03:17:45,625 Epoch 389/500
2025-05-12 03:20:00,801 Current Learning Rate: 0.0001167535
2025-05-12 03:20:00,881 Train Loss: 0.0000278, Val Loss: 0.0000331
2025-05-12 03:20:00,881 Epoch 390/500
2025-05-12 03:22:16,192 Current Learning Rate: 0.0001147434
2025-05-12 03:22:16,193 Train Loss: 0.0000280, Val Loss: 0.0000332
2025-05-12 03:22:16,193 Epoch 391/500
2025-05-12 03:24:31,526 Current Learning Rate: 0.0001127485
2025-05-12 03:24:31,526 Train Loss: 0.0000281, Val Loss: 0.0000337
2025-05-12 03:24:31,527 Epoch 392/500
2025-05-12 03:26:46,685 Current Learning Rate: 0.0001107688
2025-05-12 03:26:46,686 Train Loss: 0.0000283, Val Loss: 0.0000334
2025-05-12 03:26:46,686 Epoch 393/500
2025-05-12 03:29:01,897 Current Learning Rate: 0.0001088046
2025-05-12 03:29:01,974 Train Loss: 0.0000282, Val Loss: 0.0000330
2025-05-12 03:29:01,974 Epoch 394/500
2025-05-12 03:31:17,114 Current Learning Rate: 0.0001068558
2025-05-12 03:31:17,115 Train Loss: 0.0000281, Val Loss: 0.0000331
2025-05-12 03:31:17,116 Epoch 395/500
2025-05-12 03:33:32,214 Current Learning Rate: 0.0001049225
2025-05-12 03:33:32,286 Train Loss: 0.0000277, Val Loss: 0.0000329
2025-05-12 03:33:32,286 Epoch 396/500
2025-05-12 03:35:47,453 Current Learning Rate: 0.0001030048
2025-05-12 03:35:47,524 Train Loss: 0.0000276, Val Loss: 0.0000328
2025-05-12 03:35:47,525 Epoch 397/500
2025-05-12 03:38:02,724 Current Learning Rate: 0.0001011028
2025-05-12 03:38:02,724 Train Loss: 0.0000277, Val Loss: 0.0000331
2025-05-12 03:38:02,724 Epoch 398/500
2025-05-12 03:40:17,993 Current Learning Rate: 0.0000992165
2025-05-12 03:40:17,995 Train Loss: 0.0000276, Val Loss: 0.0000329
2025-05-12 03:40:17,995 Epoch 399/500
2025-05-12 03:42:33,447 Current Learning Rate: 0.0000973461
2025-05-12 03:42:33,447 Train Loss: 0.0000279, Val Loss: 0.0000330
2025-05-12 03:42:33,448 Epoch 400/500
2025-05-12 03:44:48,652 Current Learning Rate: 0.0000954915
2025-05-12 03:44:48,733 Saved periodic model at epoch 400 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/TurbL1_0511_McWilliams2d_epoch_400.pth
2025-05-12 03:44:48,734 Train Loss: 0.0000276, Val Loss: 0.0000330
2025-05-12 03:44:48,734 Epoch 401/500
2025-05-12 03:47:04,145 Current Learning Rate: 0.0000936529
2025-05-12 03:47:04,147 Train Loss: 0.0000276, Val Loss: 0.0000330
2025-05-12 03:47:04,148 Epoch 402/500
2025-05-12 03:49:19,532 Current Learning Rate: 0.0000918304
2025-05-12 03:49:19,628 Train Loss: 0.0000275, Val Loss: 0.0000327
2025-05-12 03:49:19,629 Epoch 403/500
2025-05-12 03:51:34,990 Current Learning Rate: 0.0000900239
2025-05-12 03:51:35,065 Train Loss: 0.0000274, Val Loss: 0.0000327
2025-05-12 03:51:35,065 Epoch 404/500
2025-05-12 03:53:50,729 Current Learning Rate: 0.0000882337
2025-05-12 03:53:50,730 Train Loss: 0.0000276, Val Loss: 0.0000327
2025-05-12 03:53:50,730 Epoch 405/500
2025-05-12 03:56:06,592 Current Learning Rate: 0.0000864597
2025-05-12 03:56:06,593 Train Loss: 0.0000273, Val Loss: 0.0000327
2025-05-12 03:56:06,593 Epoch 406/500
2025-05-12 03:58:22,052 Current Learning Rate: 0.0000847021
2025-05-12 03:58:22,053 Train Loss: 0.0000274, Val Loss: 0.0000327
2025-05-12 03:58:22,054 Epoch 407/500
2025-05-12 04:00:37,420 Current Learning Rate: 0.0000829608
2025-05-12 04:00:37,421 Train Loss: 0.0000271, Val Loss: 0.0000327
2025-05-12 04:00:37,421 Epoch 408/500
2025-05-12 04:02:52,746 Current Learning Rate: 0.0000812360
2025-05-12 04:02:52,823 Train Loss: 0.0000275, Val Loss: 0.0000325
2025-05-12 04:02:52,824 Epoch 409/500
2025-05-12 04:05:08,212 Current Learning Rate: 0.0000795277
2025-05-12 04:05:08,213 Train Loss: 0.0000274, Val Loss: 0.0000327
2025-05-12 04:05:08,213 Epoch 410/500
2025-05-12 04:07:23,635 Current Learning Rate: 0.0000778360
2025-05-12 04:07:23,636 Train Loss: 0.0000272, Val Loss: 0.0000326
2025-05-12 04:07:23,637 Epoch 411/500
2025-05-12 04:09:38,943 Current Learning Rate: 0.0000761610
2025-05-12 04:09:38,944 Train Loss: 0.0000271, Val Loss: 0.0000326
2025-05-12 04:09:38,944 Epoch 412/500
2025-05-12 04:11:54,128 Current Learning Rate: 0.0000745028
2025-05-12 04:11:54,199 Train Loss: 0.0000274, Val Loss: 0.0000324
2025-05-12 04:11:54,199 Epoch 413/500
2025-05-12 04:14:09,413 Current Learning Rate: 0.0000728613
2025-05-12 04:14:09,414 Train Loss: 0.0000273, Val Loss: 0.0000325
2025-05-12 04:14:09,414 Epoch 414/500
2025-05-12 04:16:24,803 Current Learning Rate: 0.0000712367
2025-05-12 04:16:24,805 Train Loss: 0.0000272, Val Loss: 0.0000325
2025-05-12 04:16:24,805 Epoch 415/500
2025-05-12 04:18:40,216 Current Learning Rate: 0.0000696290
2025-05-12 04:18:40,307 Train Loss: 0.0000272, Val Loss: 0.0000324
2025-05-12 04:18:40,307 Epoch 416/500
2025-05-12 04:20:55,576 Current Learning Rate: 0.0000680383
2025-05-12 04:20:55,643 Train Loss: 0.0000272, Val Loss: 0.0000323
2025-05-12 04:20:55,643 Epoch 417/500
2025-05-12 04:23:10,686 Current Learning Rate: 0.0000664646
2025-05-12 04:23:10,688 Train Loss: 0.0000270, Val Loss: 0.0000323
2025-05-12 04:23:10,688 Epoch 418/500
2025-05-12 04:25:25,919 Current Learning Rate: 0.0000649081
2025-05-12 04:25:25,995 Train Loss: 0.0000270, Val Loss: 0.0000322
2025-05-12 04:25:25,996 Epoch 419/500
2025-05-12 04:27:41,527 Current Learning Rate: 0.0000633688
2025-05-12 04:27:41,528 Train Loss: 0.0000272, Val Loss: 0.0000324
2025-05-12 04:27:41,528 Epoch 420/500
2025-05-12 04:29:56,927 Current Learning Rate: 0.0000618467
2025-05-12 04:29:57,038 Train Loss: 0.0000275, Val Loss: 0.0000322
2025-05-12 04:29:57,038 Epoch 421/500
2025-05-12 04:32:12,307 Current Learning Rate: 0.0000603418
2025-05-12 04:32:12,308 Train Loss: 0.0000274, Val Loss: 0.0000323
2025-05-12 04:32:12,308 Epoch 422/500
2025-05-12 04:34:27,437 Current Learning Rate: 0.0000588544
2025-05-12 04:34:27,438 Train Loss: 0.0000269, Val Loss: 0.0000324
2025-05-12 04:34:27,438 Epoch 423/500
2025-05-12 04:36:42,734 Current Learning Rate: 0.0000573843
2025-05-12 04:36:42,807 Train Loss: 0.0000268, Val Loss: 0.0000321
2025-05-12 04:36:42,808 Epoch 424/500
2025-05-12 04:38:58,008 Current Learning Rate: 0.0000559318
2025-05-12 04:38:58,091 Train Loss: 0.0000267, Val Loss: 0.0000321
2025-05-12 04:38:58,092 Epoch 425/500
2025-05-12 04:41:13,373 Current Learning Rate: 0.0000544967
2025-05-12 04:41:13,373 Train Loss: 0.0000267, Val Loss: 0.0000323
2025-05-12 04:41:13,374 Epoch 426/500
2025-05-12 04:43:28,631 Current Learning Rate: 0.0000530793
2025-05-12 04:43:28,709 Train Loss: 0.0000268, Val Loss: 0.0000321
2025-05-12 04:43:28,709 Epoch 427/500
2025-05-12 04:45:44,092 Current Learning Rate: 0.0000516795
2025-05-12 04:45:44,093 Train Loss: 0.0000268, Val Loss: 0.0000321
2025-05-12 04:45:44,093 Epoch 428/500
2025-05-12 04:47:59,587 Current Learning Rate: 0.0000502974
2025-05-12 04:47:59,588 Train Loss: 0.0000268, Val Loss: 0.0000322
2025-05-12 04:47:59,588 Epoch 429/500
2025-05-12 04:50:15,257 Current Learning Rate: 0.0000489330
2025-05-12 04:50:15,259 Train Loss: 0.0000267, Val Loss: 0.0000321
2025-05-12 04:50:15,260 Epoch 430/500
2025-05-12 04:52:31,161 Current Learning Rate: 0.0000475865
2025-05-12 04:52:31,162 Train Loss: 0.0000268, Val Loss: 0.0000322
2025-05-12 04:52:31,163 Epoch 431/500
2025-05-12 04:54:46,746 Current Learning Rate: 0.0000462578
2025-05-12 04:54:46,814 Train Loss: 0.0000267, Val Loss: 0.0000321
2025-05-12 04:54:46,814 Epoch 432/500
2025-05-12 04:57:02,163 Current Learning Rate: 0.0000449470
2025-05-12 04:57:02,163 Train Loss: 0.0000268, Val Loss: 0.0000321
2025-05-12 04:57:02,163 Epoch 433/500
2025-05-12 04:59:17,420 Current Learning Rate: 0.0000436542
2025-05-12 04:59:17,420 Train Loss: 0.0000267, Val Loss: 0.0000323
2025-05-12 04:59:17,421 Epoch 434/500
2025-05-12 05:01:32,928 Current Learning Rate: 0.0000423794
2025-05-12 05:01:32,929 Train Loss: 0.0000266, Val Loss: 0.0000324
2025-05-12 05:01:32,929 Epoch 435/500
2025-05-12 05:03:48,414 Current Learning Rate: 0.0000411227
2025-05-12 05:03:48,414 Train Loss: 0.0000266, Val Loss: 0.0000321
2025-05-12 05:03:48,414 Epoch 436/500
2025-05-12 05:06:03,859 Current Learning Rate: 0.0000398841
2025-05-12 05:06:03,859 Train Loss: 0.0000266, Val Loss: 0.0000322
2025-05-12 05:06:03,859 Epoch 437/500
2025-05-12 05:08:19,197 Current Learning Rate: 0.0000386636
2025-05-12 05:08:19,334 Train Loss: 0.0000265, Val Loss: 0.0000320
2025-05-12 05:08:19,335 Epoch 438/500
2025-05-12 05:10:34,587 Current Learning Rate: 0.0000374614
2025-05-12 05:10:34,660 Train Loss: 0.0000267, Val Loss: 0.0000319
2025-05-12 05:10:34,661 Epoch 439/500
2025-05-12 05:12:49,901 Current Learning Rate: 0.0000362774
2025-05-12 05:12:50,011 Train Loss: 0.0000264, Val Loss: 0.0000318
2025-05-12 05:12:50,011 Epoch 440/500
2025-05-12 05:15:05,234 Current Learning Rate: 0.0000351118
2025-05-12 05:15:05,234 Train Loss: 0.0000266, Val Loss: 0.0000320
2025-05-12 05:15:05,235 Epoch 441/500
2025-05-12 05:17:20,475 Current Learning Rate: 0.0000339644
2025-05-12 05:17:20,475 Train Loss: 0.0000266, Val Loss: 0.0000319
2025-05-12 05:17:20,476 Epoch 442/500
2025-05-12 05:19:35,746 Current Learning Rate: 0.0000328355
2025-05-12 05:19:35,746 Train Loss: 0.0000263, Val Loss: 0.0000320
2025-05-12 05:19:35,746 Epoch 443/500
2025-05-12 05:21:51,203 Current Learning Rate: 0.0000317251
2025-05-12 05:21:51,203 Train Loss: 0.0000268, Val Loss: 0.0000319
2025-05-12 05:21:51,204 Epoch 444/500
2025-05-12 05:24:06,558 Current Learning Rate: 0.0000306331
2025-05-12 05:24:06,559 Train Loss: 0.0000269, Val Loss: 0.0000319
2025-05-12 05:24:06,560 Epoch 445/500
2025-05-12 05:26:21,980 Current Learning Rate: 0.0000295596
2025-05-12 05:26:22,066 Train Loss: 0.0000265, Val Loss: 0.0000318
2025-05-12 05:26:22,067 Epoch 446/500
2025-05-12 05:28:37,422 Current Learning Rate: 0.0000285047
2025-05-12 05:28:37,423 Train Loss: 0.0000264, Val Loss: 0.0000319
2025-05-12 05:28:37,423 Epoch 447/500
2025-05-12 05:30:52,796 Current Learning Rate: 0.0000274685
2025-05-12 05:30:52,797 Train Loss: 0.0000264, Val Loss: 0.0000320
2025-05-12 05:30:52,797 Epoch 448/500
2025-05-12 05:33:08,094 Current Learning Rate: 0.0000264508
2025-05-12 05:33:08,095 Train Loss: 0.0000266, Val Loss: 0.0000319
2025-05-12 05:33:08,096 Epoch 449/500
2025-05-12 05:35:23,330 Current Learning Rate: 0.0000254519
2025-05-12 05:35:23,331 Train Loss: 0.0000264, Val Loss: 0.0000318
2025-05-12 05:35:23,331 Epoch 450/500
2025-05-12 05:37:38,914 Current Learning Rate: 0.0000244717
2025-05-12 05:37:39,083 Saved periodic model at epoch 450 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/TurbL1_0511_McWilliams2d_epoch_450.pth
2025-05-12 05:37:39,084 Train Loss: 0.0000263, Val Loss: 0.0000318
2025-05-12 05:37:39,084 Epoch 451/500
2025-05-12 05:39:54,760 Current Learning Rate: 0.0000235103
2025-05-12 05:39:54,761 Train Loss: 0.0000262, Val Loss: 0.0000319
2025-05-12 05:39:54,762 Epoch 452/500
2025-05-12 05:42:10,177 Current Learning Rate: 0.0000225677
2025-05-12 05:42:10,265 Train Loss: 0.0000263, Val Loss: 0.0000317
2025-05-12 05:42:10,265 Epoch 453/500
2025-05-12 05:44:25,775 Current Learning Rate: 0.0000216440
2025-05-12 05:44:25,862 Train Loss: 0.0000264, Val Loss: 0.0000317
2025-05-12 05:44:25,863 Epoch 454/500
2025-05-12 05:46:41,390 Current Learning Rate: 0.0000207391
2025-05-12 05:46:41,468 Train Loss: 0.0000263, Val Loss: 0.0000317
2025-05-12 05:46:41,468 Epoch 455/500
2025-05-12 05:48:56,970 Current Learning Rate: 0.0000198532
2025-05-12 05:48:57,051 Train Loss: 0.0000263, Val Loss: 0.0000317
2025-05-12 05:48:57,051 Epoch 456/500
2025-05-12 05:51:12,472 Current Learning Rate: 0.0000189862
2025-05-12 05:51:12,547 Train Loss: 0.0000264, Val Loss: 0.0000317
2025-05-12 05:51:12,547 Epoch 457/500
2025-05-12 05:53:27,900 Current Learning Rate: 0.0000181382
2025-05-12 05:53:27,901 Train Loss: 0.0000265, Val Loss: 0.0000318
2025-05-12 05:53:27,901 Epoch 458/500
2025-05-12 05:55:43,401 Current Learning Rate: 0.0000173092
2025-05-12 05:55:43,402 Train Loss: 0.0000263, Val Loss: 0.0000317
2025-05-12 05:55:43,402 Epoch 459/500
2025-05-12 05:57:58,882 Current Learning Rate: 0.0000164993
2025-05-12 05:57:58,883 Train Loss: 0.0000263, Val Loss: 0.0000317
2025-05-12 05:57:58,883 Epoch 460/500
2025-05-12 06:00:14,421 Current Learning Rate: 0.0000157084
2025-05-12 06:00:14,421 Train Loss: 0.0000262, Val Loss: 0.0000317
2025-05-12 06:00:14,421 Epoch 461/500
2025-05-12 06:02:29,880 Current Learning Rate: 0.0000149367
2025-05-12 06:02:29,881 Train Loss: 0.0000262, Val Loss: 0.0000317
2025-05-12 06:02:29,882 Epoch 462/500
2025-05-12 06:04:45,353 Current Learning Rate: 0.0000141841
2025-05-12 06:04:45,354 Train Loss: 0.0000263, Val Loss: 0.0000317
2025-05-12 06:04:45,354 Epoch 463/500
2025-05-12 06:07:00,879 Current Learning Rate: 0.0000134507
2025-05-12 06:07:00,952 Train Loss: 0.0000263, Val Loss: 0.0000315
2025-05-12 06:07:00,952 Epoch 464/500
2025-05-12 06:09:16,458 Current Learning Rate: 0.0000127366
2025-05-12 06:09:16,458 Train Loss: 0.0000262, Val Loss: 0.0000317
2025-05-12 06:09:16,459 Epoch 465/500
2025-05-12 06:11:32,028 Current Learning Rate: 0.0000120416
2025-05-12 06:11:32,029 Train Loss: 0.0000263, Val Loss: 0.0000317
2025-05-12 06:11:32,029 Epoch 466/500
2025-05-12 06:13:47,597 Current Learning Rate: 0.0000113659
2025-05-12 06:13:47,597 Train Loss: 0.0000262, Val Loss: 0.0000316
2025-05-12 06:13:47,597 Epoch 467/500
2025-05-12 06:16:03,379 Current Learning Rate: 0.0000107095
2025-05-12 06:16:03,380 Train Loss: 0.0000261, Val Loss: 0.0000316
2025-05-12 06:16:03,381 Epoch 468/500
2025-05-12 06:18:18,958 Current Learning Rate: 0.0000100725
2025-05-12 06:18:18,958 Train Loss: 0.0000261, Val Loss: 0.0000316
2025-05-12 06:18:18,959 Epoch 469/500
2025-05-12 06:20:34,531 Current Learning Rate: 0.0000094547
2025-05-12 06:20:34,532 Train Loss: 0.0000262, Val Loss: 0.0000316
2025-05-12 06:20:34,532 Epoch 470/500
2025-05-12 06:22:50,295 Current Learning Rate: 0.0000088564
2025-05-12 06:22:50,296 Train Loss: 0.0000264, Val Loss: 0.0000316
2025-05-12 06:22:50,296 Epoch 471/500
2025-05-12 06:25:05,865 Current Learning Rate: 0.0000082774
2025-05-12 06:25:05,867 Train Loss: 0.0000262, Val Loss: 0.0000316
2025-05-12 06:25:05,867 Epoch 472/500
2025-05-12 06:27:21,230 Current Learning Rate: 0.0000077178
2025-05-12 06:27:21,231 Train Loss: 0.0000263, Val Loss: 0.0000316
2025-05-12 06:27:21,231 Epoch 473/500
2025-05-12 06:29:36,496 Current Learning Rate: 0.0000071777
2025-05-12 06:29:36,497 Train Loss: 0.0000261, Val Loss: 0.0000316
2025-05-12 06:29:36,497 Epoch 474/500
2025-05-12 06:31:51,880 Current Learning Rate: 0.0000066570
2025-05-12 06:31:51,881 Train Loss: 0.0000262, Val Loss: 0.0000316
2025-05-12 06:31:51,881 Epoch 475/500
2025-05-12 06:34:07,169 Current Learning Rate: 0.0000061558
2025-05-12 06:34:07,169 Train Loss: 0.0000261, Val Loss: 0.0000316
2025-05-12 06:34:07,169 Epoch 476/500
2025-05-12 06:36:22,527 Current Learning Rate: 0.0000056741
2025-05-12 06:36:22,610 Train Loss: 0.0000267, Val Loss: 0.0000315
2025-05-12 06:36:22,610 Epoch 477/500
2025-05-12 06:38:38,077 Current Learning Rate: 0.0000052119
2025-05-12 06:38:38,150 Train Loss: 0.0000260, Val Loss: 0.0000315
2025-05-12 06:38:38,150 Epoch 478/500
2025-05-12 06:40:53,597 Current Learning Rate: 0.0000047693
2025-05-12 06:40:53,673 Train Loss: 0.0000263, Val Loss: 0.0000315
2025-05-12 06:40:53,674 Epoch 479/500
2025-05-12 06:43:09,309 Current Learning Rate: 0.0000043462
2025-05-12 06:43:09,383 Train Loss: 0.0000261, Val Loss: 0.0000315
2025-05-12 06:43:09,383 Epoch 480/500
2025-05-12 06:45:25,307 Current Learning Rate: 0.0000039426
2025-05-12 06:45:25,308 Train Loss: 0.0000261, Val Loss: 0.0000315
2025-05-12 06:45:25,309 Epoch 481/500
2025-05-12 06:47:41,087 Current Learning Rate: 0.0000035587
2025-05-12 06:47:41,088 Train Loss: 0.0000261, Val Loss: 0.0000315
2025-05-12 06:47:41,089 Epoch 482/500
2025-05-12 06:49:56,778 Current Learning Rate: 0.0000031943
2025-05-12 06:49:56,779 Train Loss: 0.0000261, Val Loss: 0.0000316
2025-05-12 06:49:56,780 Epoch 483/500
2025-05-12 06:52:12,253 Current Learning Rate: 0.0000028496
2025-05-12 06:52:12,254 Train Loss: 0.0000261, Val Loss: 0.0000315
2025-05-12 06:52:12,255 Epoch 484/500
2025-05-12 06:54:27,758 Current Learning Rate: 0.0000025245
2025-05-12 06:54:27,759 Train Loss: 0.0000264, Val Loss: 0.0000315
2025-05-12 06:54:27,759 Epoch 485/500
2025-05-12 06:56:43,256 Current Learning Rate: 0.0000022190
2025-05-12 06:56:43,257 Train Loss: 0.0000261, Val Loss: 0.0000315
2025-05-12 06:56:43,258 Epoch 486/500
2025-05-12 06:58:58,640 Current Learning Rate: 0.0000019332
2025-05-12 06:58:58,721 Train Loss: 0.0000262, Val Loss: 0.0000315
2025-05-12 06:58:58,722 Epoch 487/500
2025-05-12 07:01:14,292 Current Learning Rate: 0.0000016670
2025-05-12 07:01:14,293 Train Loss: 0.0000261, Val Loss: 0.0000315
2025-05-12 07:01:14,293 Epoch 488/500
2025-05-12 07:03:29,810 Current Learning Rate: 0.0000014205
2025-05-12 07:03:29,810 Train Loss: 0.0000259, Val Loss: 0.0000315
2025-05-12 07:03:29,810 Epoch 489/500
2025-05-12 07:05:45,220 Current Learning Rate: 0.0000011937
2025-05-12 07:05:45,294 Train Loss: 0.0000263, Val Loss: 0.0000315
2025-05-12 07:05:45,294 Epoch 490/500
2025-05-12 07:08:00,766 Current Learning Rate: 0.0000009866
2025-05-12 07:08:00,766 Train Loss: 0.0000260, Val Loss: 0.0000315
2025-05-12 07:08:00,767 Epoch 491/500
2025-05-12 07:10:16,214 Current Learning Rate: 0.0000007992
2025-05-12 07:10:16,215 Train Loss: 0.0000260, Val Loss: 0.0000315
2025-05-12 07:10:16,215 Epoch 492/500
2025-05-12 07:12:31,510 Current Learning Rate: 0.0000006315
2025-05-12 07:12:31,511 Train Loss: 0.0000261, Val Loss: 0.0000315
2025-05-12 07:12:31,511 Epoch 493/500
2025-05-12 07:14:46,710 Current Learning Rate: 0.0000004835
2025-05-12 07:14:46,710 Train Loss: 0.0000259, Val Loss: 0.0000315
2025-05-12 07:14:46,711 Epoch 494/500
2025-05-12 07:17:02,151 Current Learning Rate: 0.0000003553
2025-05-12 07:17:02,152 Train Loss: 0.0000264, Val Loss: 0.0000315
2025-05-12 07:17:02,152 Epoch 495/500
2025-05-12 07:19:17,428 Current Learning Rate: 0.0000002467
2025-05-12 07:19:17,430 Train Loss: 0.0000265, Val Loss: 0.0000315
2025-05-12 07:19:17,430 Epoch 496/500
2025-05-12 07:21:32,852 Current Learning Rate: 0.0000001579
2025-05-12 07:21:32,852 Train Loss: 0.0000259, Val Loss: 0.0000315
2025-05-12 07:21:32,853 Epoch 497/500
2025-05-12 07:23:48,177 Current Learning Rate: 0.0000000888
2025-05-12 07:23:48,178 Train Loss: 0.0000262, Val Loss: 0.0000315
2025-05-12 07:23:48,178 Epoch 498/500
2025-05-12 07:26:03,430 Current Learning Rate: 0.0000000395
2025-05-12 07:26:03,431 Train Loss: 0.0000261, Val Loss: 0.0000315
2025-05-12 07:26:03,431 Epoch 499/500
2025-05-12 07:28:18,679 Current Learning Rate: 0.0000000099
2025-05-12 07:28:18,680 Train Loss: 0.0000259, Val Loss: 0.0000315
2025-05-12 07:28:18,680 Epoch 500/500
2025-05-12 07:30:33,923 Current Learning Rate: 0.0000000000
2025-05-12 07:30:34,005 Saved periodic model at epoch 500 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/TurbL1_0511_McWilliams2d_epoch_500.pth
2025-05-12 07:30:34,006 Train Loss: 0.0000261, Val Loss: 0.0000315
