2025-05-12 13:31:45,854 Epoch 1/500
2025-05-12 13:32:23,764 Current Learning Rate: 0.0009999901
2025-05-12 13:32:23,986 Train Loss: 0.0402834, Val Loss: 0.0267511
2025-05-12 13:32:23,987 Epoch 2/500
2025-05-12 13:32:59,312 Current Learning Rate: 0.0009999605
2025-05-12 13:32:59,502 Train Loss: 0.0222939, Val Loss: 0.0179005
2025-05-12 13:32:59,502 Epoch 3/500
2025-05-12 13:33:35,958 Current Learning Rate: 0.0009999112
2025-05-12 13:33:36,152 Train Loss: 0.0136390, Val Loss: 0.0111934
2025-05-12 13:33:36,152 Epoch 4/500
2025-05-12 13:34:11,163 Current Learning Rate: 0.0009998421
2025-05-12 13:34:11,378 Train Loss: 0.0088909, Val Loss: 0.0083390
2025-05-12 13:34:11,378 Epoch 5/500
2025-05-12 13:34:47,798 Current Learning Rate: 0.0009997533
2025-05-12 13:34:48,049 Train Loss: 0.0068823, Val Loss: 0.0063747
2025-05-12 13:34:48,049 Epoch 6/500
2025-05-12 13:35:22,494 Current Learning Rate: 0.0009996447
2025-05-12 13:35:22,685 Train Loss: 0.0057366, Val Loss: 0.0061519
2025-05-12 13:35:22,685 Epoch 7/500
2025-05-12 13:35:58,141 Current Learning Rate: 0.0009995165
2025-05-12 13:35:58,329 Train Loss: 0.0048627, Val Loss: 0.0045712
2025-05-12 13:35:58,329 Epoch 8/500
2025-05-12 13:36:34,247 Current Learning Rate: 0.0009993685
2025-05-12 13:36:34,438 Train Loss: 0.0044396, Val Loss: 0.0041758
2025-05-12 13:36:34,439 Epoch 9/500
2025-05-12 13:37:09,429 Current Learning Rate: 0.0009992008
2025-05-12 13:37:09,625 Train Loss: 0.0039816, Val Loss: 0.0038666
2025-05-12 13:37:09,625 Epoch 10/500
2025-05-12 13:37:45,251 Current Learning Rate: 0.0009990134
2025-05-12 13:37:45,461 Train Loss: 0.0036638, Val Loss: 0.0036295
2025-05-12 13:37:45,461 Epoch 11/500
2025-05-12 13:38:20,603 Current Learning Rate: 0.0009988063
2025-05-12 13:38:20,604 Train Loss: 0.0033210, Val Loss: 0.0036547
2025-05-12 13:38:20,604 Epoch 12/500
2025-05-12 13:38:56,856 Current Learning Rate: 0.0009985795
2025-05-12 13:38:57,049 Train Loss: 0.0030895, Val Loss: 0.0032856
2025-05-12 13:38:57,049 Epoch 13/500
2025-05-12 13:39:31,790 Current Learning Rate: 0.0009983330
2025-05-12 13:39:32,001 Train Loss: 0.0029522, Val Loss: 0.0031273
2025-05-12 13:39:32,002 Epoch 14/500
2025-05-12 13:40:08,177 Current Learning Rate: 0.0009980668
2025-05-12 13:40:08,370 Train Loss: 0.0028099, Val Loss: 0.0030711
2025-05-12 13:40:08,370 Epoch 15/500
2025-05-12 13:40:43,420 Current Learning Rate: 0.0009977810
2025-05-12 13:40:43,696 Train Loss: 0.0025766, Val Loss: 0.0029325
2025-05-12 13:40:43,697 Epoch 16/500
2025-05-12 13:41:20,226 Current Learning Rate: 0.0009974755
2025-05-12 13:41:20,582 Train Loss: 0.0025251, Val Loss: 0.0025159
2025-05-12 13:41:20,583 Epoch 17/500
2025-05-12 13:41:56,980 Current Learning Rate: 0.0009971504
2025-05-12 13:41:56,981 Train Loss: 0.0023482, Val Loss: 0.0026646
2025-05-12 13:41:56,981 Epoch 18/500
2025-05-12 13:42:32,629 Current Learning Rate: 0.0009968057
2025-05-12 13:42:32,632 Train Loss: 0.0022412, Val Loss: 0.0025593
2025-05-12 13:42:32,633 Epoch 19/500
2025-05-12 13:43:09,505 Current Learning Rate: 0.0009964413
2025-05-12 13:43:09,732 Train Loss: 0.0021763, Val Loss: 0.0023696
2025-05-12 13:43:09,733 Epoch 20/500
2025-05-12 13:43:45,279 Current Learning Rate: 0.0009960574
2025-05-12 13:43:45,552 Train Loss: 0.0021549, Val Loss: 0.0022514
2025-05-12 13:43:45,552 Epoch 21/500
2025-05-12 13:44:21,642 Current Learning Rate: 0.0009956538
2025-05-12 13:44:21,874 Train Loss: 0.0020736, Val Loss: 0.0022258
2025-05-12 13:44:21,875 Epoch 22/500
2025-05-12 13:44:57,011 Current Learning Rate: 0.0009952307
2025-05-12 13:44:57,014 Train Loss: 0.0019711, Val Loss: 0.0023384
2025-05-12 13:44:57,015 Epoch 23/500
2025-05-12 13:45:33,754 Current Learning Rate: 0.0009947881
2025-05-12 13:45:33,990 Train Loss: 0.0018045, Val Loss: 0.0021534
2025-05-12 13:45:33,991 Epoch 24/500
2025-05-12 13:46:11,234 Current Learning Rate: 0.0009943259
2025-05-12 13:46:11,477 Train Loss: 0.0017591, Val Loss: 0.0020101
2025-05-12 13:46:11,478 Epoch 25/500
2025-05-12 13:46:48,378 Current Learning Rate: 0.0009938442
2025-05-12 13:46:48,378 Train Loss: 0.0016700, Val Loss: 0.0021552
2025-05-12 13:46:48,379 Epoch 26/500
2025-05-12 13:47:25,652 Current Learning Rate: 0.0009933430
2025-05-12 13:47:25,937 Train Loss: 0.0016775, Val Loss: 0.0019600
2025-05-12 13:47:25,937 Epoch 27/500
2025-05-12 13:48:02,027 Current Learning Rate: 0.0009928223
2025-05-12 13:48:02,027 Train Loss: 0.0016125, Val Loss: 0.0020615
2025-05-12 13:48:02,029 Epoch 28/500
2025-05-12 13:48:39,369 Current Learning Rate: 0.0009922822
2025-05-12 13:48:39,652 Train Loss: 0.0015245, Val Loss: 0.0018976
2025-05-12 13:48:39,653 Epoch 29/500
2025-05-12 13:49:16,316 Current Learning Rate: 0.0009917226
2025-05-12 13:49:16,317 Train Loss: 0.0015685, Val Loss: 0.0029451
2025-05-12 13:49:16,317 Epoch 30/500
2025-05-12 13:49:52,245 Current Learning Rate: 0.0009911436
2025-05-12 13:49:52,512 Train Loss: 0.0015721, Val Loss: 0.0018412
2025-05-12 13:49:52,513 Epoch 31/500
2025-05-12 13:50:30,217 Current Learning Rate: 0.0009905453
2025-05-12 13:50:30,498 Train Loss: 0.0014088, Val Loss: 0.0017135
2025-05-12 13:50:30,499 Epoch 32/500
2025-05-12 13:51:07,605 Current Learning Rate: 0.0009899275
2025-05-12 13:51:07,832 Train Loss: 0.0013478, Val Loss: 0.0015844
2025-05-12 13:51:07,832 Epoch 33/500
2025-05-12 13:51:44,587 Current Learning Rate: 0.0009892905
2025-05-12 13:51:44,587 Train Loss: 0.0013713, Val Loss: 0.0016452
2025-05-12 13:51:44,587 Epoch 34/500
2025-05-12 13:52:20,423 Current Learning Rate: 0.0009886341
2025-05-12 13:52:20,423 Train Loss: 0.0013916, Val Loss: 0.0018287
2025-05-12 13:52:20,424 Epoch 35/500
2025-05-12 13:52:57,624 Current Learning Rate: 0.0009879584
2025-05-12 13:52:57,624 Train Loss: 0.0014395, Val Loss: 0.0016058
2025-05-12 13:52:57,625 Epoch 36/500
2025-05-12 13:53:34,592 Current Learning Rate: 0.0009872634
2025-05-12 13:53:34,890 Train Loss: 0.0012297, Val Loss: 0.0015307
2025-05-12 13:53:34,890 Epoch 37/500
2025-05-12 13:54:10,438 Current Learning Rate: 0.0009865493
2025-05-12 13:54:10,438 Train Loss: 0.0013322, Val Loss: 0.0017631
2025-05-12 13:54:10,439 Epoch 38/500
2025-05-12 13:54:47,683 Current Learning Rate: 0.0009858159
2025-05-12 13:54:47,683 Train Loss: 0.0012563, Val Loss: 0.0015451
2025-05-12 13:54:47,683 Epoch 39/500
2025-05-12 13:55:23,748 Current Learning Rate: 0.0009850633
2025-05-12 13:55:23,970 Train Loss: 0.0011667, Val Loss: 0.0015084
2025-05-12 13:55:23,970 Epoch 40/500
2025-05-12 13:56:00,604 Current Learning Rate: 0.0009842916
2025-05-12 13:56:00,604 Train Loss: 0.0011693, Val Loss: 0.0017874
2025-05-12 13:56:00,604 Epoch 41/500
2025-05-12 13:56:36,803 Current Learning Rate: 0.0009835007
2025-05-12 13:56:36,803 Train Loss: 0.0012794, Val Loss: 0.0017092
2025-05-12 13:56:36,804 Epoch 42/500
2025-05-12 13:57:13,676 Current Learning Rate: 0.0009826908
2025-05-12 13:57:13,677 Train Loss: 0.0011506, Val Loss: 0.0015680
2025-05-12 13:57:13,677 Epoch 43/500
2025-05-12 13:57:50,332 Current Learning Rate: 0.0009818618
2025-05-12 13:57:50,551 Train Loss: 0.0011851, Val Loss: 0.0013539
2025-05-12 13:57:50,552 Epoch 44/500
2025-05-12 13:58:26,387 Current Learning Rate: 0.0009810138
2025-05-12 13:58:26,388 Train Loss: 0.0010556, Val Loss: 0.0014184
2025-05-12 13:58:26,388 Epoch 45/500
2025-05-12 13:59:03,332 Current Learning Rate: 0.0009801468
2025-05-12 13:59:03,332 Train Loss: 0.0010686, Val Loss: 0.0016365
2025-05-12 13:59:03,333 Epoch 46/500
2025-05-12 13:59:39,554 Current Learning Rate: 0.0009792609
2025-05-12 13:59:39,555 Train Loss: 0.0010585, Val Loss: 0.0014287
2025-05-12 13:59:39,555 Epoch 47/500
2025-05-12 14:00:18,265 Current Learning Rate: 0.0009783560
2025-05-12 14:00:18,265 Train Loss: 0.0010639, Val Loss: 0.0014011
2025-05-12 14:00:18,266 Epoch 48/500
2025-05-12 14:00:54,621 Current Learning Rate: 0.0009774323
2025-05-12 14:00:54,838 Train Loss: 0.0009956, Val Loss: 0.0012583
2025-05-12 14:00:54,838 Epoch 49/500
2025-05-12 14:01:31,509 Current Learning Rate: 0.0009764897
2025-05-12 14:01:31,510 Train Loss: 0.0009538, Val Loss: 0.0013574
2025-05-12 14:01:31,510 Epoch 50/500
2025-05-12 14:02:08,527 Current Learning Rate: 0.0009755283
2025-05-12 14:02:08,830 Saved periodic model at epoch 50 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/SimVP_0512_LiNS2d_epoch_50.pth
2025-05-12 14:02:08,831 Train Loss: 0.0010011, Val Loss: 0.0012880
2025-05-12 14:02:08,831 Epoch 51/500
2025-05-12 14:02:44,506 Current Learning Rate: 0.0009745481
2025-05-12 14:02:44,506 Train Loss: 0.0009969, Val Loss: 0.0012767
2025-05-12 14:02:44,506 Epoch 52/500
2025-05-12 14:03:20,762 Current Learning Rate: 0.0009735492
2025-05-12 14:03:20,762 Train Loss: 0.0009821, Val Loss: 0.0015067
2025-05-12 14:03:20,763 Epoch 53/500
2025-05-12 14:03:56,039 Current Learning Rate: 0.0009725315
2025-05-12 14:03:56,039 Train Loss: 0.0010163, Val Loss: 0.0013941
2025-05-12 14:03:56,039 Epoch 54/500
2025-05-12 14:04:32,317 Current Learning Rate: 0.0009714953
2025-05-12 14:04:32,318 Train Loss: 0.0009220, Val Loss: 0.0013128
2025-05-12 14:04:32,318 Epoch 55/500
2025-05-12 14:05:07,789 Current Learning Rate: 0.0009704404
2025-05-12 14:05:08,014 Train Loss: 0.0009080, Val Loss: 0.0012284
2025-05-12 14:05:08,014 Epoch 56/500
2025-05-12 14:05:43,613 Current Learning Rate: 0.0009693669
2025-05-12 14:05:43,613 Train Loss: 0.0009196, Val Loss: 0.0012429
2025-05-12 14:05:43,613 Epoch 57/500
2025-05-12 14:06:19,585 Current Learning Rate: 0.0009682749
2025-05-12 14:06:19,586 Train Loss: 0.0008888, Val Loss: 0.0014865
2025-05-12 14:06:19,587 Epoch 58/500
2025-05-12 14:06:55,689 Current Learning Rate: 0.0009671645
2025-05-12 14:06:55,689 Train Loss: 0.0009800, Val Loss: 0.0013595
2025-05-12 14:06:55,689 Epoch 59/500
2025-05-12 14:07:32,683 Current Learning Rate: 0.0009660356
2025-05-12 14:07:32,896 Train Loss: 0.0008035, Val Loss: 0.0011761
2025-05-12 14:07:32,896 Epoch 60/500
2025-05-12 14:08:07,919 Current Learning Rate: 0.0009648882
2025-05-12 14:08:07,920 Train Loss: 0.0008109, Val Loss: 0.0012800
2025-05-12 14:08:07,920 Epoch 61/500
2025-05-12 14:08:44,611 Current Learning Rate: 0.0009637226
2025-05-12 14:08:44,612 Train Loss: 0.0008685, Val Loss: 0.0011800
2025-05-12 14:08:44,612 Epoch 62/500
2025-05-12 14:09:19,572 Current Learning Rate: 0.0009625386
2025-05-12 14:09:19,573 Train Loss: 0.0008517, Val Loss: 0.0015515
2025-05-12 14:09:19,573 Epoch 63/500
2025-05-12 14:09:56,599 Current Learning Rate: 0.0009613364
2025-05-12 14:09:56,955 Train Loss: 0.0008182, Val Loss: 0.0011388
2025-05-12 14:09:56,957 Epoch 64/500
2025-05-12 14:10:33,148 Current Learning Rate: 0.0009601159
2025-05-12 14:10:33,149 Train Loss: 0.0007641, Val Loss: 0.0011823
2025-05-12 14:10:33,150 Epoch 65/500
2025-05-12 14:11:08,620 Current Learning Rate: 0.0009588773
2025-05-12 14:11:08,808 Train Loss: 0.0007434, Val Loss: 0.0011384
2025-05-12 14:11:08,808 Epoch 66/500
2025-05-12 14:11:44,306 Current Learning Rate: 0.0009576206
2025-05-12 14:11:44,307 Train Loss: 0.0007923, Val Loss: 0.0011609
2025-05-12 14:11:44,307 Epoch 67/500
2025-05-12 14:12:19,862 Current Learning Rate: 0.0009563458
2025-05-12 14:12:19,862 Train Loss: 0.0008210, Val Loss: 0.0011755
2025-05-12 14:12:19,862 Epoch 68/500
2025-05-12 14:12:56,518 Current Learning Rate: 0.0009550530
2025-05-12 14:12:56,518 Train Loss: 0.0007435, Val Loss: 0.0012358
2025-05-12 14:12:56,519 Epoch 69/500
2025-05-12 14:13:31,861 Current Learning Rate: 0.0009537422
2025-05-12 14:13:31,861 Train Loss: 0.0007747, Val Loss: 0.0011565
2025-05-12 14:13:31,861 Epoch 70/500
2025-05-12 14:14:07,959 Current Learning Rate: 0.0009524135
2025-05-12 14:14:07,960 Train Loss: 0.0007976, Val Loss: 0.0011728
2025-05-12 14:14:07,960 Epoch 71/500
2025-05-12 14:14:43,479 Current Learning Rate: 0.0009510670
2025-05-12 14:14:43,489 Train Loss: 0.0006975, Val Loss: 0.0012421
2025-05-12 14:14:43,489 Epoch 72/500
2025-05-12 14:15:20,522 Current Learning Rate: 0.0009497026
2025-05-12 14:15:20,974 Train Loss: 0.0007270, Val Loss: 0.0011070
2025-05-12 14:15:20,978 Epoch 73/500
2025-05-12 14:15:57,206 Current Learning Rate: 0.0009483205
2025-05-12 14:15:57,465 Train Loss: 0.0007108, Val Loss: 0.0011053
2025-05-12 14:15:57,466 Epoch 74/500
2025-05-12 14:16:33,669 Current Learning Rate: 0.0009469207
2025-05-12 14:16:33,670 Train Loss: 0.0006554, Val Loss: 0.0011384
2025-05-12 14:16:33,670 Epoch 75/500
2025-05-12 14:17:09,919 Current Learning Rate: 0.0009455033
2025-05-12 14:17:10,177 Train Loss: 0.0007177, Val Loss: 0.0010428
2025-05-12 14:17:10,177 Epoch 76/500
2025-05-12 14:17:45,585 Current Learning Rate: 0.0009440682
2025-05-12 14:17:45,586 Train Loss: 0.0007544, Val Loss: 0.0013418
2025-05-12 14:17:45,586 Epoch 77/500
2025-05-12 14:18:22,868 Current Learning Rate: 0.0009426157
2025-05-12 14:18:22,869 Train Loss: 0.0006957, Val Loss: 0.0011006
2025-05-12 14:18:22,869 Epoch 78/500
2025-05-12 14:18:58,579 Current Learning Rate: 0.0009411456
2025-05-12 14:18:58,580 Train Loss: 0.0006789, Val Loss: 0.0010614
2025-05-12 14:18:58,580 Epoch 79/500
2025-05-12 14:19:35,008 Current Learning Rate: 0.0009396582
2025-05-12 14:19:35,008 Train Loss: 0.0006306, Val Loss: 0.0010485
2025-05-12 14:19:35,009 Epoch 80/500
2025-05-12 14:20:11,270 Current Learning Rate: 0.0009381533
2025-05-12 14:20:11,270 Train Loss: 0.0006572, Val Loss: 0.0010882
2025-05-12 14:20:11,270 Epoch 81/500
2025-05-12 14:20:47,896 Current Learning Rate: 0.0009366312
2025-05-12 14:20:47,897 Train Loss: 0.0006860, Val Loss: 0.0010790
2025-05-12 14:20:47,898 Epoch 82/500
2025-05-12 14:21:24,678 Current Learning Rate: 0.0009350919
2025-05-12 14:21:24,679 Train Loss: 0.0007052, Val Loss: 0.0010558
2025-05-12 14:21:24,680 Epoch 83/500
2025-05-12 14:22:00,650 Current Learning Rate: 0.0009335354
2025-05-12 14:22:00,899 Train Loss: 0.0005815, Val Loss: 0.0010219
2025-05-12 14:22:00,900 Epoch 84/500
2025-05-12 14:22:37,299 Current Learning Rate: 0.0009319617
2025-05-12 14:22:37,525 Train Loss: 0.0006219, Val Loss: 0.0010184
2025-05-12 14:22:37,525 Epoch 85/500
2025-05-12 14:23:13,285 Current Learning Rate: 0.0009303710
2025-05-12 14:23:13,537 Train Loss: 0.0006181, Val Loss: 0.0009753
2025-05-12 14:23:13,537 Epoch 86/500
2025-05-12 14:23:49,628 Current Learning Rate: 0.0009287633
2025-05-12 14:23:49,628 Train Loss: 0.0005461, Val Loss: 0.0010327
2025-05-12 14:23:49,629 Epoch 87/500
2025-05-12 14:24:25,051 Current Learning Rate: 0.0009271387
2025-05-12 14:24:25,052 Train Loss: 0.0006181, Val Loss: 0.0010813
2025-05-12 14:24:25,052 Epoch 88/500
2025-05-12 14:25:01,161 Current Learning Rate: 0.0009254972
2025-05-12 14:25:01,161 Train Loss: 0.0007112, Val Loss: 0.0013735
2025-05-12 14:25:01,161 Epoch 89/500
2025-05-12 14:25:37,548 Current Learning Rate: 0.0009238390
2025-05-12 14:25:37,549 Train Loss: 0.0006316, Val Loss: 0.0009902
2025-05-12 14:25:37,549 Epoch 90/500
2025-05-12 14:26:12,108 Current Learning Rate: 0.0009221640
2025-05-12 14:26:12,108 Train Loss: 0.0005374, Val Loss: 0.0009982
2025-05-12 14:26:12,108 Epoch 91/500
2025-05-12 14:26:48,061 Current Learning Rate: 0.0009204723
2025-05-12 14:26:48,062 Train Loss: 0.0005397, Val Loss: 0.0009852
2025-05-12 14:26:48,062 Epoch 92/500
2025-05-12 14:27:22,708 Current Learning Rate: 0.0009187640
2025-05-12 14:27:22,708 Train Loss: 0.0006589, Val Loss: 0.0014373
2025-05-12 14:27:22,709 Epoch 93/500
2025-05-12 14:27:58,255 Current Learning Rate: 0.0009170392
2025-05-12 14:27:58,463 Train Loss: 0.0005974, Val Loss: 0.0009697
2025-05-12 14:27:58,463 Epoch 94/500
2025-05-12 14:28:33,540 Current Learning Rate: 0.0009152979
2025-05-12 14:28:33,753 Train Loss: 0.0006338, Val Loss: 0.0009625
2025-05-12 14:28:33,753 Epoch 95/500
2025-05-12 14:29:09,667 Current Learning Rate: 0.0009135403
2025-05-12 14:29:09,668 Train Loss: 0.0005027, Val Loss: 0.0009762
2025-05-12 14:29:09,668 Epoch 96/500
2025-05-12 14:29:45,616 Current Learning Rate: 0.0009117663
2025-05-12 14:29:45,617 Train Loss: 0.0005751, Val Loss: 0.0014995
2025-05-12 14:29:45,617 Epoch 97/500
2025-05-12 14:30:20,431 Current Learning Rate: 0.0009099761
2025-05-12 14:30:20,665 Train Loss: 0.0005681, Val Loss: 0.0009290
2025-05-12 14:30:20,665 Epoch 98/500
2025-05-12 14:30:56,541 Current Learning Rate: 0.0009081696
2025-05-12 14:30:56,541 Train Loss: 0.0004995, Val Loss: 0.0010149
2025-05-12 14:30:56,542 Epoch 99/500
2025-05-12 14:31:31,581 Current Learning Rate: 0.0009063471
2025-05-12 14:31:31,803 Train Loss: 0.0004918, Val Loss: 0.0009275
2025-05-12 14:31:31,804 Epoch 100/500
2025-05-12 14:32:07,858 Current Learning Rate: 0.0009045085
2025-05-12 14:32:08,037 Saved periodic model at epoch 100 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/SimVP_0512_LiNS2d_epoch_100.pth
2025-05-12 14:32:08,037 Train Loss: 0.0005101, Val Loss: 0.0009508
2025-05-12 14:32:08,037 Epoch 101/500
2025-05-12 14:32:43,667 Current Learning Rate: 0.0009026539
2025-05-12 14:32:43,667 Train Loss: 0.0005071, Val Loss: 0.0009638
2025-05-12 14:32:43,667 Epoch 102/500
2025-05-12 14:33:19,763 Current Learning Rate: 0.0009007835
2025-05-12 14:33:19,763 Train Loss: 0.0004915, Val Loss: 0.0009994
2025-05-12 14:33:19,764 Epoch 103/500
2025-05-12 14:33:50,988 Current Learning Rate: 0.0008988972
2025-05-12 14:33:50,989 Train Loss: 0.0005280, Val Loss: 0.0010923
2025-05-12 14:33:50,989 Epoch 104/500
2025-05-12 14:34:12,474 Current Learning Rate: 0.0008969952
2025-05-12 14:34:12,475 Train Loss: 0.0005669, Val Loss: 0.0009921
2025-05-12 14:34:12,475 Epoch 105/500
2025-05-12 14:34:34,170 Current Learning Rate: 0.0008950775
2025-05-12 14:34:34,171 Train Loss: 0.0004783, Val Loss: 0.0009769
2025-05-12 14:34:34,171 Epoch 106/500
2025-05-12 14:34:55,886 Current Learning Rate: 0.0008931442
2025-05-12 14:34:56,099 Train Loss: 0.0004758, Val Loss: 0.0009233
2025-05-12 14:34:56,099 Epoch 107/500
2025-05-12 14:35:17,631 Current Learning Rate: 0.0008911954
2025-05-12 14:35:17,632 Train Loss: 0.0005300, Val Loss: 0.0009641
2025-05-12 14:35:17,632 Epoch 108/500
2025-05-12 14:35:39,117 Current Learning Rate: 0.0008892312
2025-05-12 14:35:39,118 Train Loss: 0.0004882, Val Loss: 0.0009594
2025-05-12 14:35:39,118 Epoch 109/500
2025-05-12 14:36:00,413 Current Learning Rate: 0.0008872515
2025-05-12 14:36:00,413 Train Loss: 0.0004609, Val Loss: 0.0009607
2025-05-12 14:36:00,414 Epoch 110/500
2025-05-12 14:36:21,984 Current Learning Rate: 0.0008852566
2025-05-12 14:36:21,985 Train Loss: 0.0005234, Val Loss: 0.0010531
2025-05-12 14:36:21,985 Epoch 111/500
2025-05-12 14:36:44,187 Current Learning Rate: 0.0008832465
2025-05-12 14:36:44,187 Train Loss: 0.0005900, Val Loss: 0.0010923
2025-05-12 14:36:44,188 Epoch 112/500
2025-05-12 14:37:06,013 Current Learning Rate: 0.0008812213
2025-05-12 14:37:06,024 Train Loss: 0.0005528, Val Loss: 0.0009396
2025-05-12 14:37:06,025 Epoch 113/500
2025-05-12 14:37:28,280 Current Learning Rate: 0.0008791810
2025-05-12 14:37:28,497 Train Loss: 0.0004418, Val Loss: 0.0009009
2025-05-12 14:37:28,498 Epoch 114/500
2025-05-12 14:37:50,289 Current Learning Rate: 0.0008771257
2025-05-12 14:37:50,289 Train Loss: 0.0004027, Val Loss: 0.0009051
2025-05-12 14:37:50,290 Epoch 115/500
2025-05-12 14:38:12,967 Current Learning Rate: 0.0008750555
2025-05-12 14:38:13,176 Train Loss: 0.0004224, Val Loss: 0.0008753
2025-05-12 14:38:13,177 Epoch 116/500
2025-05-12 14:38:35,651 Current Learning Rate: 0.0008729706
2025-05-12 14:38:35,651 Train Loss: 0.0004537, Val Loss: 0.0009872
2025-05-12 14:38:35,651 Epoch 117/500
2025-05-12 14:38:57,930 Current Learning Rate: 0.0008708709
2025-05-12 14:38:57,931 Train Loss: 0.0004711, Val Loss: 0.0009309
2025-05-12 14:38:57,931 Epoch 118/500
2025-05-12 14:39:20,114 Current Learning Rate: 0.0008687566
2025-05-12 14:39:20,115 Train Loss: 0.0004128, Val Loss: 0.0009070
2025-05-12 14:39:20,115 Epoch 119/500
2025-05-12 14:39:42,632 Current Learning Rate: 0.0008666277
2025-05-12 14:39:42,632 Train Loss: 0.0004148, Val Loss: 0.0009357
2025-05-12 14:39:42,633 Epoch 120/500
2025-05-12 14:40:04,833 Current Learning Rate: 0.0008644843
2025-05-12 14:40:04,833 Train Loss: 0.0005442, Val Loss: 0.0008847
2025-05-12 14:40:04,833 Epoch 121/500
2025-05-12 14:40:26,794 Current Learning Rate: 0.0008623266
2025-05-12 14:40:26,795 Train Loss: 0.0004509, Val Loss: 0.0008982
2025-05-12 14:40:26,795 Epoch 122/500
2025-05-12 14:40:48,885 Current Learning Rate: 0.0008601545
2025-05-12 14:40:48,886 Train Loss: 0.0004158, Val Loss: 0.0009049
2025-05-12 14:40:48,886 Epoch 123/500
2025-05-12 14:41:11,079 Current Learning Rate: 0.0008579682
2025-05-12 14:41:11,080 Train Loss: 0.0004328, Val Loss: 0.0009421
2025-05-12 14:41:11,080 Epoch 124/500
2025-05-12 14:41:32,688 Current Learning Rate: 0.0008557678
2025-05-12 14:41:32,689 Train Loss: 0.0004068, Val Loss: 0.0009094
2025-05-12 14:41:32,689 Epoch 125/500
2025-05-12 14:41:54,634 Current Learning Rate: 0.0008535534
2025-05-12 14:41:54,634 Train Loss: 0.0004217, Val Loss: 0.0011453
2025-05-12 14:41:54,635 Epoch 126/500
2025-05-12 14:42:17,126 Current Learning Rate: 0.0008513250
2025-05-12 14:42:17,126 Train Loss: 0.0004570, Val Loss: 0.0009406
2025-05-12 14:42:17,126 Epoch 127/500
2025-05-12 14:42:40,023 Current Learning Rate: 0.0008490827
2025-05-12 14:42:40,024 Train Loss: 0.0003853, Val Loss: 0.0009305
2025-05-12 14:42:40,035 Epoch 128/500
2025-05-12 14:43:02,769 Current Learning Rate: 0.0008468267
2025-05-12 14:43:02,770 Train Loss: 0.0004137, Val Loss: 0.0008839
2025-05-12 14:43:02,770 Epoch 129/500
2025-05-12 14:43:24,852 Current Learning Rate: 0.0008445569
2025-05-12 14:43:24,852 Train Loss: 0.0004016, Val Loss: 0.0008805
2025-05-12 14:43:24,853 Epoch 130/500
2025-05-12 14:43:46,862 Current Learning Rate: 0.0008422736
2025-05-12 14:43:46,863 Train Loss: 0.0004249, Val Loss: 0.0009192
2025-05-12 14:43:46,863 Epoch 131/500
2025-05-12 14:44:09,139 Current Learning Rate: 0.0008399767
2025-05-12 14:44:09,139 Train Loss: 0.0004461, Val Loss: 0.0008756
2025-05-12 14:44:09,141 Epoch 132/500
2025-05-12 14:44:31,287 Current Learning Rate: 0.0008376664
2025-05-12 14:44:31,504 Train Loss: 0.0004047, Val Loss: 0.0008600
2025-05-12 14:44:31,504 Epoch 133/500
2025-05-12 14:44:53,810 Current Learning Rate: 0.0008353428
2025-05-12 14:44:53,811 Train Loss: 0.0003632, Val Loss: 0.0008642
2025-05-12 14:44:53,811 Epoch 134/500
2025-05-12 14:45:16,391 Current Learning Rate: 0.0008330059
2025-05-12 14:45:16,392 Train Loss: 0.0003852, Val Loss: 0.0008766
2025-05-12 14:45:16,392 Epoch 135/500
2025-05-12 14:45:38,676 Current Learning Rate: 0.0008306559
2025-05-12 14:45:38,872 Train Loss: 0.0003688, Val Loss: 0.0008442
2025-05-12 14:45:38,872 Epoch 136/500
2025-05-12 14:46:00,743 Current Learning Rate: 0.0008282929
2025-05-12 14:46:00,743 Train Loss: 0.0003696, Val Loss: 0.0008817
2025-05-12 14:46:00,744 Epoch 137/500
2025-05-12 14:46:23,289 Current Learning Rate: 0.0008259169
2025-05-12 14:46:23,289 Train Loss: 0.0003650, Val Loss: 0.0009641
2025-05-12 14:46:23,290 Epoch 138/500
2025-05-12 14:46:46,569 Current Learning Rate: 0.0008235280
2025-05-12 14:46:46,570 Train Loss: 0.0004002, Val Loss: 0.0008584
2025-05-12 14:46:46,570 Epoch 139/500
2025-05-12 14:47:09,466 Current Learning Rate: 0.0008211263
2025-05-12 14:47:09,704 Train Loss: 0.0003727, Val Loss: 0.0008409
2025-05-12 14:47:09,704 Epoch 140/500
2025-05-12 14:47:32,481 Current Learning Rate: 0.0008187120
2025-05-12 14:47:32,481 Train Loss: 0.0003721, Val Loss: 0.0008747
2025-05-12 14:47:32,481 Epoch 141/500
2025-05-12 14:47:54,705 Current Learning Rate: 0.0008162851
2025-05-12 14:47:54,705 Train Loss: 0.0003845, Val Loss: 0.0009105
2025-05-12 14:47:54,707 Epoch 142/500
2025-05-12 14:48:17,714 Current Learning Rate: 0.0008138457
2025-05-12 14:48:17,715 Train Loss: 0.0003677, Val Loss: 0.0008531
2025-05-12 14:48:17,715 Epoch 143/500
2025-05-12 14:48:40,666 Current Learning Rate: 0.0008113939
2025-05-12 14:48:40,666 Train Loss: 0.0003314, Val Loss: 0.0008474
2025-05-12 14:48:40,667 Epoch 144/500
2025-05-12 14:49:02,939 Current Learning Rate: 0.0008089298
2025-05-12 14:49:02,940 Train Loss: 0.0003670, Val Loss: 0.0008502
2025-05-12 14:49:02,940 Epoch 145/500
2025-05-12 14:49:24,977 Current Learning Rate: 0.0008064535
2025-05-12 14:49:24,977 Train Loss: 0.0003743, Val Loss: 0.0008692
2025-05-12 14:49:24,977 Epoch 146/500
2025-05-12 14:49:47,089 Current Learning Rate: 0.0008039651
2025-05-12 14:49:47,309 Train Loss: 0.0003609, Val Loss: 0.0008255
2025-05-12 14:49:47,310 Epoch 147/500
2025-05-12 14:50:09,512 Current Learning Rate: 0.0008014648
2025-05-12 14:50:09,716 Train Loss: 0.0003412, Val Loss: 0.0008186
2025-05-12 14:50:09,717 Epoch 148/500
2025-05-12 14:50:32,089 Current Learning Rate: 0.0007989525
2025-05-12 14:50:32,090 Train Loss: 0.0003405, Val Loss: 0.0008988
2025-05-12 14:50:32,090 Epoch 149/500
2025-05-12 14:50:54,223 Current Learning Rate: 0.0007964284
2025-05-12 14:50:54,224 Train Loss: 0.0004134, Val Loss: 0.0009314
2025-05-12 14:50:54,224 Epoch 150/500
2025-05-12 14:51:15,990 Current Learning Rate: 0.0007938926
2025-05-12 14:51:16,200 Saved periodic model at epoch 150 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/SimVP_0512_LiNS2d_epoch_150.pth
2025-05-12 14:51:16,201 Train Loss: 0.0003476, Val Loss: 0.0008396
2025-05-12 14:51:16,201 Epoch 151/500
2025-05-12 14:51:38,019 Current Learning Rate: 0.0007913452
2025-05-12 14:51:38,025 Train Loss: 0.0003768, Val Loss: 0.0009210
2025-05-12 14:51:38,026 Epoch 152/500
2025-05-12 14:51:59,665 Current Learning Rate: 0.0007887864
2025-05-12 14:51:59,666 Train Loss: 0.0003421, Val Loss: 0.0008558
2025-05-12 14:51:59,666 Epoch 153/500
2025-05-12 14:52:21,457 Current Learning Rate: 0.0007862161
2025-05-12 14:52:21,457 Train Loss: 0.0003383, Val Loss: 0.0008373
2025-05-12 14:52:21,457 Epoch 154/500
2025-05-12 14:52:43,517 Current Learning Rate: 0.0007836345
2025-05-12 14:52:43,517 Train Loss: 0.0003374, Val Loss: 0.0008862
2025-05-12 14:52:43,517 Epoch 155/500
2025-05-12 14:53:05,702 Current Learning Rate: 0.0007810417
2025-05-12 14:53:05,868 Train Loss: 0.0003319, Val Loss: 0.0008030
2025-05-12 14:53:05,868 Epoch 156/500
2025-05-12 14:53:28,307 Current Learning Rate: 0.0007784378
2025-05-12 14:53:28,309 Train Loss: 0.0002977, Val Loss: 0.0008094
2025-05-12 14:53:28,311 Epoch 157/500
2025-05-12 14:53:50,151 Current Learning Rate: 0.0007758229
2025-05-12 14:53:50,152 Train Loss: 0.0002942, Val Loss: 0.0008838
2025-05-12 14:53:50,152 Epoch 158/500
2025-05-12 14:54:11,756 Current Learning Rate: 0.0007731972
2025-05-12 14:54:11,756 Train Loss: 0.0003749, Val Loss: 0.0008658
2025-05-12 14:54:11,756 Epoch 159/500
2025-05-12 14:54:33,527 Current Learning Rate: 0.0007705606
2025-05-12 14:54:33,529 Train Loss: 0.0003271, Val Loss: 0.0008080
2025-05-12 14:54:33,529 Epoch 160/500
2025-05-12 14:54:55,471 Current Learning Rate: 0.0007679134
2025-05-12 14:54:55,688 Train Loss: 0.0003068, Val Loss: 0.0007998
2025-05-12 14:54:55,688 Epoch 161/500
2025-05-12 14:55:17,324 Current Learning Rate: 0.0007652556
2025-05-12 14:55:17,325 Train Loss: 0.0002953, Val Loss: 0.0008362
2025-05-12 14:55:17,325 Epoch 162/500
2025-05-12 14:55:39,193 Current Learning Rate: 0.0007625873
2025-05-12 14:55:39,194 Train Loss: 0.0003034, Val Loss: 0.0008564
2025-05-12 14:55:39,194 Epoch 163/500
2025-05-12 14:56:01,784 Current Learning Rate: 0.0007599087
2025-05-12 14:56:01,784 Train Loss: 0.0003572, Val Loss: 0.0009717
2025-05-12 14:56:01,785 Epoch 164/500
2025-05-12 14:56:24,581 Current Learning Rate: 0.0007572198
2025-05-12 14:56:24,582 Train Loss: 0.0003419, Val Loss: 0.0008404
2025-05-12 14:56:24,582 Epoch 165/500
2025-05-12 14:56:47,279 Current Learning Rate: 0.0007545207
2025-05-12 14:56:47,280 Train Loss: 0.0003218, Val Loss: 0.0008646
2025-05-12 14:56:47,281 Epoch 166/500
2025-05-12 14:57:09,628 Current Learning Rate: 0.0007518116
2025-05-12 14:57:09,834 Train Loss: 0.0003019, Val Loss: 0.0007833
2025-05-12 14:57:09,834 Epoch 167/500
2025-05-12 14:57:32,016 Current Learning Rate: 0.0007490926
2025-05-12 14:57:32,017 Train Loss: 0.0002898, Val Loss: 0.0008071
2025-05-12 14:57:32,017 Epoch 168/500
2025-05-12 14:57:54,135 Current Learning Rate: 0.0007463637
2025-05-12 14:57:54,135 Train Loss: 0.0002863, Val Loss: 0.0008259
2025-05-12 14:57:54,135 Epoch 169/500
2025-05-12 14:58:16,438 Current Learning Rate: 0.0007436251
2025-05-12 14:58:16,438 Train Loss: 0.0002893, Val Loss: 0.0007917
2025-05-12 14:58:16,439 Epoch 170/500
2025-05-12 14:58:38,444 Current Learning Rate: 0.0007408768
2025-05-12 14:58:38,444 Train Loss: 0.0002892, Val Loss: 0.0008127
2025-05-12 14:58:38,445 Epoch 171/500
2025-05-12 14:59:00,137 Current Learning Rate: 0.0007381191
2025-05-12 14:59:00,137 Train Loss: 0.0003054, Val Loss: 0.0008566
2025-05-12 14:59:00,137 Epoch 172/500
2025-05-12 14:59:21,752 Current Learning Rate: 0.0007353520
2025-05-12 14:59:21,753 Train Loss: 0.0003090, Val Loss: 0.0008187
2025-05-12 14:59:21,753 Epoch 173/500
2025-05-12 14:59:43,574 Current Learning Rate: 0.0007325755
2025-05-12 14:59:43,574 Train Loss: 0.0003180, Val Loss: 0.0008084
2025-05-12 14:59:43,575 Epoch 174/500
2025-05-12 15:00:05,111 Current Learning Rate: 0.0007297899
2025-05-12 15:00:05,112 Train Loss: 0.0002993, Val Loss: 0.0008019
2025-05-12 15:00:05,112 Epoch 175/500
2025-05-12 15:00:27,144 Current Learning Rate: 0.0007269952
2025-05-12 15:00:27,144 Train Loss: 0.0002831, Val Loss: 0.0007947
2025-05-12 15:00:27,145 Epoch 176/500
2025-05-12 15:00:48,924 Current Learning Rate: 0.0007241916
2025-05-12 15:00:48,924 Train Loss: 0.0002842, Val Loss: 0.0008343
2025-05-12 15:00:48,924 Epoch 177/500
2025-05-12 15:01:10,881 Current Learning Rate: 0.0007213791
2025-05-12 15:01:10,881 Train Loss: 0.0002712, Val Loss: 0.0008536
2025-05-12 15:01:10,881 Epoch 178/500
2025-05-12 15:01:32,839 Current Learning Rate: 0.0007185579
2025-05-12 15:01:32,840 Train Loss: 0.0003095, Val Loss: 0.0008082
2025-05-12 15:01:32,840 Epoch 179/500
2025-05-12 15:01:54,555 Current Learning Rate: 0.0007157280
2025-05-12 15:01:54,556 Train Loss: 0.0002849, Val Loss: 0.0008277
2025-05-12 15:01:54,556 Epoch 180/500
2025-05-12 15:02:16,159 Current Learning Rate: 0.0007128896
2025-05-12 15:02:16,159 Train Loss: 0.0002683, Val Loss: 0.0008063
2025-05-12 15:02:16,160 Epoch 181/500
2025-05-12 15:02:38,035 Current Learning Rate: 0.0007100429
2025-05-12 15:02:38,036 Train Loss: 0.0002703, Val Loss: 0.0008162
2025-05-12 15:02:38,036 Epoch 182/500
2025-05-12 15:02:59,646 Current Learning Rate: 0.0007071878
2025-05-12 15:02:59,647 Train Loss: 0.0002877, Val Loss: 0.0008202
2025-05-12 15:02:59,647 Epoch 183/500
2025-05-12 15:03:21,158 Current Learning Rate: 0.0007043245
2025-05-12 15:03:21,158 Train Loss: 0.0002914, Val Loss: 0.0007915
2025-05-12 15:03:21,159 Epoch 184/500
2025-05-12 15:03:42,814 Current Learning Rate: 0.0007014532
2025-05-12 15:03:42,814 Train Loss: 0.0002694, Val Loss: 0.0008300
2025-05-12 15:03:42,815 Epoch 185/500
2025-05-12 15:04:04,664 Current Learning Rate: 0.0006985739
2025-05-12 15:04:04,665 Train Loss: 0.0002788, Val Loss: 0.0007949
2025-05-12 15:04:04,665 Epoch 186/500
2025-05-12 15:04:26,341 Current Learning Rate: 0.0006956868
2025-05-12 15:04:26,342 Train Loss: 0.0002557, Val Loss: 0.0007978
2025-05-12 15:04:26,342 Epoch 187/500
2025-05-12 15:04:48,191 Current Learning Rate: 0.0006927920
2025-05-12 15:04:48,381 Train Loss: 0.0002463, Val Loss: 0.0007705
2025-05-12 15:04:48,381 Epoch 188/500
2025-05-12 15:05:10,078 Current Learning Rate: 0.0006898895
2025-05-12 15:05:10,283 Train Loss: 0.0002425, Val Loss: 0.0007644
2025-05-12 15:05:10,283 Epoch 189/500
2025-05-12 15:05:32,169 Current Learning Rate: 0.0006869796
2025-05-12 15:05:32,170 Train Loss: 0.0002555, Val Loss: 0.0007920
2025-05-12 15:05:32,170 Epoch 190/500
2025-05-12 15:05:53,788 Current Learning Rate: 0.0006840623
2025-05-12 15:05:53,789 Train Loss: 0.0002980, Val Loss: 0.0008130
2025-05-12 15:05:53,789 Epoch 191/500
2025-05-12 15:06:15,006 Current Learning Rate: 0.0006811377
2025-05-12 15:06:15,006 Train Loss: 0.0002728, Val Loss: 0.0007794
2025-05-12 15:06:15,006 Epoch 192/500
2025-05-12 15:06:36,361 Current Learning Rate: 0.0006782059
2025-05-12 15:06:36,362 Train Loss: 0.0002622, Val Loss: 0.0007738
2025-05-12 15:06:36,362 Epoch 193/500
2025-05-12 15:06:57,852 Current Learning Rate: 0.0006752672
2025-05-12 15:06:57,853 Train Loss: 0.0002515, Val Loss: 0.0007667
2025-05-12 15:06:57,853 Epoch 194/500
2025-05-12 15:07:19,749 Current Learning Rate: 0.0006723215
2025-05-12 15:07:19,750 Train Loss: 0.0002424, Val Loss: 0.0008107
2025-05-12 15:07:19,751 Epoch 195/500
2025-05-12 15:07:41,268 Current Learning Rate: 0.0006693690
2025-05-12 15:07:41,268 Train Loss: 0.0002720, Val Loss: 0.0007872
2025-05-12 15:07:41,268 Epoch 196/500
2025-05-12 15:08:03,110 Current Learning Rate: 0.0006664098
2025-05-12 15:08:03,111 Train Loss: 0.0002532, Val Loss: 0.0008047
2025-05-12 15:08:03,111 Epoch 197/500
2025-05-12 15:08:24,369 Current Learning Rate: 0.0006634440
2025-05-12 15:08:24,370 Train Loss: 0.0002500, Val Loss: 0.0007967
2025-05-12 15:08:24,370 Epoch 198/500
2025-05-12 15:08:45,916 Current Learning Rate: 0.0006604718
2025-05-12 15:08:45,917 Train Loss: 0.0002496, Val Loss: 0.0008035
2025-05-12 15:08:45,917 Epoch 199/500
2025-05-12 15:09:07,291 Current Learning Rate: 0.0006574933
2025-05-12 15:09:07,291 Train Loss: 0.0002587, Val Loss: 0.0007979
2025-05-12 15:09:07,291 Epoch 200/500
2025-05-12 15:09:29,147 Current Learning Rate: 0.0006545085
2025-05-12 15:09:29,507 Saved periodic model at epoch 200 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/SimVP_0512_LiNS2d_epoch_200.pth
2025-05-12 15:09:29,507 Train Loss: 0.0002503, Val Loss: 0.0007563
2025-05-12 15:09:29,507 Epoch 201/500
2025-05-12 15:09:50,945 Current Learning Rate: 0.0006515176
2025-05-12 15:09:50,945 Train Loss: 0.0002288, Val Loss: 0.0007715
2025-05-12 15:09:50,946 Epoch 202/500
2025-05-12 15:10:12,797 Current Learning Rate: 0.0006485208
2025-05-12 15:10:12,798 Train Loss: 0.0002290, Val Loss: 0.0007635
2025-05-12 15:10:12,798 Epoch 203/500
2025-05-12 15:10:34,434 Current Learning Rate: 0.0006455181
2025-05-12 15:10:34,632 Train Loss: 0.0002439, Val Loss: 0.0007430
2025-05-12 15:10:34,632 Epoch 204/500
2025-05-12 15:10:56,092 Current Learning Rate: 0.0006425096
2025-05-12 15:10:56,093 Train Loss: 0.0002250, Val Loss: 0.0007769
2025-05-12 15:10:56,093 Epoch 205/500
2025-05-12 15:11:18,085 Current Learning Rate: 0.0006394956
2025-05-12 15:11:18,086 Train Loss: 0.0002543, Val Loss: 0.0007655
2025-05-12 15:11:18,086 Epoch 206/500
2025-05-12 15:11:39,880 Current Learning Rate: 0.0006364760
2025-05-12 15:11:39,880 Train Loss: 0.0002464, Val Loss: 0.0008617
2025-05-12 15:11:39,881 Epoch 207/500
2025-05-12 15:12:01,841 Current Learning Rate: 0.0006334510
2025-05-12 15:12:01,842 Train Loss: 0.0002456, Val Loss: 0.0007620
2025-05-12 15:12:01,842 Epoch 208/500
2025-05-12 15:12:24,033 Current Learning Rate: 0.0006304208
2025-05-12 15:12:24,033 Train Loss: 0.0002449, Val Loss: 0.0007908
2025-05-12 15:12:24,034 Epoch 209/500
2025-05-12 15:12:45,866 Current Learning Rate: 0.0006273854
2025-05-12 15:12:45,867 Train Loss: 0.0002410, Val Loss: 0.0007759
2025-05-12 15:12:45,867 Epoch 210/500
2025-05-12 15:13:08,017 Current Learning Rate: 0.0006243449
2025-05-12 15:13:08,018 Train Loss: 0.0002199, Val Loss: 0.0007616
2025-05-12 15:13:08,018 Epoch 211/500
2025-05-12 15:13:30,030 Current Learning Rate: 0.0006212996
2025-05-12 15:13:30,030 Train Loss: 0.0002198, Val Loss: 0.0007473
2025-05-12 15:13:30,030 Epoch 212/500
2025-05-12 15:13:52,295 Current Learning Rate: 0.0006182495
2025-05-12 15:13:52,296 Train Loss: 0.0002216, Val Loss: 0.0007583
2025-05-12 15:13:52,296 Epoch 213/500
2025-05-12 15:14:14,515 Current Learning Rate: 0.0006151947
2025-05-12 15:14:14,515 Train Loss: 0.0002280, Val Loss: 0.0007576
2025-05-12 15:14:14,515 Epoch 214/500
2025-05-12 15:14:36,539 Current Learning Rate: 0.0006121354
2025-05-12 15:14:36,539 Train Loss: 0.0002393, Val Loss: 0.0008527
2025-05-12 15:14:36,539 Epoch 215/500
2025-05-12 15:14:58,887 Current Learning Rate: 0.0006090716
2025-05-12 15:14:59,094 Train Loss: 0.0002402, Val Loss: 0.0007330
2025-05-12 15:14:59,095 Epoch 216/500
2025-05-12 15:15:20,962 Current Learning Rate: 0.0006060036
2025-05-12 15:15:20,962 Train Loss: 0.0002210, Val Loss: 0.0007621
2025-05-12 15:15:20,962 Epoch 217/500
2025-05-12 15:15:42,900 Current Learning Rate: 0.0006029313
2025-05-12 15:15:42,901 Train Loss: 0.0002297, Val Loss: 0.0007470
2025-05-12 15:15:42,901 Epoch 218/500
2025-05-12 15:16:04,977 Current Learning Rate: 0.0005998550
2025-05-12 15:16:04,978 Train Loss: 0.0002224, Val Loss: 0.0007562
2025-05-12 15:16:04,978 Epoch 219/500
2025-05-12 15:16:26,418 Current Learning Rate: 0.0005967747
2025-05-12 15:16:26,419 Train Loss: 0.0002084, Val Loss: 0.0007728
2025-05-12 15:16:26,419 Epoch 220/500
2025-05-12 15:16:48,209 Current Learning Rate: 0.0005936907
2025-05-12 15:16:48,210 Train Loss: 0.0002010, Val Loss: 0.0007800
2025-05-12 15:16:48,210 Epoch 221/500
2025-05-12 15:17:09,732 Current Learning Rate: 0.0005906029
2025-05-12 15:17:09,732 Train Loss: 0.0002201, Val Loss: 0.0007563
2025-05-12 15:17:09,732 Epoch 222/500
2025-05-12 15:17:31,392 Current Learning Rate: 0.0005875115
2025-05-12 15:17:31,393 Train Loss: 0.0002227, Val Loss: 0.0007695
2025-05-12 15:17:31,393 Epoch 223/500
2025-05-12 15:17:52,950 Current Learning Rate: 0.0005844167
2025-05-12 15:17:52,950 Train Loss: 0.0002198, Val Loss: 0.0007387
2025-05-12 15:17:52,950 Epoch 224/500
2025-05-12 15:18:14,489 Current Learning Rate: 0.0005813186
2025-05-12 15:18:14,683 Train Loss: 0.0002016, Val Loss: 0.0007316
2025-05-12 15:18:14,684 Epoch 225/500
2025-05-12 15:18:36,408 Current Learning Rate: 0.0005782172
2025-05-12 15:18:36,409 Train Loss: 0.0001970, Val Loss: 0.0007518
2025-05-12 15:18:36,409 Epoch 226/500
2025-05-12 15:18:57,980 Current Learning Rate: 0.0005751128
2025-05-12 15:18:57,981 Train Loss: 0.0002041, Val Loss: 0.0007559
2025-05-12 15:18:57,990 Epoch 227/500
2025-05-12 15:19:19,138 Current Learning Rate: 0.0005720054
2025-05-12 15:19:19,139 Train Loss: 0.0002104, Val Loss: 0.0007445
2025-05-12 15:19:19,139 Epoch 228/500
2025-05-12 15:19:40,408 Current Learning Rate: 0.0005688951
2025-05-12 15:19:40,409 Train Loss: 0.0002134, Val Loss: 0.0007416
2025-05-12 15:19:40,409 Epoch 229/500
2025-05-12 15:20:02,041 Current Learning Rate: 0.0005657822
2025-05-12 15:20:02,041 Train Loss: 0.0002053, Val Loss: 0.0007601
2025-05-12 15:20:02,042 Epoch 230/500
2025-05-12 15:20:23,315 Current Learning Rate: 0.0005626666
2025-05-12 15:20:23,316 Train Loss: 0.0002098, Val Loss: 0.0007321
2025-05-12 15:20:23,316 Epoch 231/500
2025-05-12 15:20:44,890 Current Learning Rate: 0.0005595486
2025-05-12 15:20:44,891 Train Loss: 0.0002075, Val Loss: 0.0007541
2025-05-12 15:20:44,891 Epoch 232/500
2025-05-12 15:21:06,238 Current Learning Rate: 0.0005564282
2025-05-12 15:21:06,670 Train Loss: 0.0001958, Val Loss: 0.0007298
2025-05-12 15:21:06,670 Epoch 233/500
2025-05-12 15:21:27,624 Current Learning Rate: 0.0005533056
2025-05-12 15:21:27,625 Train Loss: 0.0001882, Val Loss: 0.0007299
2025-05-12 15:21:27,625 Epoch 234/500
2025-05-12 15:21:49,066 Current Learning Rate: 0.0005501809
2025-05-12 15:21:49,250 Train Loss: 0.0001891, Val Loss: 0.0007294
2025-05-12 15:21:49,250 Epoch 235/500
2025-05-12 15:22:10,328 Current Learning Rate: 0.0005470542
2025-05-12 15:22:10,328 Train Loss: 0.0001952, Val Loss: 0.0007508
2025-05-12 15:22:10,329 Epoch 236/500
2025-05-12 15:22:31,821 Current Learning Rate: 0.0005439256
2025-05-12 15:22:31,822 Train Loss: 0.0002025, Val Loss: 0.0007786
2025-05-12 15:22:31,822 Epoch 237/500
2025-05-12 15:22:53,331 Current Learning Rate: 0.0005407953
2025-05-12 15:22:53,333 Train Loss: 0.0002111, Val Loss: 0.0007388
2025-05-12 15:22:53,333 Epoch 238/500
2025-05-12 15:23:14,822 Current Learning Rate: 0.0005376634
2025-05-12 15:23:14,822 Train Loss: 0.0002020, Val Loss: 0.0007447
2025-05-12 15:23:14,822 Epoch 239/500
2025-05-12 15:23:36,178 Current Learning Rate: 0.0005345300
2025-05-12 15:23:36,178 Train Loss: 0.0002044, Val Loss: 0.0007453
2025-05-12 15:23:36,178 Epoch 240/500
2025-05-12 15:23:57,695 Current Learning Rate: 0.0005313953
2025-05-12 15:23:57,860 Train Loss: 0.0002013, Val Loss: 0.0007279
2025-05-12 15:23:57,860 Epoch 241/500
2025-05-12 15:24:19,086 Current Learning Rate: 0.0005282593
2025-05-12 15:24:19,086 Train Loss: 0.0001857, Val Loss: 0.0007447
2025-05-12 15:24:19,087 Epoch 242/500
2025-05-12 15:24:40,479 Current Learning Rate: 0.0005251222
2025-05-12 15:24:40,479 Train Loss: 0.0001874, Val Loss: 0.0007396
2025-05-12 15:24:40,479 Epoch 243/500
2025-05-12 15:25:01,674 Current Learning Rate: 0.0005219841
2025-05-12 15:25:01,674 Train Loss: 0.0001770, Val Loss: 0.0007333
2025-05-12 15:25:01,674 Epoch 244/500
2025-05-12 15:25:23,035 Current Learning Rate: 0.0005188451
2025-05-12 15:25:23,035 Train Loss: 0.0001818, Val Loss: 0.0007377
2025-05-12 15:25:23,035 Epoch 245/500
2025-05-12 15:25:44,335 Current Learning Rate: 0.0005157054
2025-05-12 15:25:44,335 Train Loss: 0.0001869, Val Loss: 0.0007297
2025-05-12 15:25:44,335 Epoch 246/500
2025-05-12 15:26:05,695 Current Learning Rate: 0.0005125650
2025-05-12 15:26:05,695 Train Loss: 0.0001963, Val Loss: 0.0007280
2025-05-12 15:26:05,696 Epoch 247/500
2025-05-12 15:26:27,265 Current Learning Rate: 0.0005094242
2025-05-12 15:26:27,266 Train Loss: 0.0001886, Val Loss: 0.0007487
2025-05-12 15:26:27,266 Epoch 248/500
2025-05-12 15:26:49,415 Current Learning Rate: 0.0005062830
2025-05-12 15:26:49,415 Train Loss: 0.0001962, Val Loss: 0.0007412
2025-05-12 15:26:49,415 Epoch 249/500
2025-05-12 15:27:11,530 Current Learning Rate: 0.0005031416
2025-05-12 15:27:11,530 Train Loss: 0.0001902, Val Loss: 0.0007305
2025-05-12 15:27:11,530 Epoch 250/500
2025-05-12 15:27:33,096 Current Learning Rate: 0.0005000000
2025-05-12 15:27:33,267 Saved periodic model at epoch 250 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/SimVP_0512_LiNS2d_epoch_250.pth
2025-05-12 15:27:33,268 Train Loss: 0.0001944, Val Loss: 0.0007332
2025-05-12 15:27:33,268 Epoch 251/500
2025-05-12 15:27:54,708 Current Learning Rate: 0.0004968584
2025-05-12 15:27:54,906 Train Loss: 0.0001751, Val Loss: 0.0007254
2025-05-12 15:27:54,907 Epoch 252/500
2025-05-12 15:28:16,768 Current Learning Rate: 0.0004937170
2025-05-12 15:28:16,768 Train Loss: 0.0001737, Val Loss: 0.0007288
2025-05-12 15:28:16,769 Epoch 253/500
2025-05-12 15:28:38,848 Current Learning Rate: 0.0004905758
2025-05-12 15:28:38,848 Train Loss: 0.0001731, Val Loss: 0.0007372
2025-05-12 15:28:38,848 Epoch 254/500
2025-05-12 15:29:00,898 Current Learning Rate: 0.0004874350
2025-05-12 15:29:00,899 Train Loss: 0.0001710, Val Loss: 0.0007401
2025-05-12 15:29:00,899 Epoch 255/500
2025-05-12 15:29:22,418 Current Learning Rate: 0.0004842946
2025-05-12 15:29:22,418 Train Loss: 0.0001702, Val Loss: 0.0007309
2025-05-12 15:29:22,419 Epoch 256/500
2025-05-12 15:29:44,156 Current Learning Rate: 0.0004811549
2025-05-12 15:29:44,157 Train Loss: 0.0001735, Val Loss: 0.0007316
2025-05-12 15:29:44,157 Epoch 257/500
2025-05-12 15:30:05,905 Current Learning Rate: 0.0004780159
2025-05-12 15:30:06,083 Train Loss: 0.0001667, Val Loss: 0.0007222
2025-05-12 15:30:06,084 Epoch 258/500
2025-05-12 15:30:27,812 Current Learning Rate: 0.0004748778
2025-05-12 15:30:27,813 Train Loss: 0.0001683, Val Loss: 0.0007236
2025-05-12 15:30:27,813 Epoch 259/500
2025-05-12 15:30:49,799 Current Learning Rate: 0.0004717407
2025-05-12 15:30:49,800 Train Loss: 0.0001675, Val Loss: 0.0007343
2025-05-12 15:30:49,800 Epoch 260/500
2025-05-12 15:31:12,036 Current Learning Rate: 0.0004686047
2025-05-12 15:31:12,037 Train Loss: 0.0001750, Val Loss: 0.0007409
2025-05-12 15:31:12,037 Epoch 261/500
2025-05-12 15:31:34,070 Current Learning Rate: 0.0004654700
2025-05-12 15:31:34,071 Train Loss: 0.0001800, Val Loss: 0.0007288
2025-05-12 15:31:34,071 Epoch 262/500
2025-05-12 15:31:56,078 Current Learning Rate: 0.0004623366
2025-05-12 15:31:56,079 Train Loss: 0.0001745, Val Loss: 0.0007326
2025-05-12 15:31:56,079 Epoch 263/500
2025-05-12 15:32:17,831 Current Learning Rate: 0.0004592047
2025-05-12 15:32:17,833 Train Loss: 0.0001782, Val Loss: 0.0007324
2025-05-12 15:32:17,834 Epoch 264/500
2025-05-12 15:32:39,992 Current Learning Rate: 0.0004560744
2025-05-12 15:32:39,993 Train Loss: 0.0001744, Val Loss: 0.0007262
2025-05-12 15:32:39,993 Epoch 265/500
2025-05-12 15:33:02,188 Current Learning Rate: 0.0004529458
2025-05-12 15:33:02,189 Train Loss: 0.0001784, Val Loss: 0.0007245
2025-05-12 15:33:02,189 Epoch 266/500
2025-05-12 15:33:24,395 Current Learning Rate: 0.0004498191
2025-05-12 15:33:24,578 Train Loss: 0.0001689, Val Loss: 0.0007198
2025-05-12 15:33:24,578 Epoch 267/500
2025-05-12 15:33:46,558 Current Learning Rate: 0.0004466944
2025-05-12 15:33:46,559 Train Loss: 0.0001646, Val Loss: 0.0007217
2025-05-12 15:33:46,559 Epoch 268/500
2025-05-12 15:34:08,545 Current Learning Rate: 0.0004435718
2025-05-12 15:34:08,546 Train Loss: 0.0001646, Val Loss: 0.0007209
2025-05-12 15:34:08,546 Epoch 269/500
2025-05-12 15:34:30,716 Current Learning Rate: 0.0004404514
2025-05-12 15:34:30,717 Train Loss: 0.0001628, Val Loss: 0.0007244
2025-05-12 15:34:30,717 Epoch 270/500
2025-05-12 15:34:52,514 Current Learning Rate: 0.0004373334
2025-05-12 15:34:52,702 Train Loss: 0.0001602, Val Loss: 0.0007138
2025-05-12 15:34:52,702 Epoch 271/500
2025-05-12 15:35:14,911 Current Learning Rate: 0.0004342178
2025-05-12 15:35:14,911 Train Loss: 0.0001630, Val Loss: 0.0007280
2025-05-12 15:35:14,912 Epoch 272/500
2025-05-12 15:35:37,405 Current Learning Rate: 0.0004311049
2025-05-12 15:35:37,590 Train Loss: 0.0001597, Val Loss: 0.0007125
2025-05-12 15:35:37,591 Epoch 273/500
2025-05-12 15:35:59,552 Current Learning Rate: 0.0004279946
2025-05-12 15:35:59,553 Train Loss: 0.0001588, Val Loss: 0.0007143
2025-05-12 15:35:59,553 Epoch 274/500
2025-05-12 15:36:21,425 Current Learning Rate: 0.0004248872
2025-05-12 15:36:21,426 Train Loss: 0.0001581, Val Loss: 0.0007137
2025-05-12 15:36:21,427 Epoch 275/500
2025-05-12 15:36:43,228 Current Learning Rate: 0.0004217828
2025-05-12 15:36:43,229 Train Loss: 0.0001592, Val Loss: 0.0007197
2025-05-12 15:36:43,229 Epoch 276/500
2025-05-12 15:37:05,197 Current Learning Rate: 0.0004186814
2025-05-12 15:37:05,198 Train Loss: 0.0001549, Val Loss: 0.0007159
2025-05-12 15:37:05,198 Epoch 277/500
2025-05-12 15:37:27,216 Current Learning Rate: 0.0004155833
2025-05-12 15:37:27,217 Train Loss: 0.0001598, Val Loss: 0.0007134
2025-05-12 15:37:27,218 Epoch 278/500
2025-05-12 15:37:49,393 Current Learning Rate: 0.0004124885
2025-05-12 15:37:49,394 Train Loss: 0.0001570, Val Loss: 0.0007263
2025-05-12 15:37:49,394 Epoch 279/500
2025-05-12 15:38:11,152 Current Learning Rate: 0.0004093971
2025-05-12 15:38:11,153 Train Loss: 0.0001546, Val Loss: 0.0007217
2025-05-12 15:38:11,153 Epoch 280/500
2025-05-12 15:38:32,906 Current Learning Rate: 0.0004063093
2025-05-12 15:38:32,907 Train Loss: 0.0001565, Val Loss: 0.0007199
2025-05-12 15:38:32,907 Epoch 281/500
2025-05-12 15:38:54,979 Current Learning Rate: 0.0004032253
2025-05-12 15:38:54,979 Train Loss: 0.0001656, Val Loss: 0.0007132
2025-05-12 15:38:54,979 Epoch 282/500
2025-05-12 15:39:17,039 Current Learning Rate: 0.0004001450
2025-05-12 15:39:17,039 Train Loss: 0.0001529, Val Loss: 0.0007141
2025-05-12 15:39:17,040 Epoch 283/500
2025-05-12 15:39:39,166 Current Learning Rate: 0.0003970687
2025-05-12 15:39:39,342 Train Loss: 0.0001512, Val Loss: 0.0007095
2025-05-12 15:39:39,342 Epoch 284/500
2025-05-12 15:40:01,770 Current Learning Rate: 0.0003939964
2025-05-12 15:40:02,652 Train Loss: 0.0001522, Val Loss: 0.0007059
2025-05-12 15:40:02,652 Epoch 285/500
2025-05-12 15:40:24,911 Current Learning Rate: 0.0003909284
2025-05-12 15:40:24,913 Train Loss: 0.0001421, Val Loss: 0.0007141
2025-05-12 15:40:24,914 Epoch 286/500
2025-05-12 15:40:47,207 Current Learning Rate: 0.0003878646
2025-05-12 15:40:47,208 Train Loss: 0.0001401, Val Loss: 0.0007080
2025-05-12 15:40:47,209 Epoch 287/500
2025-05-12 15:41:09,085 Current Learning Rate: 0.0003848053
2025-05-12 15:41:09,085 Train Loss: 0.0001479, Val Loss: 0.0007146
2025-05-12 15:41:09,086 Epoch 288/500
2025-05-12 15:41:30,915 Current Learning Rate: 0.0003817505
2025-05-12 15:41:30,916 Train Loss: 0.0001489, Val Loss: 0.0007159
2025-05-12 15:41:30,916 Epoch 289/500
2025-05-12 15:41:52,873 Current Learning Rate: 0.0003787004
2025-05-12 15:41:52,874 Train Loss: 0.0001503, Val Loss: 0.0007173
2025-05-12 15:41:52,874 Epoch 290/500
2025-05-12 15:42:14,967 Current Learning Rate: 0.0003756551
2025-05-12 15:42:14,968 Train Loss: 0.0001433, Val Loss: 0.0007064
2025-05-12 15:42:14,968 Epoch 291/500
2025-05-12 15:42:37,223 Current Learning Rate: 0.0003726146
2025-05-12 15:42:37,223 Train Loss: 0.0001520, Val Loss: 0.0007329
2025-05-12 15:42:37,224 Epoch 292/500
2025-05-12 15:42:58,844 Current Learning Rate: 0.0003695792
2025-05-12 15:42:58,844 Train Loss: 0.0001635, Val Loss: 0.0007095
2025-05-12 15:42:58,844 Epoch 293/500
2025-05-12 15:43:20,745 Current Learning Rate: 0.0003665490
2025-05-12 15:43:20,745 Train Loss: 0.0001495, Val Loss: 0.0007169
2025-05-12 15:43:20,745 Epoch 294/500
2025-05-12 15:43:43,297 Current Learning Rate: 0.0003635240
2025-05-12 15:43:43,297 Train Loss: 0.0001456, Val Loss: 0.0007083
2025-05-12 15:43:43,297 Epoch 295/500
2025-05-12 15:44:05,429 Current Learning Rate: 0.0003605044
2025-05-12 15:44:05,615 Train Loss: 0.0001399, Val Loss: 0.0007052
2025-05-12 15:44:05,616 Epoch 296/500
2025-05-12 15:44:27,795 Current Learning Rate: 0.0003574904
2025-05-12 15:44:28,010 Train Loss: 0.0001358, Val Loss: 0.0007032
2025-05-12 15:44:28,010 Epoch 297/500
2025-05-12 15:44:49,615 Current Learning Rate: 0.0003544819
2025-05-12 15:44:49,615 Train Loss: 0.0001420, Val Loss: 0.0007051
2025-05-12 15:44:49,615 Epoch 298/500
2025-05-12 15:45:11,280 Current Learning Rate: 0.0003514792
2025-05-12 15:45:11,280 Train Loss: 0.0001375, Val Loss: 0.0007046
2025-05-12 15:45:11,280 Epoch 299/500
2025-05-12 15:45:33,310 Current Learning Rate: 0.0003484824
2025-05-12 15:45:33,310 Train Loss: 0.0001329, Val Loss: 0.0007081
2025-05-12 15:45:33,311 Epoch 300/500
2025-05-12 15:45:55,137 Current Learning Rate: 0.0003454915
2025-05-12 15:45:55,714 Saved periodic model at epoch 300 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/SimVP_0512_LiNS2d_epoch_300.pth
2025-05-12 15:45:55,714 Train Loss: 0.0001327, Val Loss: 0.0007025
2025-05-12 15:45:55,714 Epoch 301/500
2025-05-12 15:46:17,592 Current Learning Rate: 0.0003425067
2025-05-12 15:46:17,592 Train Loss: 0.0001329, Val Loss: 0.0007108
2025-05-12 15:46:17,592 Epoch 302/500
2025-05-12 15:46:39,566 Current Learning Rate: 0.0003395282
2025-05-12 15:46:39,567 Train Loss: 0.0001405, Val Loss: 0.0007152
2025-05-12 15:46:39,567 Epoch 303/500
2025-05-12 15:47:01,814 Current Learning Rate: 0.0003365560
2025-05-12 15:47:01,814 Train Loss: 0.0001405, Val Loss: 0.0007074
2025-05-12 15:47:01,815 Epoch 304/500
2025-05-12 15:47:23,645 Current Learning Rate: 0.0003335902
2025-05-12 15:47:23,645 Train Loss: 0.0001387, Val Loss: 0.0007176
2025-05-12 15:47:23,645 Epoch 305/500
2025-05-12 15:47:45,491 Current Learning Rate: 0.0003306310
2025-05-12 15:47:45,747 Train Loss: 0.0001428, Val Loss: 0.0007025
2025-05-12 15:47:45,748 Epoch 306/500
2025-05-12 15:48:08,171 Current Learning Rate: 0.0003276785
2025-05-12 15:48:08,171 Train Loss: 0.0001394, Val Loss: 0.0007073
2025-05-12 15:48:08,171 Epoch 307/500
2025-05-12 15:48:29,794 Current Learning Rate: 0.0003247328
2025-05-12 15:48:29,794 Train Loss: 0.0001380, Val Loss: 0.0007113
2025-05-12 15:48:29,795 Epoch 308/500
2025-05-12 15:48:52,064 Current Learning Rate: 0.0003217941
2025-05-12 15:48:52,064 Train Loss: 0.0001322, Val Loss: 0.0007088
2025-05-12 15:48:52,064 Epoch 309/500
2025-05-12 15:49:13,965 Current Learning Rate: 0.0003188623
2025-05-12 15:49:13,965 Train Loss: 0.0001287, Val Loss: 0.0007149
2025-05-12 15:49:13,965 Epoch 310/500
2025-05-12 15:49:35,296 Current Learning Rate: 0.0003159377
2025-05-12 15:49:35,514 Train Loss: 0.0001292, Val Loss: 0.0007015
2025-05-12 15:49:35,515 Epoch 311/500
2025-05-12 15:49:57,150 Current Learning Rate: 0.0003130204
2025-05-12 15:49:57,355 Train Loss: 0.0001266, Val Loss: 0.0006967
2025-05-12 15:49:57,356 Epoch 312/500
2025-05-12 15:50:19,440 Current Learning Rate: 0.0003101105
2025-05-12 15:50:19,440 Train Loss: 0.0001286, Val Loss: 0.0007054
2025-05-12 15:50:19,440 Epoch 313/500
2025-05-12 15:50:41,663 Current Learning Rate: 0.0003072080
2025-05-12 15:50:41,663 Train Loss: 0.0001326, Val Loss: 0.0007027
2025-05-12 15:50:41,663 Epoch 314/500
2025-05-12 15:51:03,718 Current Learning Rate: 0.0003043132
2025-05-12 15:51:03,719 Train Loss: 0.0001283, Val Loss: 0.0007036
2025-05-12 15:51:03,719 Epoch 315/500
2025-05-12 15:51:25,406 Current Learning Rate: 0.0003014261
2025-05-12 15:51:25,406 Train Loss: 0.0001294, Val Loss: 0.0007022
2025-05-12 15:51:25,407 Epoch 316/500
2025-05-12 15:51:47,505 Current Learning Rate: 0.0002985468
2025-05-12 15:51:47,505 Train Loss: 0.0001304, Val Loss: 0.0006995
2025-05-12 15:51:47,506 Epoch 317/500
2025-05-12 15:52:09,405 Current Learning Rate: 0.0002956755
2025-05-12 15:52:09,405 Train Loss: 0.0001269, Val Loss: 0.0007039
2025-05-12 15:52:09,406 Epoch 318/500
2025-05-12 15:52:31,115 Current Learning Rate: 0.0002928122
2025-05-12 15:52:31,116 Train Loss: 0.0001279, Val Loss: 0.0007071
2025-05-12 15:52:31,116 Epoch 319/500
2025-05-12 15:52:52,521 Current Learning Rate: 0.0002899571
2025-05-12 15:52:52,522 Train Loss: 0.0001262, Val Loss: 0.0007080
2025-05-12 15:52:52,522 Epoch 320/500
2025-05-12 15:53:14,380 Current Learning Rate: 0.0002871104
2025-05-12 15:53:14,380 Train Loss: 0.0001269, Val Loss: 0.0007035
2025-05-12 15:53:14,380 Epoch 321/500
2025-05-12 15:53:35,947 Current Learning Rate: 0.0002842720
2025-05-12 15:53:35,948 Train Loss: 0.0001250, Val Loss: 0.0007026
2025-05-12 15:53:35,948 Epoch 322/500
2025-05-12 15:53:57,884 Current Learning Rate: 0.0002814421
2025-05-12 15:53:57,884 Train Loss: 0.0001255, Val Loss: 0.0007051
2025-05-12 15:53:57,884 Epoch 323/500
2025-05-12 15:54:19,874 Current Learning Rate: 0.0002786209
2025-05-12 15:54:19,875 Train Loss: 0.0001243, Val Loss: 0.0006988
2025-05-12 15:54:19,875 Epoch 324/500
2025-05-12 15:54:41,794 Current Learning Rate: 0.0002758084
2025-05-12 15:54:41,794 Train Loss: 0.0001226, Val Loss: 0.0007081
2025-05-12 15:54:41,794 Epoch 325/500
2025-05-12 15:55:03,681 Current Learning Rate: 0.0002730048
2025-05-12 15:55:03,873 Train Loss: 0.0001267, Val Loss: 0.0006962
2025-05-12 15:55:03,873 Epoch 326/500
2025-05-12 15:55:25,822 Current Learning Rate: 0.0002702101
2025-05-12 15:55:25,822 Train Loss: 0.0001225, Val Loss: 0.0007011
2025-05-12 15:55:25,822 Epoch 327/500
2025-05-12 15:55:47,764 Current Learning Rate: 0.0002674245
2025-05-12 15:55:47,764 Train Loss: 0.0001221, Val Loss: 0.0006992
2025-05-12 15:55:47,765 Epoch 328/500
2025-05-12 15:56:09,583 Current Learning Rate: 0.0002646480
2025-05-12 15:56:09,583 Train Loss: 0.0001207, Val Loss: 0.0007033
2025-05-12 15:56:09,592 Epoch 329/500
2025-05-12 15:56:30,840 Current Learning Rate: 0.0002618809
2025-05-12 15:56:30,841 Train Loss: 0.0001208, Val Loss: 0.0006999
2025-05-12 15:56:30,841 Epoch 330/500
2025-05-12 15:56:52,262 Current Learning Rate: 0.0002591232
2025-05-12 15:56:52,263 Train Loss: 0.0001200, Val Loss: 0.0007041
2025-05-12 15:56:52,263 Epoch 331/500
2025-05-12 15:57:14,036 Current Learning Rate: 0.0002563749
2025-05-12 15:57:14,036 Train Loss: 0.0001203, Val Loss: 0.0006994
2025-05-12 15:57:14,036 Epoch 332/500
2025-05-12 15:57:36,147 Current Learning Rate: 0.0002536363
2025-05-12 15:57:36,147 Train Loss: 0.0001181, Val Loss: 0.0006993
2025-05-12 15:57:36,147 Epoch 333/500
2025-05-12 15:57:58,025 Current Learning Rate: 0.0002509074
2025-05-12 15:57:58,025 Train Loss: 0.0001197, Val Loss: 0.0006993
2025-05-12 15:57:58,026 Epoch 334/500
2025-05-12 15:58:19,933 Current Learning Rate: 0.0002481884
2025-05-12 15:58:19,933 Train Loss: 0.0001223, Val Loss: 0.0007050
2025-05-12 15:58:19,934 Epoch 335/500
2025-05-12 15:58:41,505 Current Learning Rate: 0.0002454793
2025-05-12 15:58:41,505 Train Loss: 0.0001199, Val Loss: 0.0006982
2025-05-12 15:58:41,505 Epoch 336/500
2025-05-12 15:59:05,126 Current Learning Rate: 0.0002427802
2025-05-12 15:59:05,126 Train Loss: 0.0001185, Val Loss: 0.0007046
2025-05-12 15:59:05,127 Epoch 337/500
2025-05-12 15:59:26,673 Current Learning Rate: 0.0002400913
2025-05-12 15:59:26,673 Train Loss: 0.0001177, Val Loss: 0.0006963
2025-05-12 15:59:26,673 Epoch 338/500
2025-05-12 15:59:48,647 Current Learning Rate: 0.0002374127
2025-05-12 15:59:48,648 Train Loss: 0.0001176, Val Loss: 0.0007018
2025-05-12 15:59:48,648 Epoch 339/500
2025-05-12 16:00:10,476 Current Learning Rate: 0.0002347444
2025-05-12 16:00:10,476 Train Loss: 0.0001152, Val Loss: 0.0006993
2025-05-12 16:00:10,476 Epoch 340/500
2025-05-12 16:00:32,527 Current Learning Rate: 0.0002320866
2025-05-12 16:00:32,527 Train Loss: 0.0001178, Val Loss: 0.0007002
2025-05-12 16:00:32,528 Epoch 341/500
2025-05-12 16:00:54,414 Current Learning Rate: 0.0002294394
2025-05-12 16:00:54,415 Train Loss: 0.0001148, Val Loss: 0.0006982
2025-05-12 16:00:54,415 Epoch 342/500
2025-05-12 16:01:16,327 Current Learning Rate: 0.0002268028
2025-05-12 16:01:16,328 Train Loss: 0.0001125, Val Loss: 0.0006975
2025-05-12 16:01:16,328 Epoch 343/500
2025-05-12 16:01:37,973 Current Learning Rate: 0.0002241771
2025-05-12 16:01:38,148 Train Loss: 0.0001112, Val Loss: 0.0006955
2025-05-12 16:01:38,148 Epoch 344/500
2025-05-12 16:02:00,144 Current Learning Rate: 0.0002215622
2025-05-12 16:02:00,144 Train Loss: 0.0001113, Val Loss: 0.0006963
2025-05-12 16:02:00,145 Epoch 345/500
2025-05-12 16:02:23,176 Current Learning Rate: 0.0002189583
2025-05-12 16:02:23,176 Train Loss: 0.0001109, Val Loss: 0.0006992
2025-05-12 16:02:23,177 Epoch 346/500
2025-05-12 16:02:45,197 Current Learning Rate: 0.0002163655
2025-05-12 16:02:45,197 Train Loss: 0.0001127, Val Loss: 0.0007025
2025-05-12 16:02:45,197 Epoch 347/500
2025-05-12 16:03:07,379 Current Learning Rate: 0.0002137839
2025-05-12 16:03:07,553 Train Loss: 0.0001137, Val Loss: 0.0006949
2025-05-12 16:03:07,553 Epoch 348/500
2025-05-12 16:03:29,762 Current Learning Rate: 0.0002112136
2025-05-12 16:03:29,762 Train Loss: 0.0001116, Val Loss: 0.0007014
2025-05-12 16:03:29,763 Epoch 349/500
2025-05-12 16:03:52,166 Current Learning Rate: 0.0002086548
2025-05-12 16:03:52,166 Train Loss: 0.0001109, Val Loss: 0.0007017
2025-05-12 16:03:52,167 Epoch 350/500
2025-05-12 16:04:14,432 Current Learning Rate: 0.0002061074
2025-05-12 16:04:14,603 Saved periodic model at epoch 350 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/SimVP_0512_LiNS2d_epoch_350.pth
2025-05-12 16:04:14,603 Train Loss: 0.0001101, Val Loss: 0.0006995
2025-05-12 16:04:14,603 Epoch 351/500
2025-05-12 16:04:35,624 Current Learning Rate: 0.0002035716
2025-05-12 16:04:35,624 Train Loss: 0.0001117, Val Loss: 0.0006970
2025-05-12 16:04:35,624 Epoch 352/500
2025-05-12 16:04:57,285 Current Learning Rate: 0.0002010475
2025-05-12 16:04:57,286 Train Loss: 0.0001112, Val Loss: 0.0007020
2025-05-12 16:04:57,286 Epoch 353/500
2025-05-12 16:05:18,732 Current Learning Rate: 0.0001985352
2025-05-12 16:05:18,954 Train Loss: 0.0001090, Val Loss: 0.0006949
2025-05-12 16:05:18,954 Epoch 354/500
2025-05-12 16:05:40,625 Current Learning Rate: 0.0001960349
2025-05-12 16:05:40,625 Train Loss: 0.0001081, Val Loss: 0.0006999
2025-05-12 16:05:40,625 Epoch 355/500
2025-05-12 16:06:02,251 Current Learning Rate: 0.0001935465
2025-05-12 16:06:02,252 Train Loss: 0.0001073, Val Loss: 0.0006961
2025-05-12 16:06:02,252 Epoch 356/500
2025-05-12 16:06:23,925 Current Learning Rate: 0.0001910702
2025-05-12 16:06:23,925 Train Loss: 0.0001074, Val Loss: 0.0006979
2025-05-12 16:06:23,925 Epoch 357/500
2025-05-12 16:06:45,694 Current Learning Rate: 0.0001886061
2025-05-12 16:06:45,694 Train Loss: 0.0001073, Val Loss: 0.0007002
2025-05-12 16:06:45,695 Epoch 358/500
2025-05-12 16:07:07,579 Current Learning Rate: 0.0001861543
2025-05-12 16:07:07,579 Train Loss: 0.0001079, Val Loss: 0.0007007
2025-05-12 16:07:07,580 Epoch 359/500
2025-05-12 16:07:29,569 Current Learning Rate: 0.0001837149
2025-05-12 16:07:29,569 Train Loss: 0.0001081, Val Loss: 0.0006969
2025-05-12 16:07:29,569 Epoch 360/500
2025-05-12 16:07:51,728 Current Learning Rate: 0.0001812880
2025-05-12 16:07:51,730 Train Loss: 0.0001059, Val Loss: 0.0006985
2025-05-12 16:07:51,730 Epoch 361/500
2025-05-12 16:08:13,947 Current Learning Rate: 0.0001788737
2025-05-12 16:08:13,947 Train Loss: 0.0001059, Val Loss: 0.0006965
2025-05-12 16:08:13,948 Epoch 362/500
2025-05-12 16:08:35,905 Current Learning Rate: 0.0001764720
2025-05-12 16:08:35,906 Train Loss: 0.0001056, Val Loss: 0.0006975
2025-05-12 16:08:35,906 Epoch 363/500
2025-05-12 16:08:57,402 Current Learning Rate: 0.0001740831
2025-05-12 16:08:57,403 Train Loss: 0.0001056, Val Loss: 0.0006991
2025-05-12 16:08:57,403 Epoch 364/500
2025-05-12 16:09:18,958 Current Learning Rate: 0.0001717071
2025-05-12 16:09:18,959 Train Loss: 0.0001061, Val Loss: 0.0006998
2025-05-12 16:09:18,959 Epoch 365/500
2025-05-12 16:09:40,534 Current Learning Rate: 0.0001693441
2025-05-12 16:09:40,535 Train Loss: 0.0001088, Val Loss: 0.0006971
2025-05-12 16:09:40,536 Epoch 366/500
2025-05-12 16:10:01,858 Current Learning Rate: 0.0001669941
2025-05-12 16:10:01,858 Train Loss: 0.0001045, Val Loss: 0.0006980
2025-05-12 16:10:01,858 Epoch 367/500
2025-05-12 16:10:23,150 Current Learning Rate: 0.0001646572
2025-05-12 16:10:23,151 Train Loss: 0.0001033, Val Loss: 0.0006953
2025-05-12 16:10:23,151 Epoch 368/500
2025-05-12 16:10:44,569 Current Learning Rate: 0.0001623336
2025-05-12 16:10:44,569 Train Loss: 0.0001017, Val Loss: 0.0006957
2025-05-12 16:10:44,569 Epoch 369/500
2025-05-12 16:11:05,719 Current Learning Rate: 0.0001600233
2025-05-12 16:11:05,720 Train Loss: 0.0001022, Val Loss: 0.0006974
2025-05-12 16:11:05,720 Epoch 370/500
2025-05-12 16:11:27,052 Current Learning Rate: 0.0001577264
2025-05-12 16:11:27,053 Train Loss: 0.0001020, Val Loss: 0.0007010
2025-05-12 16:11:27,053 Epoch 371/500
2025-05-12 16:11:48,401 Current Learning Rate: 0.0001554431
2025-05-12 16:11:48,401 Train Loss: 0.0001018, Val Loss: 0.0006953
2025-05-12 16:11:48,401 Epoch 372/500
2025-05-12 16:12:09,976 Current Learning Rate: 0.0001531733
2025-05-12 16:12:09,977 Train Loss: 0.0001006, Val Loss: 0.0006963
2025-05-12 16:12:09,977 Epoch 373/500
2025-05-12 16:12:31,310 Current Learning Rate: 0.0001509173
2025-05-12 16:12:31,311 Train Loss: 0.0001007, Val Loss: 0.0006997
2025-05-12 16:12:31,311 Epoch 374/500
2025-05-12 16:12:52,539 Current Learning Rate: 0.0001486750
2025-05-12 16:12:52,540 Train Loss: 0.0001007, Val Loss: 0.0006972
2025-05-12 16:12:52,540 Epoch 375/500
2025-05-12 16:13:13,920 Current Learning Rate: 0.0001464466
2025-05-12 16:13:13,921 Train Loss: 0.0001003, Val Loss: 0.0007007
2025-05-12 16:13:13,921 Epoch 376/500
2025-05-12 16:13:34,994 Current Learning Rate: 0.0001442322
2025-05-12 16:13:34,994 Train Loss: 0.0000999, Val Loss: 0.0006999
2025-05-12 16:13:34,995 Epoch 377/500
2025-05-12 16:13:56,152 Current Learning Rate: 0.0001420318
2025-05-12 16:13:56,152 Train Loss: 0.0000998, Val Loss: 0.0006985
2025-05-12 16:13:56,152 Epoch 378/500
2025-05-12 16:14:17,333 Current Learning Rate: 0.0001398455
2025-05-12 16:14:17,333 Train Loss: 0.0001008, Val Loss: 0.0006969
2025-05-12 16:14:17,334 Epoch 379/500
2025-05-12 16:14:38,618 Current Learning Rate: 0.0001376734
2025-05-12 16:14:38,619 Train Loss: 0.0001002, Val Loss: 0.0006987
2025-05-12 16:14:38,619 Epoch 380/500
2025-05-12 16:14:59,926 Current Learning Rate: 0.0001355157
2025-05-12 16:14:59,926 Train Loss: 0.0001003, Val Loss: 0.0006993
2025-05-12 16:14:59,927 Epoch 381/500
2025-05-12 16:15:21,197 Current Learning Rate: 0.0001333723
2025-05-12 16:15:21,198 Train Loss: 0.0000992, Val Loss: 0.0006986
2025-05-12 16:15:21,198 Epoch 382/500
2025-05-12 16:15:42,481 Current Learning Rate: 0.0001312434
2025-05-12 16:15:42,481 Train Loss: 0.0000992, Val Loss: 0.0006974
2025-05-12 16:15:42,482 Epoch 383/500
2025-05-12 16:16:03,659 Current Learning Rate: 0.0001291291
2025-05-12 16:16:03,660 Train Loss: 0.0000994, Val Loss: 0.0006965
2025-05-12 16:16:03,660 Epoch 384/500
2025-05-12 16:16:24,917 Current Learning Rate: 0.0001270294
2025-05-12 16:16:24,917 Train Loss: 0.0000978, Val Loss: 0.0006996
2025-05-12 16:16:24,917 Epoch 385/500
2025-05-12 16:16:46,114 Current Learning Rate: 0.0001249445
2025-05-12 16:16:46,114 Train Loss: 0.0000979, Val Loss: 0.0007027
2025-05-12 16:16:46,114 Epoch 386/500
2025-05-12 16:17:07,216 Current Learning Rate: 0.0001228743
2025-05-12 16:17:07,217 Train Loss: 0.0000975, Val Loss: 0.0006956
2025-05-12 16:17:07,217 Epoch 387/500
2025-05-12 16:17:28,485 Current Learning Rate: 0.0001208190
2025-05-12 16:17:28,486 Train Loss: 0.0000968, Val Loss: 0.0006982
2025-05-12 16:17:28,486 Epoch 388/500
2025-05-12 16:17:49,909 Current Learning Rate: 0.0001187787
2025-05-12 16:17:50,087 Train Loss: 0.0000963, Val Loss: 0.0006947
2025-05-12 16:17:50,087 Epoch 389/500
2025-05-12 16:18:11,124 Current Learning Rate: 0.0001167535
2025-05-12 16:18:11,125 Train Loss: 0.0000962, Val Loss: 0.0006969
2025-05-12 16:18:11,125 Epoch 390/500
2025-05-12 16:18:32,450 Current Learning Rate: 0.0001147434
2025-05-12 16:18:32,450 Train Loss: 0.0000959, Val Loss: 0.0006999
2025-05-12 16:18:32,450 Epoch 391/500
2025-05-12 16:18:53,666 Current Learning Rate: 0.0001127485
2025-05-12 16:18:53,666 Train Loss: 0.0000958, Val Loss: 0.0006970
2025-05-12 16:18:53,667 Epoch 392/500
2025-05-12 16:19:15,297 Current Learning Rate: 0.0001107688
2025-05-12 16:19:15,298 Train Loss: 0.0000952, Val Loss: 0.0006953
2025-05-12 16:19:15,298 Epoch 393/500
2025-05-12 16:19:36,785 Current Learning Rate: 0.0001088046
2025-05-12 16:19:36,786 Train Loss: 0.0000950, Val Loss: 0.0006989
2025-05-12 16:19:36,786 Epoch 394/500
2025-05-12 16:19:58,540 Current Learning Rate: 0.0001068558
2025-05-12 16:19:58,540 Train Loss: 0.0000953, Val Loss: 0.0006975
2025-05-12 16:19:58,540 Epoch 395/500
2025-05-12 16:20:20,086 Current Learning Rate: 0.0001049225
2025-05-12 16:20:20,087 Train Loss: 0.0000949, Val Loss: 0.0006977
2025-05-12 16:20:20,087 Epoch 396/500
2025-05-12 16:20:41,712 Current Learning Rate: 0.0001030048
2025-05-12 16:20:41,712 Train Loss: 0.0000950, Val Loss: 0.0006985
2025-05-12 16:20:41,712 Epoch 397/500
2025-05-12 16:21:03,699 Current Learning Rate: 0.0001011028
2025-05-12 16:21:03,699 Train Loss: 0.0000947, Val Loss: 0.0006967
2025-05-12 16:21:03,699 Epoch 398/500
2025-05-12 16:21:25,902 Current Learning Rate: 0.0000992165
2025-05-12 16:21:25,903 Train Loss: 0.0000942, Val Loss: 0.0006998
2025-05-12 16:21:25,907 Epoch 399/500
2025-05-12 16:21:47,762 Current Learning Rate: 0.0000973461
2025-05-12 16:21:47,763 Train Loss: 0.0000939, Val Loss: 0.0006985
2025-05-12 16:21:47,764 Epoch 400/500
2025-05-12 16:22:09,833 Current Learning Rate: 0.0000954915
2025-05-12 16:22:10,006 Saved periodic model at epoch 400 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/SimVP_0512_LiNS2d_epoch_400.pth
2025-05-12 16:22:10,006 Train Loss: 0.0000937, Val Loss: 0.0006990
2025-05-12 16:22:10,006 Epoch 401/500
2025-05-12 16:22:31,613 Current Learning Rate: 0.0000936529
2025-05-12 16:22:31,613 Train Loss: 0.0000935, Val Loss: 0.0006981
2025-05-12 16:22:31,613 Epoch 402/500
2025-05-12 16:22:53,278 Current Learning Rate: 0.0000918304
2025-05-12 16:22:53,279 Train Loss: 0.0000930, Val Loss: 0.0006986
2025-05-12 16:22:53,279 Epoch 403/500
2025-05-12 16:23:15,125 Current Learning Rate: 0.0000900239
2025-05-12 16:23:15,125 Train Loss: 0.0000931, Val Loss: 0.0006981
2025-05-12 16:23:15,125 Epoch 404/500
2025-05-12 16:23:36,767 Current Learning Rate: 0.0000882337
2025-05-12 16:23:36,769 Train Loss: 0.0000929, Val Loss: 0.0006994
2025-05-12 16:23:36,770 Epoch 405/500
2025-05-12 16:23:58,574 Current Learning Rate: 0.0000864597
2025-05-12 16:23:58,574 Train Loss: 0.0000925, Val Loss: 0.0006971
2025-05-12 16:23:58,575 Epoch 406/500
2025-05-12 16:24:20,266 Current Learning Rate: 0.0000847021
2025-05-12 16:24:20,267 Train Loss: 0.0000922, Val Loss: 0.0006990
2025-05-12 16:24:20,267 Epoch 407/500
2025-05-12 16:24:41,933 Current Learning Rate: 0.0000829608
2025-05-12 16:24:41,934 Train Loss: 0.0000923, Val Loss: 0.0006982
2025-05-12 16:24:41,934 Epoch 408/500
2025-05-12 16:25:03,555 Current Learning Rate: 0.0000812360
2025-05-12 16:25:03,556 Train Loss: 0.0000920, Val Loss: 0.0006988
2025-05-12 16:25:03,556 Epoch 409/500
2025-05-12 16:25:25,073 Current Learning Rate: 0.0000795277
2025-05-12 16:25:25,073 Train Loss: 0.0000916, Val Loss: 0.0006984
2025-05-12 16:25:25,073 Epoch 410/500
2025-05-12 16:25:46,971 Current Learning Rate: 0.0000778360
2025-05-12 16:25:46,972 Train Loss: 0.0000912, Val Loss: 0.0006987
2025-05-12 16:25:46,972 Epoch 411/500
2025-05-12 16:26:09,032 Current Learning Rate: 0.0000761610
2025-05-12 16:26:09,032 Train Loss: 0.0000912, Val Loss: 0.0006984
2025-05-12 16:26:09,033 Epoch 412/500
2025-05-12 16:26:31,007 Current Learning Rate: 0.0000745028
2025-05-12 16:26:31,007 Train Loss: 0.0000911, Val Loss: 0.0007004
2025-05-12 16:26:31,008 Epoch 413/500
2025-05-12 16:26:53,186 Current Learning Rate: 0.0000728613
2025-05-12 16:26:53,186 Train Loss: 0.0000909, Val Loss: 0.0006993
2025-05-12 16:26:53,186 Epoch 414/500
2025-05-12 16:27:14,824 Current Learning Rate: 0.0000712367
2025-05-12 16:27:14,827 Train Loss: 0.0000907, Val Loss: 0.0007005
2025-05-12 16:27:14,828 Epoch 415/500
2025-05-12 16:27:36,576 Current Learning Rate: 0.0000696290
2025-05-12 16:27:36,576 Train Loss: 0.0000905, Val Loss: 0.0006993
2025-05-12 16:27:36,577 Epoch 416/500
2025-05-12 16:27:58,270 Current Learning Rate: 0.0000680383
2025-05-12 16:27:58,271 Train Loss: 0.0000902, Val Loss: 0.0006994
2025-05-12 16:27:58,271 Epoch 417/500
2025-05-12 16:28:19,839 Current Learning Rate: 0.0000664646
2025-05-12 16:28:19,839 Train Loss: 0.0000900, Val Loss: 0.0006993
2025-05-12 16:28:19,839 Epoch 418/500
2025-05-12 16:28:41,500 Current Learning Rate: 0.0000649081
2025-05-12 16:28:41,500 Train Loss: 0.0000899, Val Loss: 0.0006981
2025-05-12 16:28:41,500 Epoch 419/500
2025-05-12 16:29:03,348 Current Learning Rate: 0.0000633688
2025-05-12 16:29:03,349 Train Loss: 0.0000898, Val Loss: 0.0006985
2025-05-12 16:29:03,349 Epoch 420/500
2025-05-12 16:29:24,740 Current Learning Rate: 0.0000618467
2025-05-12 16:29:24,741 Train Loss: 0.0000896, Val Loss: 0.0006991
2025-05-12 16:29:24,742 Epoch 421/500
2025-05-12 16:29:46,246 Current Learning Rate: 0.0000603418
2025-05-12 16:29:46,247 Train Loss: 0.0000896, Val Loss: 0.0006995
2025-05-12 16:29:46,247 Epoch 422/500
2025-05-12 16:30:07,956 Current Learning Rate: 0.0000588544
2025-05-12 16:30:07,957 Train Loss: 0.0000892, Val Loss: 0.0006994
2025-05-12 16:30:07,957 Epoch 423/500
2025-05-12 16:30:29,697 Current Learning Rate: 0.0000573843
2025-05-12 16:30:29,698 Train Loss: 0.0000893, Val Loss: 0.0006988
2025-05-12 16:30:29,698 Epoch 424/500
2025-05-12 16:30:51,646 Current Learning Rate: 0.0000559318
2025-05-12 16:30:51,648 Train Loss: 0.0000889, Val Loss: 0.0007002
2025-05-12 16:30:51,648 Epoch 425/500
2025-05-12 16:31:13,624 Current Learning Rate: 0.0000544967
2025-05-12 16:31:13,625 Train Loss: 0.0000887, Val Loss: 0.0006995
2025-05-12 16:31:13,625 Epoch 426/500
2025-05-12 16:31:35,070 Current Learning Rate: 0.0000530793
2025-05-12 16:31:35,071 Train Loss: 0.0000886, Val Loss: 0.0007000
2025-05-12 16:31:35,076 Epoch 427/500
2025-05-12 16:31:56,983 Current Learning Rate: 0.0000516795
2025-05-12 16:31:56,984 Train Loss: 0.0000885, Val Loss: 0.0006990
2025-05-12 16:31:56,985 Epoch 428/500
2025-05-12 16:32:18,450 Current Learning Rate: 0.0000502974
2025-05-12 16:32:18,451 Train Loss: 0.0000884, Val Loss: 0.0007006
2025-05-12 16:32:18,451 Epoch 429/500
2025-05-12 16:32:40,055 Current Learning Rate: 0.0000489330
2025-05-12 16:32:40,056 Train Loss: 0.0000882, Val Loss: 0.0006998
2025-05-12 16:32:40,056 Epoch 430/500
2025-05-12 16:33:01,551 Current Learning Rate: 0.0000475865
2025-05-12 16:33:01,552 Train Loss: 0.0000881, Val Loss: 0.0006997
2025-05-12 16:33:01,552 Epoch 431/500
2025-05-12 16:33:22,754 Current Learning Rate: 0.0000462578
2025-05-12 16:33:22,754 Train Loss: 0.0000879, Val Loss: 0.0006996
2025-05-12 16:33:22,755 Epoch 432/500
2025-05-12 16:33:43,904 Current Learning Rate: 0.0000449470
2025-05-12 16:33:43,904 Train Loss: 0.0000877, Val Loss: 0.0007000
2025-05-12 16:33:43,904 Epoch 433/500
2025-05-12 16:34:04,964 Current Learning Rate: 0.0000436542
2025-05-12 16:34:04,965 Train Loss: 0.0000875, Val Loss: 0.0007008
2025-05-12 16:34:04,965 Epoch 434/500
2025-05-12 16:34:26,131 Current Learning Rate: 0.0000423794
2025-05-12 16:34:26,131 Train Loss: 0.0000875, Val Loss: 0.0007008
2025-05-12 16:34:26,132 Epoch 435/500
2025-05-12 16:34:47,572 Current Learning Rate: 0.0000411227
2025-05-12 16:34:47,572 Train Loss: 0.0000874, Val Loss: 0.0006994
2025-05-12 16:34:47,572 Epoch 436/500
2025-05-12 16:35:08,771 Current Learning Rate: 0.0000398841
2025-05-12 16:35:08,772 Train Loss: 0.0000873, Val Loss: 0.0006999
2025-05-12 16:35:08,776 Epoch 437/500
2025-05-12 16:35:30,034 Current Learning Rate: 0.0000386636
2025-05-12 16:35:30,035 Train Loss: 0.0000871, Val Loss: 0.0007006
2025-05-12 16:35:30,035 Epoch 438/500
2025-05-12 16:35:51,241 Current Learning Rate: 0.0000374614
2025-05-12 16:35:51,241 Train Loss: 0.0000870, Val Loss: 0.0007001
2025-05-12 16:35:51,242 Epoch 439/500
2025-05-12 16:36:12,570 Current Learning Rate: 0.0000362774
2025-05-12 16:36:12,570 Train Loss: 0.0000869, Val Loss: 0.0006990
2025-05-12 16:36:12,570 Epoch 440/500
2025-05-12 16:36:33,484 Current Learning Rate: 0.0000351118
2025-05-12 16:36:33,484 Train Loss: 0.0000868, Val Loss: 0.0007004
2025-05-12 16:36:33,485 Epoch 441/500
2025-05-12 16:36:54,884 Current Learning Rate: 0.0000339644
2025-05-12 16:36:54,885 Train Loss: 0.0000866, Val Loss: 0.0007001
2025-05-12 16:36:54,885 Epoch 442/500
2025-05-12 16:37:16,105 Current Learning Rate: 0.0000328355
2025-05-12 16:37:16,105 Train Loss: 0.0000865, Val Loss: 0.0007001
2025-05-12 16:37:16,105 Epoch 443/500
2025-05-12 16:37:37,499 Current Learning Rate: 0.0000317251
2025-05-12 16:37:37,499 Train Loss: 0.0000864, Val Loss: 0.0007000
2025-05-12 16:37:37,499 Epoch 444/500
2025-05-12 16:37:59,326 Current Learning Rate: 0.0000306331
2025-05-12 16:37:59,326 Train Loss: 0.0000863, Val Loss: 0.0007004
2025-05-12 16:37:59,326 Epoch 445/500
2025-05-12 16:38:20,860 Current Learning Rate: 0.0000295596
2025-05-12 16:38:20,861 Train Loss: 0.0000862, Val Loss: 0.0007009
2025-05-12 16:38:20,861 Epoch 446/500
2025-05-12 16:38:42,192 Current Learning Rate: 0.0000285047
2025-05-12 16:38:42,192 Train Loss: 0.0000861, Val Loss: 0.0007008
2025-05-12 16:38:42,192 Epoch 447/500
2025-05-12 16:39:03,687 Current Learning Rate: 0.0000274685
2025-05-12 16:39:03,688 Train Loss: 0.0000860, Val Loss: 0.0007009
2025-05-12 16:39:03,688 Epoch 448/500
2025-05-12 16:39:25,123 Current Learning Rate: 0.0000264508
2025-05-12 16:39:25,124 Train Loss: 0.0000859, Val Loss: 0.0007004
2025-05-12 16:39:25,124 Epoch 449/500
2025-05-12 16:39:46,113 Current Learning Rate: 0.0000254519
2025-05-12 16:39:46,113 Train Loss: 0.0000859, Val Loss: 0.0007015
2025-05-12 16:39:46,113 Epoch 450/500
2025-05-12 16:40:07,339 Current Learning Rate: 0.0000244717
2025-05-12 16:40:07,511 Saved periodic model at epoch 450 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/SimVP_0512_LiNS2d_epoch_450.pth
2025-05-12 16:40:07,511 Train Loss: 0.0000858, Val Loss: 0.0007004
2025-05-12 16:40:07,511 Epoch 451/500
2025-05-12 16:40:28,629 Current Learning Rate: 0.0000235103
2025-05-12 16:40:28,629 Train Loss: 0.0000857, Val Loss: 0.0007006
2025-05-12 16:40:28,630 Epoch 452/500
2025-05-12 16:40:49,918 Current Learning Rate: 0.0000225677
2025-05-12 16:40:49,919 Train Loss: 0.0000856, Val Loss: 0.0007012
2025-05-12 16:40:49,919 Epoch 453/500
2025-05-12 16:41:11,020 Current Learning Rate: 0.0000216440
2025-05-12 16:41:11,021 Train Loss: 0.0000855, Val Loss: 0.0007013
2025-05-12 16:41:11,021 Epoch 454/500
2025-05-12 16:41:32,301 Current Learning Rate: 0.0000207391
2025-05-12 16:41:32,301 Train Loss: 0.0000854, Val Loss: 0.0007010
2025-05-12 16:41:32,301 Epoch 455/500
2025-05-12 16:41:53,513 Current Learning Rate: 0.0000198532
2025-05-12 16:41:53,514 Train Loss: 0.0000853, Val Loss: 0.0007014
2025-05-12 16:41:53,514 Epoch 456/500
2025-05-12 16:42:14,721 Current Learning Rate: 0.0000189862
2025-05-12 16:42:14,721 Train Loss: 0.0000853, Val Loss: 0.0007005
2025-05-12 16:42:14,721 Epoch 457/500
2025-05-12 16:42:35,945 Current Learning Rate: 0.0000181382
2025-05-12 16:42:35,946 Train Loss: 0.0000852, Val Loss: 0.0007018
2025-05-12 16:42:35,946 Epoch 458/500
2025-05-12 16:42:57,131 Current Learning Rate: 0.0000173092
2025-05-12 16:42:57,132 Train Loss: 0.0000851, Val Loss: 0.0007012
2025-05-12 16:42:57,132 Epoch 459/500
2025-05-12 16:43:18,525 Current Learning Rate: 0.0000164993
2025-05-12 16:43:18,525 Train Loss: 0.0000850, Val Loss: 0.0007011
2025-05-12 16:43:18,525 Epoch 460/500
2025-05-12 16:43:39,745 Current Learning Rate: 0.0000157084
2025-05-12 16:43:39,745 Train Loss: 0.0000850, Val Loss: 0.0007012
2025-05-12 16:43:39,745 Epoch 461/500
2025-05-12 16:44:00,979 Current Learning Rate: 0.0000149367
2025-05-12 16:44:00,979 Train Loss: 0.0000849, Val Loss: 0.0007015
2025-05-12 16:44:00,979 Epoch 462/500
2025-05-12 16:44:22,355 Current Learning Rate: 0.0000141841
2025-05-12 16:44:22,356 Train Loss: 0.0000848, Val Loss: 0.0007016
2025-05-12 16:44:22,357 Epoch 463/500
2025-05-12 16:44:43,654 Current Learning Rate: 0.0000134507
2025-05-12 16:44:43,654 Train Loss: 0.0000848, Val Loss: 0.0007015
2025-05-12 16:44:43,654 Epoch 464/500
2025-05-12 16:45:05,211 Current Learning Rate: 0.0000127366
2025-05-12 16:45:05,212 Train Loss: 0.0000847, Val Loss: 0.0007016
2025-05-12 16:45:05,212 Epoch 465/500
2025-05-12 16:45:26,620 Current Learning Rate: 0.0000120416
2025-05-12 16:45:26,620 Train Loss: 0.0000847, Val Loss: 0.0007015
2025-05-12 16:45:26,621 Epoch 466/500
2025-05-12 16:45:48,047 Current Learning Rate: 0.0000113659
2025-05-12 16:45:48,048 Train Loss: 0.0000846, Val Loss: 0.0007014
2025-05-12 16:45:48,048 Epoch 467/500
2025-05-12 16:46:09,267 Current Learning Rate: 0.0000107095
2025-05-12 16:46:09,268 Train Loss: 0.0000846, Val Loss: 0.0007013
2025-05-12 16:46:09,268 Epoch 468/500
2025-05-12 16:46:30,697 Current Learning Rate: 0.0000100725
2025-05-12 16:46:30,697 Train Loss: 0.0000845, Val Loss: 0.0007013
2025-05-12 16:46:30,697 Epoch 469/500
2025-05-12 16:46:51,765 Current Learning Rate: 0.0000094547
2025-05-12 16:46:51,765 Train Loss: 0.0000845, Val Loss: 0.0007016
2025-05-12 16:46:51,765 Epoch 470/500
2025-05-12 16:47:12,835 Current Learning Rate: 0.0000088564
2025-05-12 16:47:12,835 Train Loss: 0.0000844, Val Loss: 0.0007019
2025-05-12 16:47:12,836 Epoch 471/500
2025-05-12 16:47:34,069 Current Learning Rate: 0.0000082774
2025-05-12 16:47:34,070 Train Loss: 0.0000844, Val Loss: 0.0007017
2025-05-12 16:47:34,070 Epoch 472/500
2025-05-12 16:47:55,375 Current Learning Rate: 0.0000077178
2025-05-12 16:47:55,375 Train Loss: 0.0000843, Val Loss: 0.0007016
2025-05-12 16:47:55,375 Epoch 473/500
2025-05-12 16:48:16,607 Current Learning Rate: 0.0000071777
2025-05-12 16:48:16,608 Train Loss: 0.0000843, Val Loss: 0.0007020
2025-05-12 16:48:16,608 Epoch 474/500
2025-05-12 16:48:37,896 Current Learning Rate: 0.0000066570
2025-05-12 16:48:37,896 Train Loss: 0.0000842, Val Loss: 0.0007017
2025-05-12 16:48:37,896 Epoch 475/500
2025-05-12 16:48:59,150 Current Learning Rate: 0.0000061558
2025-05-12 16:48:59,151 Train Loss: 0.0000842, Val Loss: 0.0007016
2025-05-12 16:48:59,151 Epoch 476/500
2025-05-12 16:49:20,403 Current Learning Rate: 0.0000056741
2025-05-12 16:49:20,403 Train Loss: 0.0000842, Val Loss: 0.0007018
2025-05-12 16:49:20,403 Epoch 477/500
2025-05-12 16:49:41,740 Current Learning Rate: 0.0000052119
2025-05-12 16:49:41,741 Train Loss: 0.0000841, Val Loss: 0.0007019
2025-05-12 16:49:41,741 Epoch 478/500
2025-05-12 16:50:02,928 Current Learning Rate: 0.0000047693
2025-05-12 16:50:02,929 Train Loss: 0.0000841, Val Loss: 0.0007015
2025-05-12 16:50:02,936 Epoch 479/500
2025-05-12 16:50:24,297 Current Learning Rate: 0.0000043462
2025-05-12 16:50:24,297 Train Loss: 0.0000841, Val Loss: 0.0007019
2025-05-12 16:50:24,297 Epoch 480/500
2025-05-12 16:50:45,409 Current Learning Rate: 0.0000039426
2025-05-12 16:50:45,410 Train Loss: 0.0000840, Val Loss: 0.0007016
2025-05-12 16:50:45,410 Epoch 481/500
2025-05-12 16:51:06,545 Current Learning Rate: 0.0000035587
2025-05-12 16:51:06,545 Train Loss: 0.0000840, Val Loss: 0.0007020
2025-05-12 16:51:06,545 Epoch 482/500
2025-05-12 16:51:27,476 Current Learning Rate: 0.0000031943
2025-05-12 16:51:27,476 Train Loss: 0.0000840, Val Loss: 0.0007016
2025-05-12 16:51:27,476 Epoch 483/500
2025-05-12 16:51:48,718 Current Learning Rate: 0.0000028496
2025-05-12 16:51:48,718 Train Loss: 0.0000840, Val Loss: 0.0007020
2025-05-12 16:51:48,719 Epoch 484/500
2025-05-12 16:52:09,982 Current Learning Rate: 0.0000025245
2025-05-12 16:52:09,983 Train Loss: 0.0000839, Val Loss: 0.0007016
2025-05-12 16:52:09,983 Epoch 485/500
2025-05-12 16:52:31,146 Current Learning Rate: 0.0000022190
2025-05-12 16:52:31,147 Train Loss: 0.0000839, Val Loss: 0.0007017
2025-05-12 16:52:31,147 Epoch 486/500
2025-05-12 16:52:52,540 Current Learning Rate: 0.0000019332
2025-05-12 16:52:52,540 Train Loss: 0.0000839, Val Loss: 0.0007020
2025-05-12 16:52:52,541 Epoch 487/500
2025-05-12 16:53:13,779 Current Learning Rate: 0.0000016670
2025-05-12 16:53:13,780 Train Loss: 0.0000839, Val Loss: 0.0007017
2025-05-12 16:53:13,780 Epoch 488/500
2025-05-12 16:53:35,021 Current Learning Rate: 0.0000014205
2025-05-12 16:53:35,021 Train Loss: 0.0000839, Val Loss: 0.0007019
2025-05-12 16:53:35,022 Epoch 489/500
2025-05-12 16:53:56,085 Current Learning Rate: 0.0000011937
2025-05-12 16:53:56,086 Train Loss: 0.0000839, Val Loss: 0.0007018
2025-05-12 16:53:56,086 Epoch 490/500
2025-05-12 16:54:17,629 Current Learning Rate: 0.0000009866
2025-05-12 16:54:17,629 Train Loss: 0.0000838, Val Loss: 0.0007018
2025-05-12 16:54:17,629 Epoch 491/500
2025-05-12 16:54:38,799 Current Learning Rate: 0.0000007992
2025-05-12 16:54:38,799 Train Loss: 0.0000838, Val Loss: 0.0007020
2025-05-12 16:54:38,799 Epoch 492/500
2025-05-12 16:55:00,335 Current Learning Rate: 0.0000006315
2025-05-12 16:55:00,336 Train Loss: 0.0000838, Val Loss: 0.0007019
2025-05-12 16:55:00,342 Epoch 493/500
2025-05-12 16:55:21,526 Current Learning Rate: 0.0000004835
2025-05-12 16:55:21,526 Train Loss: 0.0000838, Val Loss: 0.0007017
2025-05-12 16:55:21,526 Epoch 494/500
2025-05-12 16:55:42,731 Current Learning Rate: 0.0000003553
2025-05-12 16:55:42,731 Train Loss: 0.0000838, Val Loss: 0.0007016
2025-05-12 16:55:42,732 Epoch 495/500
2025-05-12 16:56:03,858 Current Learning Rate: 0.0000002467
2025-05-12 16:56:03,858 Train Loss: 0.0000838, Val Loss: 0.0007018
2025-05-12 16:56:03,858 Epoch 496/500
2025-05-12 16:56:24,968 Current Learning Rate: 0.0000001579
2025-05-12 16:56:24,968 Train Loss: 0.0000838, Val Loss: 0.0007019
2025-05-12 16:56:24,968 Epoch 497/500
2025-05-12 16:56:46,196 Current Learning Rate: 0.0000000888
2025-05-12 16:56:46,197 Train Loss: 0.0000838, Val Loss: 0.0007018
2025-05-12 16:56:46,197 Epoch 498/500
2025-05-12 16:57:07,567 Current Learning Rate: 0.0000000395
2025-05-12 16:57:07,568 Train Loss: 0.0000838, Val Loss: 0.0007018
2025-05-12 16:57:07,568 Epoch 499/500
2025-05-12 16:57:28,752 Current Learning Rate: 0.0000000099
2025-05-12 16:57:28,752 Train Loss: 0.0000838, Val Loss: 0.0007018
2025-05-12 16:57:28,752 Epoch 500/500
2025-05-12 16:57:49,634 Current Learning Rate: 0.0000000000
2025-05-12 16:57:49,801 Saved periodic model at epoch 500 to /jizhicfs/easyluwu/ocean_project/NeurIPS_2025_wuhao/checkpoints/SimVP_0512_LiNS2d_epoch_500.pth
2025-05-12 16:57:49,801 Train Loss: 0.0000838, Val Loss: 0.0007018
