{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9dd0be5-0655-4eae-9768-ada06d076927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/envs/haowu/lib/python3.10/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11000). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 1, 1, 64, 64])\n",
      "Output shape: torch.Size([1, 1, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import operator\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "################################################################\n",
    "# Fourier Layer\n",
    "################################################################\n",
    "\n",
    "class SpectralConv2d_fast(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
    "        super(SpectralConv2d_fast, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        2D Fourier layer. It performs FFT, linear transform, and Inverse FFT.\n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1  # Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.modes2 = modes2\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        # Initialize weights with complex numbers\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul2d(self, input, weights):\n",
    "        # (batch, in_channel, x, y), (in_channel, out_channel, x, y) -> (batch, out_channel, x, y)\n",
    "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        # Compute Fourier coefficients up to factor of e^(- something)\n",
    "        x_ft = torch.fft.rfft2(x, norm='forward')\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels,  x.size(-2), x.size(-1)//2 + 1, dtype=torch.cfloat, device=x.device)\n",
    "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
    "\n",
    "        # Return to physical space\n",
    "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)), norm='forward')\n",
    "        return x\n",
    "\n",
    "################################################################\n",
    "# Fourier Neural Operator 2D\n",
    "################################################################\n",
    "\n",
    "class FNO2d(nn.Module):\n",
    "    def __init__(self, modes1, modes2, width, C_in=1, C_out=1):\n",
    "        super(FNO2d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        FNO2d model adapted to inputs with variable channels and spatial resolution.\n",
    "\n",
    "        Expected input shape: (batch_size, time_steps=1, channels=C_in, height=H, width=W)\n",
    "        Output shape: (batch_size, time_steps=1, channels=C_out, height=H, width=W)\n",
    "        \"\"\"\n",
    "\n",
    "        self.modes1 = modes1  # Number of Fourier modes in x direction\n",
    "        self.modes2 = modes2  # Number of Fourier modes in y direction\n",
    "        self.width = width\n",
    "        self.padding = 2  # Padding for non-periodic input, can be adjusted\n",
    "\n",
    "        self.C_in = C_in\n",
    "        self.C_out = C_out\n",
    "\n",
    "        self.fc0 = nn.Linear(self.C_in + 2, self.width)  # Input channels + 2 coordinates (x, y)\n",
    "\n",
    "        self.conv0 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv1 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv2 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv3 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
    "\n",
    "        self.w0 = nn.Conv2d(self.width, self.width, kernel_size=1)\n",
    "        self.w1 = nn.Conv2d(self.width, self.width, kernel_size=1)\n",
    "        self.w2 = nn.Conv2d(self.width, self.width, kernel_size=1)\n",
    "        self.w3 = nn.Conv2d(self.width, self.width, kernel_size=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, self.C_out)  # Output channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Expected input shape: (B, T, C_in, H, W)\n",
    "        B, T, C_in, H, W = x.shape\n",
    "        # Since T=1, we can squeeze the time dimension\n",
    "        x = x.squeeze(1)  # Remove the time dimension, shape becomes (B, C_in, H, W)\n",
    "        x = x.permute(0, 2, 3, 1)  # Permute to shape (B, H, W, C_in)\n",
    "\n",
    "        # Get grid and concatenate with input\n",
    "        grid = self.get_grid(x.shape, x.device)  # Shape: (B, H, W, 2)\n",
    "        x = torch.cat((x, grid), dim=-1)  # Shape becomes (B, H, W, C_in+2)\n",
    "\n",
    "        x = self.fc0(x)\n",
    "        x = x.permute(0, 3, 1, 2)  # Shape: (B, width, H, W)\n",
    "\n",
    "        x1 = self.conv0(x)\n",
    "        x2 = self.w0(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.w1(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv2(x)\n",
    "        x2 = self.w2(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv3(x)\n",
    "        x2 = self.w3(x)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = x.permute(0, 2, 3, 1)  # Shape: (B, H, W, width)\n",
    "        x = self.fc1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.fc2(x)  # Shape: (B, H, W, C_out)\n",
    "\n",
    "        # Adjust output shape to (B, T, C_out, H, W)\n",
    "        x = x.permute(0, 3, 1, 2)  # Shape: (B, C_out, H, W)\n",
    "        x = x.unsqueeze(1)  # Add time dimension T=1, shape becomes (B, 1, C_out, H, W)\n",
    "        return x  # Final output shape: (B, T, C_out, H, W)\n",
    "\n",
    "    def get_grid(self, shape, device):\n",
    "        '''\n",
    "        Returns a grid of shape (batchsize, H, W, 2)\n",
    "        '''\n",
    "        batchsize, size_x, size_y, _ = shape\n",
    "        gridx = torch.linspace(0, 1, steps=size_x, device=device)\n",
    "        gridx = gridx.view(1, size_x, 1, 1).repeat(batchsize, 1, size_y, 1)\n",
    "        gridy = torch.linspace(0, 1, steps=size_y, device=device)\n",
    "        gridy = gridy.view(1, 1, size_y, 1).repeat(batchsize, size_x, 1, 1)\n",
    "        return torch.cat((gridx, gridy), dim=-1)  # Shape: (B, H, W, 2)\n",
    "\n",
    "################################################################\n",
    "# Testing the Model with New Dimensions\n",
    "################################################################\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    modes1 = 16   # Adjusted modes, should be less than or equal to H/2\n",
    "    modes2 = 16   # Adjusted modes, should be less than or equal to W/2\n",
    "    width = 64    # Width of the neural network\n",
    "    batch_size = 1  # You can adjust the batch size as needed\n",
    "\n",
    "    T = 1         # Time steps, remains 1 as per your data\n",
    "    C_in = 1      # Input channels, adjusted to 1\n",
    "    C_out = 1     # Output channels, adjusted to 1\n",
    "    H, W = 64, 64  # Height and Width of the input, adjusted to 128 x 128\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = FNO2d(modes1, modes2, width, C_in=C_in, C_out=C_out).to(device)\n",
    "\n",
    "    x = torch.randn(batch_size, T, C_in, H, W).to(device)\n",
    "    print(\"Input shape:\", x.shape)\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af97004c-af09-4978-b309-072f07c6645d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
